[{"url":"/2020/09/03/React-Native-ExpoKit-Notification/boostnote/","content":"{\n  \"folders\": [],\n  \"version\": \"1.0\"\n}\n"},{"title":"iOS main in Assembly","url":"/2020/08/18/20200817-ios-main-in-assembly/","content":"\n### How to see Assemble code in Xcode \n\n`debug` -> `Product -> Action`->  `Assemble`  \"main.m\"\n\n```objective-c\n12 int main(int argc, char * argv[]) {\n13    NSString * appDelegateClassName;\n14    @autoreleasepool {\n15        // Setup code that might create autoreleased objects goes here.\n16        appDelegateClassName = NSStringFromClass([AppDelegate class]);\n17    }\n18    return UIApplicationMain(argc, argv, nil, appDelegateClassName);\n19 }\n```\n\nIt produces a file with 541 lines of code with lots of assembler directives for debugger.  \n\n###  Assembler directives \n\n```assembly\n\t.section\t__TEXT,__text,regular,pure_instructions\n\t.ios_version_min 11, 0\tsdk_version 13, 6\n\t.file\t1 \"/Users/rongyan.zheng/Downloads/AssemblyMain\" \"AssemblyMain/main.m\"\n\t.globl\t_main                   ; -- Begin function main\n\t.p2align\t2\n```\n\nThese are assembler directives, not assembly code. The `.section` directive specifies into which section the following will go.  \n\nNext, the `.globl` directive specifies that `_main` is an external symbol.`.p2align\t2` aligns  the current location in the file to a specified boundary, here it is 2^2, 4 bytes.  \n\n\n\nThen, here comes our `main`  assemble label. \n\n```assembly\n_main:                                  ; @main\nLfunc_begin0:\n\t.loc\t1 12 0                  ; AssemblyMain/main.m:12:0\n\t.cfi_startproc\n; %bb.0:\n\n```\n\n\n\n> The `.cfi_startproc` directive is used at the beginning of most functions. CFI is short for Call Frame Information. A *frame* corresponds loosely to a function. When you use the debugger and *step in* or *step out*, you’re actually stepping in/out of call frames. In C code, functions have their own call frames, but other things can too. The `.cfi_startproc` directive gives the function an entry into `.eh_frame`, which contains unwind information – this is how exception can unwind the call frame stack. The directive will also emit architecture-dependent instructions for CFI. It’s matched by a corresponding `.cfi_endproc` further down in the output to mark the end of our `main()` function.  -- https://www.objc.io/issues/6-build-tools/mach-o-executables/ \n\n\n\n### SP and stack\n\n```assembly\n\tsub\tsp, sp, #48             ; =48\n```\n\nIt sets up a call frame on the stack. in AArch64 the stack-pointer must be 128-bit aligned; here is 48*8-bit.\n\n![image-20200807093341883](image-20200807093341883.png)\n\nAbout stack and stack pointer, see more in. \n\n- [Using the Stack in AArch32 and AArch64](https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/using-the-stack-in-aarch32-and-aarch64)\n- [Using the Stack in AArch64: Implementing Push and Pop](https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/using-the-stack-in-aarch64-implementing-push-and-pop)\n\n\n\n### Addressing Mode\n\nAs a beginner, I want to know how the addresses are calculated from the figures within the square brackets\n\nHere, we have to know something about  `addressing modes`. There are several addressing modes that define how the address is formed according to [document s about ARMv8 instructions set](https://developer.arm.com/architectures/learn-the-architecture/armv8-a-instruction-set-architecture/loads-and-stores-addressing)  \n\n- **Base register** - The simplest form of addressing is a single register. Base register is an X register that contains the full, or absolute, virtual address of the data being accessed, as you can see in this figure:\n\n  <img src=\"image-20200807150953454.png\" alt=\"image-20200807150953454\"  />\n\n- **Offset addressing modes** - An offset can be applied optionally to the base address, as you can see in this figure:\n\n  <img src=\"image-20200807151043180.png\" alt=\"image-20200807151043180\"/>\n\n  In the preceding figure, X1 contains the base address and `#12` is a byte offset from that address. This means that the accessed address is` X1+12`. The offset can be either a constant or another register. This type of addressing might be used for structs, for example. The compiler maintains a pointer to the base of struct using the offset to select different members.\n\n- **Pre-index addressing modes** - In the instruction syntax, pre-index is shown by adding an exclamation mark `!` After the square brackets, as this figure shows: \n\n  ![image-20200807151621841](image-20200807151621841.png)\n\n  Pre-indexed addressing is like offset addressing,` except that the base pointer is updated as a result of the instruction`. In the preceding figure, `X1` would have the value X1+12 after the instruction has completed.\n\n- **Post-index addressing modes** - With post-index addressing, the value is loaded from the address in the base pointer, and then the pointer is updated, as this figure shows: \n\n  ![image-20200807151851210](image-20200807151851210.png)\n\n  Post-index addressing is useful for popping off the stack. The instruction loads the value from the location pointed at by the stack pointer, and then moves the stack pointer on to the next full location in the stack.\n\nSo, here comes the next instruction in our `main` function: \n\n```assembly\nstp\tx29, x30, [sp, #32] \n```\n\n`stp` pushes X29 and X30 onto the stack, which means this instruction will store values from `x29` and `x30` to memory where the address is `sp+32`. And in ARMv8, `X29` is for frame pointer, `X30` is used as the Link Register and can be referred to as LR.\n\n![image-20200807103821841](image-20200807103821841.png)\n\n### Store parameters on the Stack\n\n```assembly\nadd\tx29, sp, #32            ; =32\n```\n\nset the value of `x29` as `sp` + `#32`\n\n```assembly\nstur\twzr, [x29, #-4]\nstur\tw0, [x29, #-8]\nstr\tx1, [sp, #16]\n```\n\nstore value from `wzr` to `x29 + #-4`, which means write `x29 + #-4` using 0; \n\n>  The zero registers, ZXR and WZR, always read as 0 and ignore writes.\n\nstore value  from `w0` to `x29 + #-8;`\n\nstore value from `x1` to `sp + #16`.\n\n![image-20200807103920889](image-20200807103920889.png)\n\nMost A64 instructions operate on registers. The architecture provides 31 general purpose registers. Each register can be used as a 64-bit X register (X0..X30), or as a 32-bit W register (W0..W30).   W0 is the bottom 32 bits of X0.\n\n<img src=\"image-20200807155505092.png\" alt=\"image-20200807155505092\" style=\"zoom:50%;\" />\n\nThe choice of X or W determines the size of the operation. Using X registers will result in 64-bit calculations, and using W registers will result in 32-bit calculations. \n\n#### Registers for parameters \n\nThe Arm architecture has some restrictions on how general purpose registers are used.  \n\n`X0-X7` is the parameter/result registers.  x0-x7, are used to pass argument values into a subroutine and to return result values from a function.  The first argument is passed into `X0`, the second argument is in `X1`.  \n\nIn our case, `main` function takes two arguments, so `w0` and `X` are used. \n\n#### Registers for return \n\nWhich register is used for return result is determined by the type of that result:\n\n- If the type, T, of the result of a function is such that\n\n  `void func(T arg)`,  the result is returned in the same registers used as passing arguments. For exmaple\n\n![image-20200807175855759](image-20200807175855759.png)\n\n- Otherwise,  the caller shall reserve a block of memory of sufficient size and alignment to hold the result. The address of the memory block shall be passed as an additional argument to the function in X8.`XR` |`X8`.\n\n  \n\n```assembly\nLtmp0:\n\t.loc\t1 13 16 prologue_end    ; AssemblyMain/main.m:13:16\n\tmov\tx8, #0                    ; copy #0 to x8\n\tstr\tx8, [sp, #8]              ; \n\t.loc\t1 14 22                 ; AssemblyMain/main.m:14:22\n```\n\nThen,  store value from `x8` to `sp + #8`.  \n\n![image-20200807154518025](image-20200807154518025.png)\n\n### Branch instructions and Function calls \n\nSo let's see the next instruction. \n\n```assembly\nbl\t_objc_autoreleasePoolPush\n```\n\n> Ordinarily, a processor executes instructions in program order. This means that a processor executes instructions in the same order that they are set in memory. One way to change this order is to use branch instructions. Branch instructions change the program flow and are used for loops, decisions and function calls.\n>\n> The A64 instruction set also has some conditional branch instructions. These are instructions that change the way they execute, based on the results of previous instructions.       --  https://developer.arm.com/architectures/learn-the-architecture/armv8-a-instruction-set-architecture/program-flow\n\n#### Unconditional branch instructions \n\n> There are two types of unconditional branch instructions; `B` which means Branch and `BR` which means Branch with Register. \n\nThe unconditional branch instruction `B <label`> performs a direct, PC-relative, branch to <label>.\n\nIn our case, the `labe` is  `_objc_autoreleasePoolPush`; `bl\t_objc_autoreleasePoolPush` means we will jump to `_objc_autoreleasePoolPush` routine. \n\n#### Conditional branch instructions \n\nThe conditional branch instruction B.<cond> <label> is the conditional version of the B instruction. The branch is only taken if the condition <cond> is true. The range is limited to +/- 1MB.\n\n#### [Labels for PC-relative addresses](https://www.keil.com/support/man/docs/armasm/armasm_dom1359731174549.htm)\n\n> A label can represent the PC value plus or minus the offset from the PC to the label. Use these labels as targets for branch instructions, or to access small items of data embedded in code sections.\n\n\n\n```assembly\n\tadrp\tx8, _OBJC_SELECTOR_REFERENCES_@PAGE\n\tadd\tx8, x8, _OBJC_SELECTOR_REFERENCES_@PAGEOFF        ;@selector(class)\n\tadrp\tx9, _OBJC_CLASSLIST_REFERENCES_$_@PAGE \n\tadd\tx9, x9, _OBJC_CLASSLIST_REFERENCES_$_@PAGEOFF     ; objc_cls_ref_AppDelegate\n```\n\n- `adrp` is to Address of 4KB page at a PC-relative offset\n\n  I drag the final executable into `hopper`,   the address for `_OBJC_SELECTOR_REFERENCES_@PAGE` is `#0x100009000   `\n\n  ```assembly\n  000000010000621c         adrp       x8, #0x100009000                            ; 0x1000093e0@PAGE\n  0000000100006220         add        x8, x8, #0x3e0                              ; 0x1000093e0@PAGEOFF, &@selector(class)\n  0000000100006224         adrp       x9, #0x100009000                            ; 0x1000093f0@PAGE\n  0000000100006228         add        x9, x9, #0x3f0                              ; 0x1000093f0@PAGEOFF, objc_cls_ref_AppDelegate\n  000000010000622c         ldr        x9, [x9]                                    ; objc_cls_ref_AppDelegate,_OBJC_CLASS_$_AppDelegate\n  0000000100006230         ldr        x1, [x8]                                    ; \"class\",@selector(class)\n  ```\n\n  \n\n```assembly\n\tldr\tx9, [x9]                ; load data into x9 from the value in x9.\n\tldr\tx1, [x8]                ; load data into x1 from the value in x8, which is the address of @selector(class)\n\tstr\tx0, [sp]                ; 8-byte Folded Spill\n\tmov\tx0, x9                  ; move the addreess in x9 into x0, which is the address of objc_cls_ref_AppDelegate\n\tbl\t_objc_msgSend           ; call msgSend, [AppDelegate class]\n\tbl\t_NSStringFromClass      ; call NSStringFromClass \n```\n\n#### The return value and auto release \n\n```assembly\n  mov\tx29, x29\t; marker for objc_retainAutoreleaseReturnValue\n\tbl\t_objc_retainAutoreleasedReturnValue\n  ldr\tx8, [sp, #8]            ; load data into x8 from memory [sp, #8] \n\tstr\tx0, [sp, #8]            ; store data from x0 into [sp, #8], which is the result of _NSStringFromClass\n\tmov\tx0, x8                  ; move data from x8 to x0\n\tbl\t_objc_release\n\tldr\tx0, [sp]                ; 8-byte Folded Reload\n\tbl\t_objc_autoreleasePoolPop\n```\n\n\n\n`str\tx0, [sp, #8] ` means store data from x0 into [sp, #8]. As we mentioned before, for functions with this type `NSString *NSStringFromClass(Class aClass)`, the `x0` is used to store the return result. \n\n### Pass parameters\n\n```assembly\n\tldur\tw0, [x29, #-8]      ; load data into w0 from [x29, #-8]; which is int argc\n\tldr\tx1, [sp, #16]         ; load data into x1 from [sp, #16], where argv is stroed\n\tldr\tx3, [sp, #8]          ; laod data into x3 from [sp, #8], which is the result of  the result of _NSStringFromClass\n```\n\n```assembly\n\tmov\tx8, #0\n\tmov\tx2, x8                ; nil\n```\n\n\n\n```assembly\n\tbl\t_UIApplicationMain    ; call _UIApplicationMain\n\tstur\tw0, [x29, #-4]      \n\tadd\tx8, sp, #8              ; =8\n\tmov\tx0, x8\n\tmov\tx8, #0\n\tmov\tx1, x8\n\tbl\t_objc_storeStrong\n\tldur\tw0, [x29, #-4]\n\tldp\tx29, x30, [sp, #32]     ; 16-byte Folded Reload, reset \n\tadd\tsp, sp, #48             ; =48, reset \n\tret\n```\n\n\n\n`ldp\tx29, x30, [sp, #32]`  this is for reset the `fp` and linker regiseter \n\n`add\tsp, sp, #48 ` means, the call frame for this function is gone. \n\n\n\n![image-20200810095955537](image-20200810095955537.png)","tags":["Debug"],"categories":["iOS"]},{"title":"Address Sanitizer","url":"/2020/08/18/20200817-address-sanitizer/","content":"Memory corruption is hard to debug because it is `hard to consistently reproduce` and `the source of error is often far from its manifestation`. But with powful `Address Sanitizer` tool,  we  could achieve it.  `Addresss Sanitizer` is a LLVM-based debug tool to finds memory corruption at run time with `less overhead` at running time. And it works on OS X, iOS (simulator and device). \n\n### Different kinds of memory corruption \n\n- use after free \n- heap buffer overflow \n- Stack buffer overflow \n- global variable overflow \n- overflows in C++ containers \n- Use after return \n- Use after scope\n\n### How to enable Address Sanitizer\n\n- Edit Scheme \n\n- turn on the `Address Sanitizer` \n\n  ![image-20200816172927364](image-20200816172927364.png)\n\n- re-compile the App \n\nThis can be used together with `Malloc Scribble`.\n\n### Xcode Debuger UI \n\n1. showing errors \n\n   ![image-20200816210717157](image-20200816210717157.png)\n\n2. stacktrace \n\n   <img src=\"image-20200816210812044.png\" alt=\"image-20200816210812044\" style=\"zoom:50%;\" />\n\n3. memory allocation \n\n   ![image-20200816210745829](image-20200816210745829.png)\n\n4. Heap object \n\n   1. faulty addresss \n\n5. Expand Memory View. It shows the allocation and deallocation backtrace of the memory. Also we can see the bytes of the object in the memory \n   1. the black bytes : valid memory \n   2. the grey bytes: invalid memory \n\n![image-20200816213933801](image-20200816213933801.png)\n\nWe can also see the bytes of the memory  by `view Memory of xxx`\n\n![image-20200816213627715](image-20200816213627715.png)\n\nBesides, in the `LLDB`, we can run `memory history` to get the backtrace of the allocation and deallocation. \n\n![image-20200816214150578](image-20200816214150578.png)\n\n## Use Cases \n\n### Heap buffer overflow \n\n![image-20200816211332451](image-20200816211332451.png)\n\ncase from here https://www.youtube.com/watch?v=rJFoMq-RI7c\n\n### Use out of scope stack memory \n\n![image-20200816211144445](image-20200816211144445.png)\n\n`value` is a variable that inside the `if` scope. If you assign its address to `integer_pointer` and  access its memory outside the scope by using  `*integer_pointer` , it triggers `use of out of scope stack memory` \n\n### Use stack memory after return \n\n![image-20200816211204763](image-20200816211204763.png)\n\nIn the c function, `return_address_of_stack` it return `&a`, the address of `a` variable. While `a` is a stack variable in this function, the function returns, the stack frame will be released.  At. that time, if we try to use  `a` again, it triggers `use of stack memory after return`. \n\nUse of deallocated memory \n\n![image-20200816213422013](image-20200816213422013.png)\n\n\n\n## When to Use Address Sanitizer\n\n- You project is mixed with C languages and Swift\n- Memory corruptions and crashes, which are hard to reproduce and find out the root cause\n- General debugging\n\n## Integrated with Test and CI \n\nBecause it is less overhead than other tools and detects bugs at the run time,  we can integrate it with XCode test scheme and CI. \n\n#### In Xcode\n\n- Edit Scheme – Test – Diagnostics tab\n- “Enable Address Sanitizer” checkbox\n- Build and Test\n\n#### Command Line\n\n```\n$ xcodebuild -scheme \"Jogr\" test -enableAddressSanitizer YES\n```\n\n## Under the Hood \n\n### How Address Sanitizer works\n\nWhen we enable the address sanitizer and compile a executable, Xcode pass a flag to Clang when compiling. \n\n```\n-fsanitize=address\n```\n\nAfter building, the instrumented executable will contain memory checks. Besides, at runtime, this binary links with `Asan` runtime dylib that contains more checks and the dylib is required by the instrumentation. \n\n##### How this memory check works? \n\nIt will check the allocations in our process. In the following graph, the blue region is the memory we allocted.  In the right side, it is the `Shadow memory` maintained by `Address saninitzer` , which tracks the real memory in the left side, telling whether the real memory is address-accessible or not.   The `Redzones` are the poisoned memory. \n\n![image-20200816120042864](image-20200816120042864.png)\n\nIf the executable is compiled by enabling the Address sanitizer, every time before it access to memory, there is prefix instruction to check if this memory is`poisoned`.  If it was, the Address Sanitizer will generate a diagnostics report shown above. \n\n![image-20200816120700174](image-20200816120700174.png)\n\nThe following graph shows the process is trying to access to a poisoned memory and it trigger `Crash` and genrate a diagnostic report. \n\n![image-20200816120921377](image-20200816120921377.png)\n\n#### How the lookup table works \n\nIn address sanitizer, the loop up in the shadow memory should be very fast so that it will be less overhead. To achieve that, they main a look up table where every 8 bytes real memory in user process are tracked by 1 byte in the shadow memory. Even so, the loop up table is large. So they don't allocate memory region for the lookup table. Instead, they reserve the  memory region for shadow usage.  \n\n<img src=\"image-20200816121732422.png\" alt=\"image-20200816121732422\" style=\"zoom:50%;\" />\n\nSupposed the address of the real memory usage in the process is `Addr`. The address of the related shadow memory is `Add >> 3 + Offset`. If the value in the bytes in the shadow memory isn't `0`,  we know the real memory is poisoned. \n\n![image-20200816121722926](image-20200816121722926.png)\n\n### The heap object allocation \n\nThe default Malloc implementation layout out objects in memory one after another for optimizing memory consumption.  But address sanitizer replace default Malloc implementation by using it is own allocate implementation, which lays out objects further apart from each other. \n\n![image-20200816123141896](image-20200816123141896.png)\n\nAll the unused memory between objects are marked as poisoned, marked as `red` in the shadow memory.  Once  a object is free, the related shadow memory is marked as `red`, poisoned too.  Also, address sanitizer will delay reuse of free memory. So it can catch the heap buffer overflow, double-free errors, user-free etc. \n\n### Stack variables \n\n![image-20200816150456865](image-20200816150456865.png)\n\nWhen enabling the Address sanitizer and compiling the executable, some red zone will be inserted between two stack variables, so stack red zones are poisoned at the runtime. \n\n### Global variables\n\n![image-20200816151834767](image-20200816151834767.png)\n\nThey do the similar things during the compiling time for the global variables, \n\n## Overhead\n\n- CPU slowdown usually between 2x–5x\n  - In normal case, CPU slowdown 2x-3x. In some edge case, they have seen the slowdown 5x. \n\n- Memory overhead 2x–3x\n- AddressSanitizer uses more real memory than a native run. Exact overhead depends on the allocations sizes. The smaller the allocations you make the bigger the overhead is.\n- AddressSanitizer uses more stack memory. We have seen up to 3x increase.\n\nStill, this overhead is smaller than other tools that can do the same job. \n\n## The difference in Assembly code  \n\nLet's write a simple Objective-c function, and build a executable. \n\n```objective-c\n- (void)testAllocation\n{\n    NSString *f = @\"RY\";\n    NSArray *a = @[@1];\n    NSLog(@\"%@, %@\", f, a);\n}\n```\n\nThe left side is the Assembly code for normal code; the right side is the Assembly code after enabling the Address Sanitizer. \n\n![image-20200816171459459](image-20200816171459459.png)\n\nThe one with Address Sanitizer enabled adds checks. The following is the shadow memory check. If the value in `w3` , the value from the shadow memory is zero. It goes the `loc100004894` label, continue to run. But if not, it will call `imp___stubs____asan_report_store8` to generate the Address sanitizer report. \n\n![image-20200816172007233](image-20200816172007233.png)\n\n\n\n- [Avoiding Buffer Overflows and Underflows](https://developer.apple.com/library/archive/documentation/Security/Conceptual/SecureCodingGuide/Articles/BufferOverflows.html)\n\n- https://developer.apple.com/videos/play/wwdc2015/413\n- https://developer.apple.com/videos/play/wwdc2017/406\n\n- [AddressSanitizer in LLVM doc](https://clang.llvm.org/docs/AddressSanitizer.html)\n- https://www.youtube.com/watch?v=rJFoMq-RI7c","tags":["Debug"],"categories":["iOS"]},{"title":"Tail Call Elimination in iOS","url":"/2020/08/05/20200805-tail-call-elimination/","content":"\n## Basic Knowledge \n\n\n\n### Registers \n\n> Processor operations mostly involve processing data. This data can be stored in memory and accessed from thereon. However, reading data from and storing data into memory slows down the processor, as it involves complicated processes of sending the data request across the control bus and into `the memory storage unit` and getting the data through the same channel. To speed up the processor operations, the processor includes some `internal memory storage locations`, called **registers**.\n>\n> The registers store data elements for processing without having to access the memory. A limited number of registers are built into the processor chip. -- https://www.tutorialspoint.com/assembly_programming/assembly_registers.htm \n\nIn ARM 64, the following graph shows the registers' roles.\n\n![image-20200805000244292](image-20200805000244292.png)\n\n- The first eight registers, r0-r7, are used to pass argument values into a subroutine and to return result values from a function. \n- The frame record for the innermost frame (belonging to the most recent routine invocation) shall be pointed to by the `Frame Pointer register` (FP). The lowest addressed double-word shall point to the `previous frame record` and the highest addressed double-word shall contain the value passed in LR on entry to the current function. \n\n### Stack Structure\n\n> The stack is a `contiguous area of memory` that may be used for storage of local variables and for passing additional arguments to subroutines when there are insufficient argument registers available.The stack implementation is *full-descending*, with `the current extent of the stack` held in the special-purpose register `SP`.   --[Procedure Call Standard for the ARM 64-bit Architecture (AArch64)- AArch64 ABI release 1.0](https://developer.arm.com/documentation/ihi0055/b/)\n\nThe ARM environment uses a stack that—at the point of function calls—is grows downward, and contains local variables and a function’s parameters. The stack is  aligned at the point of function calls.  Figure 1 shows the stack before and during a subroutine call. \n\n![img](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/art/arm_stack.jpg)\n\n Stack frames contain the following areas:\n\n- *The parameter area* stores the arguments the caller passes to the called function or stores space for them, depending on the type of each argument and the availability of registers. This area resides in the caller’s stack frame.\n- *The linkage area* contains the address of the caller’s next instruction.\n- *The saved frame pointer* (optional) contains the base address of the caller’s stack frame.\n- The *local storage area* contains the subroutine’s local variables and the values of the registers that must be restored before the called function returns. See [Register Preservation](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/Articles/ARMv6FunctionCallingConventions.html#//apple_ref/doc/uid/TP40009021-SW4) for details.\n- The *saved registers area* contains the values of the registers that must be restored before the called function returns. See [Register Preservation](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/Articles/ARMv6FunctionCallingConventions.html#//apple_ref/doc/uid/TP40009021-SW4) for details.\n\nIn this environment, the stack frame size is not fixed.\n\nAnother stack frame layout graph comes from [Procedure Call Standard for the ARM 64-bit Architecture (AArch64)- AArch64 ABI release 1.0](https://developer.arm.com/documentation/ihi0055/b/)\n\n![image-20200805222941420](image-20200805222941420.png)\n\n### Passing Arguments\n\n> When functions (routines) call other functions (subroutines), they may need to pass arguments to them. The called subroutines access these arguments as *parameters*. Conversely, some subroutines pass a *result* or return value to their callers. In the ARMv6 environment, arguments may be passed on the runtime stack or in registers; in addition, some vector arguments are also passed passed in registers. Results are returned in registers or in memory. To efficiently pass values between callers and callees, GCC follows strict rules when it generates a program’s object code. - [ARMv6](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/Articles/ARMv6FunctionCallingConventions.html#//apple_ref/doc/uid/TP40009021-SW8)\n\nThe base standard provides for passing arguments in general-purpose registers (r0-r7)\n\n### Returning Results\n\nThe manner in which a result is returned from a function is determined by the type of that result:\n\n- If the type, `T,` of the result of a function is such that\n\n  `void func(T arg)`\n   would require that `arg` be passed as a value in a register, then the result is returned in the same registers as would be used for such an argument.\n\n- Otherwise, `the caller shall reserve a block of memory of sufficient size and alignment to hold the result`. The address of the memory block shall be passed as an additional argument to the function in `x8`. `The callee may modify the result memory block` at any point during the execution of the subroutine (there is no requirement for the callee to preserve the value stored in x8).\n\n## Tail call Elimination  \n\n### Normal Case \n\nLet's say we have a method `drawRect`, which calls ` CGContextDrawPath`\n\n```objective-c\n- (void) drawRect: (NSRect) rect {\n  // draw stuff\n  ...\n  CGContextDrawPath(_path, kCGStroke);\n}\n```\n\n<img src=\"./image-20200804224933284.png\" alt=\"image-20200804224933284\" style=\"zoom:50%;\" />\n\nThe above picture is the stack right before UIKit calls the `drawRect` method. This graph comes from [WWDC](https://developer.apple.com/videos/play/wwdc2015/412/?time=729). \n\nHere, `fp`  is the[ frame pointer]( https://chortle.ccsu.edu/assemblytutorial/Chapter-28/ass28_4.html)  .`lr` is the `link register`, which holds the next instruction to execute in the caller function( routines) that called the current function(subroutines). So the current function, `subroutines` know how to return to its caller. \n\nWhen UIKit calls `drawRect`, firstly,  `drawRect` will establish its call frame by pushing the `return` address from the link registe(`lr` )and `previous value `of the frame pointer ( `frame Ptr`), on the stack. As we said before,  there are registers store these two data. \n\n```assembly\n+0x00 push {r4, r5, r6, fp, lr}\n```\n\n the frame poniter, `fp` , will store a new address,  the value in `sp`  + 12. Then, `fp` will be set up on a new base just as the following graph shows. \n\n```assembly\n+0x02 add fp, sp, #12\n```\n\n<img src=\"./image-20200805094701153.png\" alt=\"image-20200805094701153\" style=\"zoom:50%;\" />\n\n\n\nThen, `drawRect` makes room for storing local variables,  and has its call frame on the stack. \n\n```assembly\n+0x04 sub sp, #180\n```\n\n<img src=\"./image-20200805094754924.png\" alt=\"image-20200805094754924\" style=\"zoom:50%;\" />\n\nNext, `drawRect` calls `CGContextDrawPath`,  which will also set up its call frame on the stack. \n\n<img src=\"./image-20200805094818787.png\" alt=\"image-20200805094818787\" style=\"zoom:50%;\" />\n\n> [The way time profiler works, it uses a service in the kernel ](https://developer.apple.com/videos/play/wwdc2015-412/?time=700)[that will sample what the CPUs are doing ](https://developer.apple.com/videos/play/wwdc2015-412/?time=703)[at about 1000x per second.](https://developer.apple.com/videos/play/wwdc2015-412/?time=705)In this case, if we take a sample, we see that we're running inside of context draw path.\n>\n> [Then the kernal looks at the frame Pointer register to see ](https://developer.apple.com/videos/play/wwdc2015-412/?time=714)[where the base of that function's frame is ](https://developer.apple.com/videos/play/wwdc2015-412/?time=718)[and find the return address of who called it.](https://developer.apple.com/videos/play/wwdc2015-412/?time=721) \n\n### Backtrace \n\nSo, what is Backtrace? Well,  by using frame pointer that was pushed on the stack,  we know the the base address of the caller’s stack frame. Since every call frame of the method has store the base address  of its caller's stack frame, we can use this to go through the chain of the call frames in this stack.  \n\n<img src=\"/image-20200805094837070.png\" alt=\"image-20200805094837070\" style=\"zoom:50%;\" />\n\n### Optimized case \n\nIn `drawRect`, after calling `CGContextDrawPath` , it is going to  `return`, which means actually it will `pop stack frame`, `restore fp`, and then `jump back to caller` . \n\n<img src=\"image-20200805231739717.png\" alt=\"image-20200805231739717\" style=\"zoom:50%;\" />\n\nSince `CGContextDrawPath` needs nothing from `drawRect`, the params it needs arn't from the call frame of `drawRect` , the compiler does an optimization here.  It rearranges the code as follow. I `pops stack frame` of `drawRect` firstly, `restores fp`,  then calls  `CGContextDrawPath` . So it doesn't have to `jump back to caller`  , the address stored in the `lr` register. \n\nFigure 1. it is going to  `pops stack frame`\n\n![image-20200805232447437](image-20200805232447437.png)\n\nFigure 2. after  poping stack frame of `drawRect`, the call frame of drawRect doesn't exist on the Stack any more.  Then `sp` moves.\n\n![image-20200805232642308](image-20200805232642308.png)\n\nFigure 3. after restoring `fp` to the base address of its caller's frame pointer, the `return address` and `frame ptr` of `drawRect` don't exist on the Stack any more.  Then `sp` moves.\n\n![image-20200805232724011](image-20200805232724011.png)\n\nFinally, it calls `CGContextDrawPath`, which establish its own call frame on the Stack. So, the stack is like this now. \n\n```assembly\n+0x76 b.w \"CGContextDrawPath$shim\"\n```\n\n<img src=\"image-20200805234014273.png\" alt=\"image-20200805234014273\" style=\"zoom:50%;\" />\n\n### The difference in the Call Tree \n\nThe left side is the normal case, the right side is the optimized case where then call frame of `drawRect` will be removed from the stack in the optimized case. It looks like `CGContextDrawPath` is directedly called from `drawLayout:inContext` .\n\n![image-20200805234610955](image-20200805234610955.png)\n\n### The benifit of Tail call Elimination \n\n- Saves stack memory \n- Keeps caches hot, and reuses the memory\n- Best for recursive function tail calls, especially `tail call recursive code`, where a function or method calls itself as the last line of code and then returns.  With Tail call Elimination, the stack won't grow so much that we can get hight performances.\n\n### Disabling\n\nset this compiler flag when building,  you can get better call tree in the Time Profiler when profiling app. \n\n- CFLAGS=“-fno-optimize-sibling-calls\"\n\n### Call Semantics\n\nThere is a useful trick to indentify if this is a Tail call Elimination case. That is to\n\n`look at the disaeembly and call sight of the last call`\n\n![image-20200806092252238](image-20200806092252238.png)\n\n- In normal call, it uses `a Branch and Link family of instructions` (bl)\n\n  - Sets `lr` to  next address and jumps to the caller\n\n    ```assembly\n    Caller: +0x174 blx \"CGContextDrawPath $shim”\n    ```\n\n- In optimized call, Tail Calls use `simple branches` (b) , directedly jump into the function\n\n  ```assembly\n  Caller: +0x174 b.w \"CGContextDrawPath $shim”\n  ```\n\n  ","tags":["Debug","LLDB"],"categories":["iOS"]},{"title":"Behind the Scenes of the Xcode Build Process","url":"/2020/07/05/20200705Behind-the-Scenes-of-the-•Xcode-Build-Process/","content":"\n> Most contents come from https://developer.apple.com/videos/play/wwdc2018/415 \n\nThe new building system introduced in Xcode 10 is written by Swift from scratch, and brings lots of improved performance and reliability.  So what happens when we press `CMD + B` in Xcode? \n\nIn general, Xcode has to do tasks like preprocess source files and compile them by compiler,  link source code by linker, copy and process resources like headers, asset catalogues and storyboards, And finally code sign and maybe even do some custom work in a shell script or a make file like building API documentation for your framework or running code linting and validation tools.\n\n![image-20200705224132928](image-20200705224132928.png)\n\n## Build Task dependency and execution order \n\nBuilding tasks are executed in a particular order. \n\n<img src=\"image-20200705170528761.png\" alt=\"image-20200705170528761\" style=\"zoom:50%;\" />\n\nThe building system use the dependency information to determine which tasks should be run and what task can be run in parallel.  This is called `dependency order`.  \n\n We know that a compiler can produce `.o` files from `.m` files. Then a linker consumes a number of object files and produces executable or library output. The following graphic shows the dependency info between compilation and linking tasks.  \n\n![image-20200705170723485](image-20200705170723485.png)\n\n### Build tasks are executed in dependency order \n\n1. The  building system will process the project and represented building tasks as a Directed Graph \n\n> What happens when you press build? So the first step is for the build system to take the build description, your Xcode project file.Parse it, take into account all the files in your project, your targets and the dependency relationships.Your build settings, and turn it into a tree-like structure called a directed graph.\n>  And this represents all the dependencies between the input and output files in your project and the tasks that will be executed to process them.\n\n![image-20200705172316201](image-20200705172316201.png)\n\n2. Then the low-level execution engine get the dependency specifications from the above graph and figures out which tasks to execute.\n\n   <img src=\"image-20200705225725510.png\" alt=\"image-20200705225725510\" style=\"zoom:80%;\" />\n\n### Discovered Dependencies \n\nWhen clang compile `PetController.m` source file into object file, `PetController.d` file  is also generated, which contains a listing of information about which header files were included by that source file. Next time you build, if you change any of the header files that `PetController.d` includes, the building system will recompile `PetController.m`. \n\n<img src=\"image-20200705225819662.png\" alt=\"image-20200705225819662\" style=\"zoom:50%;\" />\n\n\n\n### Incremental builds\n\nHaving accurate dependency information is very important in order for incremental builds to work correctly and efficiently, in this case,  the build system only execute a subset of the tasks on the building tasks graph\n\n**how does the build system actually detect changes?**\n\n1. Each time in the building graph has a signature, which computed from stat info of inputs and other task metadata. \n2. Building system tracks signatures of current and previous build, and compared them to determine whether a task should be run. \n\nFor example, in the following picture, building system only has to run these 3 highlight tasks when only `PetViewVontroler.m` changed\n\n![image-20200705231435967](image-20200705231435967.png)\n\n## How can we help the build system? \n\nThe answer is to handle the dependency properly so that the build system can order tasks correctly and build in parallel to save time. \n\n#### Where do dependencies come from? \n\n- Built in. The build system ships with rules for the compiler, the linker, the asset catalogue and story board processors and so on.\n   And these rules define what kind of files are accepted as inputs as well as what outputs are produced.\n\n- Target dependencies, which roughly determine the order in which targets are built.\n\n  <img src=\"image-20200705232141133.png\" alt=\"image-20200705232141133\" style=\"zoom:50%;\" />\n\n- Implicit dependencies \n\n  <img src=\"image-20200705232159289.png\" alt=\"image-20200705232159289\" style=\"zoom:50%;\" />\n\n- Build phase dependencies.  The tasks associated with each of these phrases are usually running groups according to the order in which the phases are listed. But the build system might ignore that order if it knows better.\n\n  <img src=\"image-20200705232220121.png\" alt=\"image-20200705232220121\" style=\"zoom:50%;\" />\n\n- Scheme order dependencies. \n\n  If you have the parallelize build check box enabled in your scheme settings, you get better build performance and the order of your targets in your scheme doesn't matter.  However, if you turn parallelize build off, Xcode will attempt to build their, your targets in the order you listed them in the build action of the scheme one by one.\n  <img src=\"image-20200705232238281.png\" alt=\"image-20200705232238281\" style=\"zoom:50%;\" />\n\n#### What we can do? \n\n- Declare inputs and outputs to help the build system avoid rerunning the script tasks unnecessarily\n\n  <img src=\"image-20200705232718754.png\" alt=\"image-20200705232718754\" style=\"zoom:50%;\" />\n\n- Avoid Auto-link for project dependencies.  \n\n  > This setting allows the compiler to automatically link to the frameworks corresponding to any modules you import without having to explicitly link them in your link library's build phase. However, it's important to note that auto-link does not establish dependency on that framework at the build system level. So it won't guarantee that the target you depend on is actually built before you try to link against it.\n\n  <img src=\"image-20200705232921705.png\" alt=\"image-20200705232921705\" style=\"zoom:50%;\" />\n\n- Add explicit dependencies \n-  You might also need to create project references by dragging and dropping another Xcode project into your project's file navigator in order to reveal the targets of other projects you depend on.\n\n## [Clang compiler](https://clang.llvm.org/)\n\n### Header map \n\n> `Header map` is used by the Xcode build system to know where the header files are.\n\nIn Objective-C, a header file is a promise, saying that the implementation exists somewhere else. If you only update the `header` file, adding a new function A,  without implementation of the function in `m` file, you broke your promise. Then you use function A in class B.   This doesn't break during compile time, because compiler trusts the promise, saying that there is a function A symbol exists, but during link,  we usually got `symbol undefined` error. \n\n### 1. How does Clang find your header files? \n\nWe can copy the arguments from the Xcode building log when Clang compiles a single `.m` file, then using command line to see more details. \n\n<img src=\"image-20200705234147883.png\" alt=\"image-20200705234147883\" style=\"zoom:50%;\" />\n\n```\n clang <list of arguments> -c Cat.mm -o Cat.o -v\n```\n\n\n\nFirst, Clang will start searching the header in header map files. \n\n<img src=\"image-20200705234506914.png\" alt=\"image-20200705234506914\" style=\"zoom:50%;\" />\n\n<img src=\"image-20200705234528306.png\" alt=\"image-20200705234528306\" style=\"zoom:50%;\" />\n\n#### What are header maps \n\n<img src=\"image-20200705234700573.png\" alt=\"image-20200705234700573\" style=\"zoom:50%;\" />\n\n\n\nIn the header map, for the first two keys `PetKit.h` and `Cat.h` , it just simply append the framework name, make them as `PetKit/PetKit.h` and `PetKit/Cat.h`. This keep existing projects working when you use `import <Cat.h>` or `import Cat.h`,  but there might be issues down the road with Clang modules.  So it is recommended that you always `specify the framework name` when you include a public or private header file from your own framework. \n\n#### Suggestion for importing headers explicitly in your source code to help Clang find the header:  \n\n- Always explicit a framework name when you introduce a public and private header \n- always add the header to the project \n- Always use unique name for header avoid shadowing other headers \n\n### 2. How does Clang find system header files? \n\n`Headermap` is only for developers' code. So, in the case of finding system header files, Clang focus on two directories. \n\n```\n$(SDKROOT)/usr/include \n$(SDKROOT)/System/Library/Frameworks.(framework directory).\n```\n\nTake `import <Foundation/Foundatoin.h>` as an example, Clang appends `Foundation/Foundation.h` to the `(SDKROOT)/usr/includ`, and search the header in this path.\n\n```\n$(SDKROOT)/usr/include/Foundation/Foundation.h\n```\n\nIf it doesn't find the header under `$(SDKROOT)/usr/include ` ,  it continues to find header file in framework directory. \n\n```\n$SDKROOT/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h\n```\n\n### Process your file \n\nXcode -> Product ->. Perform Action -> Preprocess \"\". This is the action to create preprocessed file for us, where the `import ...`  statement is substituted with the contents of that file.\n\n```\n#import <Foundation/Foundation.h>\n```\n\nClang has to find and process over 800 header files for this single include statement. That's over 9 megabyte of source code that has to be parsed and verified.\n\nAfter preprocessing: \n\n![image-20200706000118839](image-20200706000118839.png)\n\nHow does Clang do to avoid these redundant and heavy job?  \n\n### Clang module  \n\nTo speed up the building,  by using module, Clang can parse the header only once and store the information `in the disk`, then `reuse the cache` next time. \n\n In order to achieve this, Clang module should have  properties. \n\n- Context-free \n\n  ignore the context-related statement. Like, macro definitions\n\n  ![image-20200706091410725](image-20200706091410725.png)\n\n- Self-contained \n\n  have to specify all the dependencies.\n\n#### Module Map \n\n> A Module Map describes how a certain set of header files translate onto your module.\n\nThis is the `module map` file for Foundation.framework. \n\n<img src=\"image-20200706092447210.png\" alt=\"image-20200706092447210\" style=\"zoom: 50%;\" />\n\n- It obviously describes what is the name of the module which is, Foundation.\n\n- it also specifies what headers are part of this module.  `Foundation.h` is a umbrella header.  If you want to find `NSString` header, you have to look into `Foundation.h` file. \n\n  <img src=\"image-20200706091927374.png\" alt=\"image-20200706091927374\" style=\"zoom:50%;\" />\n\n#### Build Module \n\nWhile building the foundation module, we have to build its dependency too. \n\n<img src=\"image-20200706095037818.png\" alt=\"image-20200706095037818\" style=\"zoom:50%;\" />\n\n#### Module Cache\n\n```\n$ clang -fmodules —DENABLE_CHINCHILLA=1 ...\n```\n\nThe command line arguments for building a module can affect the content of your module. Clang will hash all those arguments and store the modules we created for this particular compiler invocation in a directory matching that hash.\n\n<img src=\"image-20200706095441247.png\" alt=\"image-20200706095441247\" style=\"zoom:50%;\" />\n\n## How about Swift \n\nWhen compiling Objective-C files,  the compiler compiles each file separately and in parallel, by process the `import` statement, and then compiling the file. As we know, unlike Objective-C, Swift doesn't have headers. So First, the compiler has to find declarations both within the Swift target and also coming from Objective-C.  Further, it has to generate interfaces describing the contents of the file. \n\n### Finding declarations \n\n- Within a Swift target \n\n  In the following example, the compiler will check the type in the `PetView`'s initializer ', firstly, it parses the `PetView` and knows the declaration of the initializer is well formed. And then, it checks the call inside the \tPetViewController`. \n\n![image-20200709093711492](image-20200709093711492.png)\n\n​\tSo, actually, when compiling one Swift file, the compiler will parse all the other Swift files in the target. When compiling files separately and in parallel, it causes repeated parsing all files to find declarations.\n\n#### ![image-20200709095907259](image-20200709095907259.png)\n\n In order to improve performance, Xcode 10 combines the files into groups to reuse parsing within a group, and only repeat parsing across groups.\n\n![image-20200709095800665](image-20200709095800665.png)\n\n- Find declarations from Objective-C \n\n  In fact, `Swiftc` compiler embeds `clang`, so   we can can import clang frameworks directly\n\n  > 1. In any target, when you import an Objective-C framework, the importer finds declarations in the headers exposing Clang's module map for that framework.\n  > 2. Within a framework that mixes Swift and Objective-C code, the importer finds declarations in the umbrella header.\n  > 3. Within applications and unit test bundles,  you can find declaration from the target's bridging header.\n\n### Generating interface \n\n- How your Objective-C header will be imported into Swift\n\n  In this `PetViewController.h`, you use the button in the top-left corner of the source editor, see `generated interface`. \n\n  ![image-20200710110626097](image-20200710110626097.png)\n\n- To use Swift in Objective-C \n\n  ![image-20200710112907949](image-20200710112907949.png)\n\n  - For classes extending NSObject and methods/properties marked `@objc`\n  - Apps and unit tests: both public and internal declarations\n  - Frameworks: Only `public declarations`\n  - Compiler ties Objective-C class to mangled Swift class name. The Objective-C name includes the module name `PetWall` . This is to prevent conflict when two modules define class with same name\n  - You can also use `@objc(Name`) to provide custom name — but must not conflict!\n\n- To use Swift in other Swift targets\n\n  - Must firstly import other modules to see their declarations, because in Swift, a module is a distributable unit of declarations.\n\n  - Can import Objective-C modules. \n\n  - In Xcode each `Swift target` produces `a separate module`, so your app target does.\n\n### swfitmodule vs header\n  `swfitmodule` file is serialized, binary representation of module’s declarations, which will be deserialised by compiler  to check the types when you use them. So this `swfitmodule` is a bit like `like a generated Objective-C header`. But instead of text, it's a binary representation. Besides, it does include the names and types of `private declarations` so that we can refer to them in the debugger. In addition, it includes the `bodies of inlineable`functions`,  like `static inline function`s in Objective-C  header\n\n    ![image-20200710113202143](image-20200710113202143.png) \n\n  ![image-20200709100603559](image-20200709100603559.png)\n\n   For incremental builds, the compiler produces partial Swift module files and then `merges` them into a single `swift module` file, and  a single Objective-C header. \n\n### In summary:\n\n- Swift uses Objective-C declarations by Bridging header.\n- Objective-C uses Swift declarations by Generated header.\n- In Objective-C Clang find where the header file is by header map files.  \n- In Swift, `swfitmodule` is a bit like like a generated Objective-C header\n\n![](generated_header.png)\n\n## Linker \n\n### What is Linker? \n\nLinking is the final task in building an executable Mach-O. What it does it to combine the output of all compiler invocations into a executable. \n\nTake two kinds of input files \n\n- Object files (`.o`)\n- Libraries (`.dylib`, `tbd`, `.a`)\n\n###  Symbols \n\n> A symbol is a name for a fragment of code or data, which may reference other symbols. \n\n- Symbols can have attributes on them that alter the linker’s behavior, like `Weak symbols`. \n\n- Languages often encode data into a symbol `mangling` the symbol\n\nweak symbols \n\n### Object Files \n\nObject file, `.o` file is the output of individual compiler actions. A non-executable Mach-O file containing code and data fragments. \n\n- Each fragment is represented by a symbol. \n- Fragment may reference `undefined` symbol. \n\n### Libraries\n\n>  Libraries define symbols that are not built as part of your target\n\n- Dylibs: Dynamic libraries\n\n  - Mach-O file that exposes code and data fragments for executables to use. Those are distributed as part of the system,  and a number of you also use your own frameworks\n\n- TBDs: Text Based Dylib Stubs\n\n  - Only contains symbols. \n\n    1. a stub dylib  where we delete the bodies of all of the symbols and we just have the names.\n    2. a textual representation of them that are easier for us to use\n\n    ```\n    ---\n    archs:           [ armv7, armv7s, arm64 ]\n    platform:        ios\n    install-name:    /usr/lib/libsqlite3.dylib\n    current-version: 216.4\n    compatibility-version: 9.0\n    exports:         \n      - archs:           [ armv7, armv7s, arm64 ]\n        symbols:         [ __sqlite3_lockstate, __sqlite3_purgeEligiblePagerCacheMemory, \n                           __sqlite3_system_busy_handler, __sqlite_auto_profile, \n                           __sqlite_auto_profile_syslog, __sqlite_auto_trace, \n                           __sqlite_auto_trace_syslog, _sqlite3OsShmHasMultipleLinks, \n                           _sqlite3OsShmRenamedWhileOpen, _sqlite3OsShmWasTruncated, \n                           _sqlite3OsShmWasUnlinkedWhileOpen, _sqlite3VersionNumber, \n    ```\n\n    from [stackoverflow](https://stackoverflow.com/questions/31450690/why-xcode-7-shows-tbd-instead-of-dylib)\n\n- Static archives\n\n  - An archive of multiple `.o` files built with the archive tool. `ar` tool. [ar](https://linux.die.net/man/1/ar)\n  - It ends with `.a` suffix, and is something like ZIP or TAR archive.\n  - Only the `.o` files with symbols you reference are included in your app\n\n  see more  [here](https://www.vadimbulavin.com/static-dynamic-frameworks-and-libraries/)\n\n### Example \n\nThe left side is the source, the right side is the object file.  \n\nFirstly, let's look at the `purrFile` variable, it is `static`  , and  `nonexported` name.  So it doesn't appear in the object file.  \n\n<img src=\"image-20200710150601150.png\" alt=\"image-20200710150601150\" style=\"zoom:50%;\" />\n\nThen, here comes  an actual symbol `-[Cat purr]`. \n\n![image-20200710150636666](image-20200710150636666.png)\n\nThen, we see two instructions to pass the variable `purrFile` into `playSound` function. It is because,  we don't have concrete address for  `purrFile` and we don't know where this string is going to end up in the final executable.  But in  `ARM64`, it could take at most two instructions.  \n\n-  [adrp](https://developer.arm.com/documentation/dui0802/b/A64-General-Instructions/ADRP) \n\nSo the compiler leaves the symbolic values `PAGE` and `PAGEOFF` that the linker will come in and fix up later.\n Finally,  we've loaded that string into register  `x0` . \n\n![image-20200710150648959](image-20200710150648959.png)\n\n`__Z9playSoundPKc`  is a C++ `demangle symbol`  \n\n![image-20200710150707825](image-20200710150707825.png)\n\n\n\n![image-20200710154006829](image-20200710154006829.png)\n\nWhen linking, linker takes a number of object files as input, and create a file to put them in.  In the `__TEXT` segment, it copies the executable code from the object file.  Then, in another segment, it copy the string. Now, the linker knows the absolute addresses of the string symbol, it will rewrite the instruction using a specific address. Meanwhile, the second instruction just went away, it replaced it with a null instruction `that does nothing`. [nop](https://developer.arm.com/documentation/dui0802/b/A64-General-Instructions/NOP?lang=en)\n\n\n\n![image-20200710154246392](image-20200710154246392.png)\n\n Then the linker has to resolve the `undefined symbol`, `__Z9playSoundKc`.  \n\n<img src=\"image-20200710155242689.png\" alt=\"image-20200710155242689\" style=\"zoom:50%;\" />\n\nWe start looking through the `.o` file in the `.a` archive file, and found out matching symbol for `playSound`. Then, linker put this symbol into the `PetKit`.   While copying code, it rewrite`_open` symbol as `_open$stub`. Why? because `_open` is in the lib system TBD file, which means it is in the system library. The linker needs to put more information in the Application executable file to make it call this function properly. \n\nSo, it makes a fake function, `_open$stub`  , where it actually loads from the`$open` pointer and jumps to it. \n\n- [bl](https://developer.arm.com/documentation/dui0802/b/A64-General-Instructions/BL?lang=en)\n- `ldr` (load register) loads data from a memory location into a register. \n- [br](https://developer.arm.com/documentation/dui0802/b/A64-General-Instructions/BR?lang=en)\n\n![image-20200710160920246](image-20200710160920246.png)\n\n![image-20200710161911500](image-20200710161911500.png)\n\n- [Building faster in Xcode](https://developer.apple.com/videos/play/wwdc2018/408)\n- [build time optimization](https://www.onswiftwings.com/posts/build-time-optimization-part1/)\n- [The build process](https://www.objc.io/issues/6-build-tools/build-process/)\n- [The compiler](https://www.objc.io/issues/6-build-tools/compiler)\n- [swift-llbuild](https://github.com/apple/swift-llbuild)\n- [Understanding Xcode Build System](https://www.vadimbulavin.com/xcode-build-system/)\n- [iOS Assembly Tutorial](https://www.raywenderlich.com/2705-ios-assembly-tutorial-understanding-arm#toc-anchor-001)\n","tags":["LLDB","Building"],"categories":["iOS"]},{"title":"Advanced debug in Xcode and LLDB","url":"/2020/06/07/20200607-Advanced-debug-in-Xcode-and-LLDB/","content":"\n# Advanced debug in Xcode and LLDB \n\nhttps://developer.apple.com/videos/play/wwdc2018/412 \n\nThis session is awesome! \n\n## Configure behaviors to dedicate a tab for debugging\n\nIn `Prefernece` -> `Behaviors` ,  we can custom the debugging tab for ourselves. For example, choose `Show tab named` , fill in the name and choose `active window` . We will have a independent debug tab. \n\n![image-20200601222857985](412/image-20200601222857985.png)\n\n\n\n<img src=\"media/15902152252875/image-20200607112605302.png\" alt=\"image-20200607112605302\" style=\"zoom:50%;\" />\n\n## LLDB expressions can modify program state\n\nBy using  auto-continuing breakpoints with debugger commands to inject code live, you can inject expression, change state or logic without compiling the project.  \n\n**How to do it? **\n\n- Click `Edit BreakPoint...`\n\n- Click `add action` ; the default option is `Debugger Command`  we can write some `LLDB` command here\n\n- Choose the `Automatically continue`, it will not pause when trigger this breakpoint. \n\n  \n\n  <img src=\"media/15902152252875/image-20200607111532596.png\" alt=\"image-20200607111532596\" style=\"zoom:50%;\" />\n\n\n\n<img src=\"media/15902152252875/image-20200601224246210.png\" alt=\"image-20200601224246210\" style=\"zoom:50%;\" />\n\n\n\n## Symbolic Breakpoint \n\n`Symbolic Breakpoint` is one of my favorite tools to debug issues caused by others' framework.\n\nIn the  `Breakpoint navigator` , choose `Symbolic Breakpoint` .  \n\n<img src=\"412/image-20200607113135963.png\" style=\"zoom:50%;\" />\n\nFill in any signature of the `Objective-c` method you want. \n\n<img src=\"412/image-20200607113105829.png\" style=\"zoom:50%;\" />\n\n## “po $arg1” ($arg2, etc) in assembly frames to print function arguments\n\n<img src=\"412/image-20200601224622911.png\" style=\"zoom:50%;\" />\n\nIn this case,  we use `Symbolic Breakpoint` to hit the `setText:` in `UILabe`, but we don't have the source code of `UIKit`. When the method is hit, we are in an assembly frame, we can use `$arg` to inspect the parameters.  `$arg1` is `self` pointer. `$arg2` is the  `selector` of the method. Others are  arguements to the method. [doc for objc_msgSend](https://developer.apple.com/documentation/objectivec/1456712-objc_msgsend#parameters)\n\n<img src=\"media/15902152252875/image-20200601224723843.png\" style=\"zoom: 50%;\" />\n\n\n\n**Noted**:  we have to do typecast for the `$arg2` , which is a `Slector` . \n\n<img src=\"media/15902152252875/image-20200601224918951.png\" alt=\"image-20200601224918951\" style=\"zoom:50%;\" />\n\n## Create dependent breakpoints using “breakpoint set --one-shot true”\n\nIf a Breakpoint is frequently hit, Like the above breakpoint `[UILabel setText:]`,  usually we will edit `conditions` for this breakpoint. And then, this `Breakppint` will be hit only when the expression for the condition is true.  However, when we don't a property to make the `condition expression`.   There is another way.  We can add action `one-shot symbolic breakpoint` in `a specific breakpoint`, where it will be hit only once in the proper time. \n\n>  The one shot breakpoint is a temporary breakpoint that only exists until it's triggered and then it's automatically deleted.\n\n\n\n<img src=\"media/15902152252875/image-20200607115734569.png\" alt=\"image-20200607115734569\" style=\"zoom:67%;\" />\n\n- Set  a break point in line 96, where we might don't want a break, but we can `configure this breakpoint` to actually set the `symbolic breakpoint` in UI label set text . \n- choose `automatically continue` \n\n- Then add action , `breakpoint set --one-shot true --name \"[UILabel setText:]\"`.  This `one-shot symbolic breakpoint` is activated only after this breakpoint in line 96 is hit.  \n\n\n\nHow magical the dependent breakpoints are!\n\n\n\n## Skip lines of code \n\nBy `dragging` Instruction Pointer, the green handler in the following picture,  we can skip lines of code. It means, these lines of  code will not be executed. \n\n![image-20200607123358909](media/15902152252875/image-20200607123358909.png)\n\n\n\nOr we can use `action` int the breakpoint to skip this line of code for us. \n\n<img src=\"media/15902152252875/image-20200607123639829.png\" alt=\"image-20200607123639829\" style=\"zoom:50%;\" />\n\n\n\nAfter doing that, we can add `expression` to add new expressions, like calling other functions. \n\n<img src=\"media/15902152252875/image-20200607123845152.png\" alt=\"image-20200607123845152\" style=\"zoom:50%;\" />\n\n\n\n## Pause when variables are modified by using watchpoints\n\n\n\n- filter the variable we want using `fitler` \n- click `Watch attempts` \n\n<img src=\"412/image-20200607124534515.png\" style=\"zoom:50%;\" />\n\nThen, we create a `Watchpoint` , which can be seen in the `breakpoint navigator`\n\n<img src=\"412/image-20200607124622132.png\" style=\"zoom:50%;\" />\n\n## Evaluate Obj-C code in Swift frames with `expression -l objc -O -- <expr>`\n\nIn swift frames, we can't use `pointers` or private func as we do in  obj-c frames. So here comes ``expression -l objc -O -- <expr>`.  This can help use them as we do in obj-c frames.  \n\n```\n// In swift\nexpression -l objc -O -- [`self.view`  recursiveDescription]\n\n// In Obj-c \n[self.view  recursiveDescription]\n```\n\nBy using the  `command alis` , we can short cut it. \n\n```\ncommand alis poc expression -l -objc -O --\n```\n\n![image-20200607141219843](media/15902152252875/image-20200607141219843.png)\n\n\n\n## Flush view changes to the screen using “expression CATransaction.flush()”\n\n#### unsafeBitCast\n\nWe can use `unsafeBitCast`  in Swift.  To do the type cast, we have to provide the correct type. \n\nPrint its property or change its property: \n\n![image-20200607142019406](media/15902152252875/image-20200607142019406.png)\n\nUse `CATransaction.flush` to apply the view module changes to the screen's frame buffer. \n\n## Add custom LLDB commands using aliases and scripts. Alias examples:\n\n- download nudge LLDB script provided by the Apple. https://developer.apple.com/videos/play/wwdc2018/412/ \n- Add to `~/.lldbinit`\n- Add  custom alias in the lldbinit\n\n![image-20200607143100209](media/15902152252875/image-20200607143100209.png)\n\n```\ncommand alias poc expression -l objc -O --\ncommand alias flush expression -l objc -- (void)[CATransaction flush]\n```\n\n## Customizing Data Formatters\n\nhttps://developer.apple.com/videos/play/wwdc2019/429","tags":["Debug","LLDB"],"categories":["iOS"]},{"title":"Beyond \"po\"","url":"/2020/06/07/20200607-beyond-po/","content":"\n> https://developer.apple.com/videos/play/wwdc2019/429 \n\n## po command\n\nWe usually use `po` to print object description, which does the same job as `expression --object-description`. \n\n### Alias the command  \n\nWe can also use `command alias` to custom it. like \n\n`command alias my_po expression --object-description` ![img](15902187135968.jpg)\n\n### Custom the output  \n\nWe can add `debugDescription` to custom the output when using `po`\n\n![image-20200607171902758](image-20200607171902758.png)\n\n### Others jobs po can do \n\n![image-20200607172607792](image-20200607172607792.png)\n\n\n### What LLDB does behind the `Po` command\n\n![img](15902307367967.jpg?lastModify=1591521218)\n\n## p command\n\n```\np is a alias of `expression\n```\n\n![-w398](15902310620901.jpg?lastModify=1591521218)\n\nThe result of LLDB is given a increasing name, such as `$R1` and `$R2` \n\n![-w509](15902311269458.jpg?lastModify=1591521218)\n\n## Dynamic type resolution\n\n![img](15902347284185.jpg?lastModify=1591521218)\n\n> In Swift, the static representation of a type in the source code and the dynamic type at the runtime, aren't necessarily the same. For example, a variable might be declared using a protocol of this type. In this example, the static type of `cruise` is `Activity`. But at runtime, the variable will have an instance of type `Trip` which is the dynamic time. If we print the value of `cruise`, we get back an object of type `Trip` because LLDB retell results metadata to display the most accurate type for a given variable at a given program point. This is what we call `dynamic type resolution`.\n\nWith the p-command, dynamic type resolution is `only` performed on the result of the `expression`.\n\nThis happens because if you remember, LLDB compiles code where running p and the only type it sees is the one in your source code, the static one. It's the same thing as typing the expression `cruise.name` in your source code. The static compiler will reject it with an error.  ![-w1104](15902348043124.jpg?lastModify=1591521218)\n\nIf you want to evaluate the expression without errors, you need to first cast the object explicitly to its dynamic type and then access the field on the result. This is true both for the debugger and your source code.\n\n![img](15902348340793.jpg?lastModify=1591521218)\n\n### “p” Under the Hood\n\n![img](15902348740856.jpg?lastModify=1591521218)\n\n### Formatter \n\nAfter it performed `dynamic type resolution` on the result, LLDB passes the resulting object to the `formatter subsystem` which is the part of LLDB responsible for printing a human readable description of objects.\n\n![-w850](15902349355474.jpg?lastModify=1591521218)\n\n## v Command\n\n- The output of `v` is exactly the same as `p` as it also relies on the formatter we just described.\n- `v` is just an alias we introduced in Xcode 10.2 for the `frame` variable command\n- The v-command doesn't compile and execute code at all which makes it very fast.\n\n![img](15902351819724.jpg?lastModify=1591521218)\n\n### v under the hood \n\n![img](15902354049114.jpg?lastModify=1591521218)\n\n### frame command\n\n![-w799](15902352051371.jpg?lastModify=1591521218)\n\n## po vs p vs v\n\n![-w1306](15902354519154.jpg?lastModify=1591521218)\n\n","tags":["Debug","LLDB"],"categories":["iOS"]},{"title":"Anchor point for 3D Transform in React Native","url":"/2020/05/15/20200515-react-native-anchor-point/","content":"\n## What is Anchor Point \nWeb developers may be familiar with `transform-origin` in css. While in iOS, there is something similar called `anchor point`. \n\n`Anchor point` in a view is a point in the unit coordinate space, about which all geometric manipulations to the view occur. \n\n> Defines the anchor point of the layer's bounds rectangle. Animatable. \n> You specify the value for this property using the unit coordinate space. The default value of this property is (0.5, 0.5), which represents the center of the layer’s bounds rectangle. `All geometric manipulations to the view occur about the specified point`. For example, applying a rotation transform to a layer with the default anchor point causes the layer to rotate around its center. Changing the anchor point to a different location would cause the layer to rotate around that new point.                -- [Apple dev](https://developer.apple.com/documentation/quartzcore/calayer/1410817-anchorpoint)\n\nBy default, the anchor point for the rotation is the center of the view. That means the rotation of a view is based on its center. Inspired by this [article](https://commitocracy.com/implementing-foldview-in-react-native-e970011f98b8#.k95f793qe), which teaches us how to rotate a view based from the origin point, I got an important clue to implement the anchor point.  \n\n### Why do we need anchor point in react-native\n\n1. Currently, there is no public API in react-native providing the ability to set `transform-origin` or `anchor-point`. So you will find it is difficult to do some fancy 3D transform animations. For example, [cube animation](https://www.npmjs.com/package/react-native-cube-transition) has some flaws: \n    - There is a gap between the views when translating views in Android \n    - The angle is not correct, less than 90 degrees, make the animation wired. It is not a cube, if you try to adjust the angle, you will break all the things. \n    - part of the view is clipped, not rendering on the screen. \n![image2020-5-27_17-17-21](https://user-images.githubusercontent.com/7471672/84166299-4c06dd00-aaa7-11ea-8c48-4e401c756767.png)\n\nActually, I use this function to solve all these issues. But it is code for company, I can't make it public. The key thing is to set anchor point as (1, 0.5) for the left view and (0, 0.5) for the right view. \n![image](https://user-images.githubusercontent.com/7471672/84166384-63de6100-aaa7-11ea-8102-9de5bee4cf18.png)\n\n2. Beside, for this foldview animation [foldview-in-react-native](https://commitocracy.com/implementing-foldview-in-react-native-e970011f98b8), one of the most import things is to use [`transformOrigin`](https://github.com/jmurzy/react-native-foldview/blob/892f89569cd851867602ce7412852515dccc7e5f/src/transformUtil.js#L3). But, this function works with `transform matrix`, and isn't easy to use. So, I made `react-native-anchor-point`. It looks simple and tricky, but actually very powerful. With it, you can use the transform API in react-native to achieve many fancy animations.\n\n\n### transformOrigin in react-native-foldview\n\n> “Since the transform origin of a view is at its horizontal and vertical center by default, to rotate it in x-space along the bottom, we need to first shift our view’s origin on the y-axis by 50% of the view’s height, then apply rotation, then shift it back to the original center.” — [@jmurzy](https://commitocracy.com/implementing-foldview-in-react-native-e970011f98b8)\n\nSo @jmurze implemented a [function]\n(https://gist.github.com/jmurzy/0d62c0b5ea88ca806c16b5e8a16deb6a#file-foldview-transformutil-transformorigin-js)\n\n```js\nfunction transformOrigin(matrix, origin) {\n  const { x, y, z } = origin;\n\n  const translate = MatrixMath.createIdentityMatrix();\n  MatrixMath.reuseTranslate3dCommand(translate, x, y, z);\n  MatrixMath.multiplyInto(matrix, translate, matrix);\n\n  const untranslate = MatrixMath.createIdentityMatrix();\n  MatrixMath.reuseTranslate3dCommand(untranslate, -x, -y, -z);\n  MatrixMath.multiplyInto(matrix, matrix, untranslate);\n}\n```\nHere\n-  `reuseTranslate3dCommand` in the [react-native source code](https://github.com/facebook/react-native/blob/a1ac2518a364ebcd3cc024a22229cadc1791e1c4/Libraries/Utilities/MatrixMath.js#L95), is to replace the 12th, 13th, 14th element in the matrix by parameters, z, y, z to achieve `translation` effect. \n- `reuseTranslate3dCommand` is called in [processTransform.js#L79](https://github.com/facebook/react-native/blob/a1ac2518a364ebcd3cc024a22229cadc1791e1c4/Libraries/StyleSheet/processTransform.js#L79), in which, RN generates a transform matrix based on `transform object` we provide. \n[https://github.com/facebook/react-native/blob/a1ac2518a364ebcd3cc024a22229cadc1791e1c4/Libraries/StyleSheet/processTransform.js#L43]\n\n### What `transformOrigin` does is to\n\n```\n1. translate the view by x, y, z on the x-axis, y-axis, z-axis \n2. apply rotation\n3. translate the view back by -x, -y, -z on the x-axis, y-axis, z-axis \n```\n\n\n### Plain Code\n\nAfter understanding the above things, we know we can can use `transform` style to set the anchor point. For example, the following code sets the anchor point of the view as (0, 0.5). This will make the rotate base on the left side of the view. \n\n```javascript\n   const transform = {\n      transform: [\n          {translateX: -w / 2}, \n          rotateY, \n          {translateX: w / 2}\n      ]\n    }\n    return (   \n        <Animated.View style={transform}></Animated.View>\n    )\n  }\n\n```\n![](./d32bef61.png)\n\nRemember that RN generates only one single transform matrix, based on `transform object` we provide, [here](https://github.com/facebook/react-native/blob/a1ac2518a364ebcd3cc024a22229cadc1791e1c4/Libraries/StyleSheet/processTransform.js#L43). So, finally, the above code will be converted into a transform matrix, with which the rendering system can render a view with a given layout and shape.  There are some transform matrix knowledge involved. [ref: tutorial-3-matrices](http://www.opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices/)\n\n\n## react-native-anchor-point\n\nIn this [package](https://github.com/sueLan/react-native-anchor-point), I provides a function `withAnchorPoint`, to inject the above code into your `transform` object. It works well with the original way you use transform and. So, you don't have to use `ref` to set the `transformOrigin` any more. This would make the `3d transform` in React Native easier to implement. \n\n![](./rotateZ.gif)\n![](./rotateXY.gif)\n![](./rotate.gif)\n\nAnd it works well with the react-native `transform` API \n\n```\nimport { withAnchorPoint } from 'react-native-anchor-point';\n\ngetTransform = () => {\n    let transform = {\n        transform: [{ perspective: 400 }, { rotateX: rotateValue }],\n    };\n    // inject the anchor point here\n    return withAnchorPoint(transform, { x: 0.5, y: 0 }, { width: CARD_WIDTH, height: CARD_HEIGHT });\n};\n    \n<Animated.View style={[styles.blockBlue, this.getTransform()]} />\n```\n\n## Ref\n\n- [Matrices](http://www.opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices/)\n- [react-native-foldview](https://github.com/jmurzy/react-native-foldview)\n- [RN How to set the anchor point of a view.](https://stackoverflow.com/a/60632809/4026902)\n- https://pages.mtu.edu/~shene/COURSES/cs3621/NOTES/geometry/geo-tran.html\n","tags":["Animation"],"categories":["React Native"]},{"title":"Work with Wider Color","url":"/2020/05/09/20190509-Work-with-Wider-Color/","content":"\n\n# Work with Wider Color \nhttps://developer.apple.com/videos/play/wwdc2016/712\n\n## Basic concepts about color\n\n### What is Color Space \n\n> A color space is a specific organization of colors. In combination with physical device profiling, it allows for reproducible representations of color, in both analog and digital representations.            --- Wiki\n\n![](media/15884935782947/15884941050187.jpg)\n\nThis is the standard RGB space, which is the default color space in iOS. \n\n#### Color Primaries\n> Color primaries generally fall at the most intense value that you can get with that particular color channel.\n\nLike, in sRGB space, the color primaries are \n> RGB {0.0, 0.0, 0.0} = Black \nRGB {1.0, 1.0, 1.0} = White \nRGB {1.0, 0.0, 0.0} = Red\n\n#### Color gamut \n  All of the colors that can be defined as a combination of those individual color channels. \n\n\n## Display P3 \n\n\n![](media/15884935782947/15885097554778.jpg)\n\nIn the above image, the colored region represents the outer limits of perception in a human's color vision. \n\nThe inner black triangle represents sRGB's limits of presentation.\nIn contrast, the DCI-P3 standard, and the Wide Color implementation, has a larger area underneath the triangle, representing the greater array of displayable color possible.\n\n- 16bit per color channel for P3 and beyond \n\n### Extended Range sRGB \n\n- Display P3\n    - {1.0, 0.0, 0.0}\n- Extended Range sRGB\n    - {1.358, -0.074, -0.012}\n## Wider Color \n                        \n                        \n> Wide color displays support a P3 color space, which can produce richer, more saturated colors than sRGB. As a result, photos and videos that use wide color are more lifelike, and visual data and status indicators that use wide color are more impactful.\n\n\n## Color Management \n\nApplication Content Types\n- Static image resources\n- Document and network image resources\n- Advanced Media\n- GPU Textures\n\nFraming the Color Problem\n- App Content can come in a broad range of color richness from many sources Devices and \n- Displays come in a broad range of color capabilities\n\n### How do we bridge the differences?\n\nThe answer is color management. \n\n> The job of color management is to ensure that an image looks the same on any output device no matter what color space it is encoded in.\n\n### How does it work?\n\n- Every image has an associated color space (color profile)\n- Color matching maps image colors to output device\n    - ![](media/15884935782947/15885122964828.jpg)\n\n- Not for free: Every pixel needs to be color matched\n- Potentially lossy: Color fidelity is lost when output has smaller gamut. For example, going down from P3 color space to sRGB color space. \n\nOpti in System: \n\n- Color matching operations are easily hardware accelerated\n\n- Color matching operations are easily hardware accelerated\n- Properly tagged content requires no code to display properly\n\n## Design Considerations for Wide Gamut \n\n- Use wide gamut content where it makes sense\n- Use where vivid colors enhance the user experience\n- No need to change all content to P3\n- Toolchain support makes gradual opt-in of wide gamut content possible\n\n## Upgrading Content to Wide Color\n\nBe careful when promoting an existing design file to wide color! \n- Don’t “assign” P3 profile. It just remaps the existing color information into new color space. The colors are stretched, and the design file will be inevitably altered. \n- Convert to P3 instead\n\n\n## Tools \n ![](media/15884935782947/15885134344507.jpg)\n\n## Color Specification \n\nWhen communicating with designers, Be specific about color space!\n\n- Use Display P3 instead of sRGB when working with wide gamut designs\n\n- Use floating point for more precision\n> P3 (255, 128, 191) \n> P3 (1.0, 0.5, 0.75)\n\n## Drawing colors \n\n### Constructing Wide Gamut Colors \n\n```swift\nNSColor(displayP3Red: 1.0, green: 0.0, blue: 0.0, alpha: 1.0)  \nUIColor(displayP3Red: 1.0, green: 0.0, blue: 0.0, alpha: 1.0)\n\n```\n### Constructing Extended Range sRGB Colors\n```swift \nNSColor(red: 1.1, green: -.25, blue: 0.0, alpha: 1.0)  \nUIColor(red: 1.1, green: -.25, blue: 0.0, alpha: 1.0)\n\n```\n\n\n### Rendering \nOptimizing your app’s drawing for wide gamut displays\n\n❌ Don't use `UIGraphicsBeginImageContext`. It doesn't support wider color. \n\n> The format for the bitmap is a ARGB 32-bit\n>  integer pixel format using host-byte order\n\n`UIGraphicsBeginImageContext` not only cannot create contexts with more than 8 bits per color channel, but also cannot represent colors in extended range sRGB. Sadlly, existing interface has no ability to create a context in non-sRGB color space. \n\nSo, they introduce `UIGraphicsImageRenderer(size: CGSize)` \n\n```swift \n\nlet renderer = UIGraphicsImageRenderer(size: CGSize(width: 250, height: 250))\nlet image =  renderer.image { rendererContext in\n    let bounds = rendererContext.format.bounds\n    let rects = bounds.divided(atDistance: bounds.size.width/2, from: .minXEdge)\n    \n    UIColor(displayP3Red: 1.0, green: 0.0, blue: 1.0, alpha: 1.0).set()\n    rendererContext.fill(rects.slice)\n    \n    UIColor(red: 1.0, green: 0.0, blue: 1.0, alpha: 1.0).set()\n    rendererContext.fill(rects.slice)\n}\n```\n\n- Fully color managed by default\n- Supports extended range sRGB color space\n- Manages CGContext lifetime\n\n\n### Draw \n\n`UIView`, `UIImageView`, Color managed since iOS 9.3 \n```swift \ndraw(_ rect: CGRect) // called in the extended sRGB color space\n```\n\nFor `UIView`, use the view’s layer’s `contentsFormat` property\n\nValid CALayer contents formats:\n- kCAContentsFormatRGBA8Uint\n- kCAContentsFormatRGBA16Float\n- kCAContentsFormatGray8Uint","tags":["WWDC","Image"]},{"title":"iOS images in memory","url":"/2020/05/03/iOS-images-in-memory/","content":"\n> Notes for [wwdc2018/219](https://developer.apple.com/videos/play/wwdc2018/219) and [wwdc2018/416](https://developer.apple.com/videos/play/wwdc2018/416/)\n\n## Why memory and CPU matter? \n![](media/15884695669510/15888626848016.jpg)\n\n\n- It is obvious that too much usage of `CPU` has negative impact on `battery life` and `responsiveness`.  \n- But, if you application consumes too much memory, that causes more `CPU utilization`, which have negative effects on `battery life` and `performance`.\n\n## Basic Concepts \n\n### Buffers \n> Buffer is contiguous region of memory. \nIt is often viewed as sequence of elements of the same sizes, usually of the same internal construction. \n\n![-w354](media/15884695669510/15888596565806.jpg)\n\n\n\n#### Image Buffers \n\n> One kind of the important buffers is the `Image Buffer`, which holds the `in-memory representation of some image`. \n\nEach element in image buffers describes the color and the transparency of single pixel in our image. Constantly, the buffer size is proportional to image size. For example, in the image with sRBG format, each 32 bits describes the color and transparency of a single pixel. `The buffer size =  4 byte  x image_width x image_height`\n\n\n\n![-w452](media/15884695669510/15888600604360.jpg)\n\n#### Frame buffer \n\n> The frame buffer is what holds the actual rendered output of your application.  \n\nAs your application updates its view hierarchy UIKit will render the application's `window` and all of its `subviews` into the `frame buffer`. And that frame buffer provides per pixel color information that the `display hardware` will read in order to illuminate the pixels on the display.\n\n[Related resource: The View Drawing Cycle](https://developer.apple.com/library/archive/documentation/WindowsViews/Conceptual/ViewPG_iPhoneOS/WindowsandViews/WindowsandViews.html#//apple_ref/doc/uid/TP40009503-CH2-SW10)\n\nThe pipeline is like this: \n\n![](image_graphic.gif)\n\n#### Data Buffer\n\n> a data buffer is just a buffer that contains a sequence of bytes. \n\nIf we've downloaded images from the network or we've `loaded` them from disk. A data buffer that contains an image file, typically, begins with some metadata describing the size of the image that's stored in that data buffer.\n\n![-w397](media/15884695669510/15888655020412.jpg)\n\n- Store contents of an `image file` in memory. The `size` is the same as that in the image file in the disk. \n- Metadata describing dimensions of image\n- Image itself `encoded` as JPEG, PNG, or other (usually compressed) form\n- Bytes `do not `directly describe pixels\n\n\n### The Pipeline in Action \n\n![-w834](media/15884695669510/15890026431784.jpg)\n\n\n## Consequences of Excessive Memory Usage \n\n- Increased fragmentation. \n    - `fragment` : The large allocation that is in your application's address space could force other related content apart from content that it wants to reference.\n- Poor locality of reference\n- System starts `compressing` memory Process termination\n    - Eventually, if your application starts accumulating a lot of memory usage the operating system will step in and start transparently `compressing` the content of physical memory. Now, the CPU needs to be involved in this operation so in addition to any CPU usage in your own application. You could be `increasing global CPU usage` that you have no control over. Eventually, your application could start consuming so much physical memory that the OS needs to start `terminating processes`. And it'll start with background processes of low priority.\n\n- You app may be terminated by the system\n- Cause `CPU peak`, and then has negative impact on battery life and responsiveness.\n\n## Decoding \n\n> Decoding is an operation that will convert the JPEG or PNG or other encoded image data into per pixel image information. \n\n- CPU-intensive process\n\n- The memory used for the image buffer is proportional to original image size, not view size. \n- There are persistent large memory allocation in decoding.\n- The image buffer is retained for repeat rendering by UIImage. \n\nAfter decoding, UIImage will hang onto that image buffer, so that it only does that work once. Consequently, your application, for every image that gets decoded, could have a persistent and large memory allocation hanging out.\n\n## The memory use of an image using sRGB space\n\n> Memory use is related to the dimensions of the images, not the file size.\n\nTake the following image as an instance, its file size is 590KB, with dimension 2048 x 1536 pixel.\n![83dca9cf.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/83dca9cf.png)\n\n\n### 4 byetes for each pixel in RGBA \n\nBy this [article](https://www.objc.io/issues/3-views/moving-pixels-onto-the-screen/), each pixel in sRGB image needs 32bit, 4 bytes, in memory when it's decoded. Because in sRGB, there are Red, Green, Blue 3 channels and Alpha. The range of each channel value is from 0 to 255, which needs 8 bits to represent the value. \n\n```\n  A   R   G   B   A   R   G   B   A   R   G   B  \n | pixel 0       | pixel 1       | pixel 2   \n  0  233  2  100  4  155 255  7   8   9   10  11 \n```\n  \n\n### More memory usage when decoding a image \n\nA image have load -> decode -> render these 3 phases.  \n\n![64aaa3cd.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/ed4e1c96.png)\n\n\n\nWe only need 590KB to load a image, while we need \n`2048 pixels x 1536 pixels x 4 bytes per pixel` = 10MB when decoding \n  \n\n\n##  Image Rendering Pipeline \n\n- `UIImage` is responsible for loading image content. Usually, it is bigger than the ImageView that is going to display it. \n- `UIImageView` is responsible for displaying the image. The image which it is going to display will be shrink down to fit its size. \n ![](media/15884695669510/15889026761062.jpg)\n\n\n## Downsampling\nSo, we can use technique, called Downsampling, to `downsample` the images to `the size that they're going to be displayed`. Rather than having these large allocations hanging around, we're reducing our memory usage.\n\n![-w1333](media/15884695669510/15889088392417.jpg)\n\n```swift \n// Downsampling large images for display at smaller size\nfunc downsample(imageAt imageURL: URL, to pointSize: CGSize, scale: CGFloat) -> UIImage {\n    // ShouldCache flag tells Core Graphics framework that we're just creating an object to\n    // represent the infomation stored in the file at this URL\n    let imageSourceOptions = [kCGImageSourceShouldCache: false] as CFDictionary\n    let imageSource = CGImageSourceCreateWithURL(imageURL as CFURL, imageSourceOptions)!\n    let maxDimensionInPixels = max(pointSize.width, pointSize.height) * scale\n    let downsampleOptions =\n        // Ask the Core Graphics to create the decoded image buffer for me when calling it to create the thumbnail\n        [kCGImageSourceCreateThumbnailFromImageAlways: true,\n        kCGImageSourceShouldCacheImmediately: true,\n        // Should include kCGImageSourceCreateThumbnailWithTransform: true in the options dictionary. Otherwise, the image result will appear rotated when an image is taken from camera in the portrait orientation.\n        kCGImageSourceCreateThumbnailWithTransform: true,\n        kCGImageSourceThumbnailMaxPixelSize: maxDimensionInPixels] as CFDictionary\n    let downsampledImage =\n        CGImageSourceCreateThumbnailAtIndex(imageSource, 0, downsampleOptions)!\n    return UIImage(cgImage: downsampledImage)\n}\n```\n\n## Decoding in ScrollViews \n### The cause of the ScrollView hitch \n\n![-w1178](media/15884695669510/15889147842616.jpg)\n\n\n> When beginning scrolling, we're about to display another row of images. And we're about to ask Core Graphics to `decode` those images before we hand the cells back to UICollectionView.\nAnd that could take `a lot of CPU time`. So much so, that we `don't` get around to `re-rendering the frame buffer`. But the `display hardware` is operating on a `fixed interval`. So, from the user's perspective the application has just `stuttered`. Now, we're done decoding these images, we're able to provide those cells back to UICollectionView. And animation continues on, as before. Just saw a `visual hitch`, \n\n## Two techniques to smooth out CPU usage \n\n1. prefetching \n2. performing work in the background\n\n### Thread Explosion \nIt is caused by \n- More images to decode than available CPUs \n- GCD continues creating threads as new work is enqueued\n- Each thread gets less time to actually decode images\n\n\n> Now, to avoid deadlock when we dispatch asynchronously to a global queue, GCD is going to create new threads to capture the work we're asking it to do. And then, the CPUs are going to spend a lot of time moving between those threads to try and make incremental progress on all of the work we asked the operating system to do for us. And switching between those threads, actually, has a pretty significant overhead.\n\n\nwe're going to serialize some work.\n\nSo, rather than simply dispatching work to one of the global asynchronous queues, we're going to create a serial queue. And inside of our implementation of the prefetch method we're going to asynchronously dispatch to that queue.\n\n![-w1516](media/15884695669510/15889150745604.jpg)\n\n## Image Sources \n\nImages may come from \n- Image assets in asset catalog\n- Files in application/framework bundle\n- Files in Documents and Caches directories \n- Data downloaded from network\n\nThis session suggests us to use image assets for the following reasons: \n\n- Optimized name- and trait-based lookup\n   - It's `faster` to `look up` an image asset in the asset catalog, than it is to search for files on disk that have a certain naming scheme. \n\n- Smarter buffer caching\n    - The asset catalog runtime has, also, got some really good smarts in it for managing `buffer sizes`.\n\n- Per-device thinning\n   - your application only downloads image resources that are relevant to the device that it's going to run on and vector artwork. The \n\n- Vector artwork\n\n## Vector artwork\n\n- Since iOS 11, image assets support  “Preserve Vector Data”\n- Avoids blurriness and aliasing when drawn larger or smaller than natural size\n\n\n\n## Image Rendering Format \n\n### SRGB\n- 4 bytes per pixel \n- full color images \n- most common used \n![a1bf604b.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/a1bf604b.png)\n\n### Wide format \n\n- 8 bytes per pixel \n- super accurate colors. Because they use 8bytes, 16 bits, for each channel. In the meantime, double the image size.  \n- Only useful with wide color display. We don't want to use it when we don't need to. \n- Wide color capture cameras since iPhone 7\n  \n\n![75a1a01e.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/75a1a01e.png)\n\n### Luminance and alpha 8 format\n\nThis image only holds grayscale value. And the image size is smaller. \n\n- 2 bytes per pixel \n- Single-color iamges and alpha\n- Most used in Metal shaders, not very common. \n![6383b177.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/6383b177.png)\n### Alpha 8 Format \n\n- 1 byte per pixel \n- Userful for monochrome images because it uses less memory. \n  - masks \n  - Emoji-free text \n- 75% smaller than SRGB\n\n![753920b5.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/753920b5.png)\nWe can also change `image.tintColor` in this image without changing its format.  \n\n## How do I pick the right format?\n\n`UIGraphicsBeginImageContextWithOptions` always uses SRGB rendering-format, which use 4 bytes per pixel. \n\nwhile `UIGraphicsImageRenderer`, which introduced in iOS 10 will automatically pick the best graphic format in iOS12. It means, you will save 75% of memory by replacing `UIGraphicsBeginImageContextWithOptions` with  `UIGraphicsImageRenderer`\n\n\n**Do** ✅\n\n![2f0229d3.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/2f0229d3.png)\n## Use ImageIO to downsample images\n\n`UIImage` is expensive for sizing and to resizing\n- Will decompress original image into memory \n- Internal coordinate space transforms are expensive\n\n**Don't** ❌\n\n \n![c25d45de.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/c25d45de.png)\n\nUse ImageIO\n- ImageIO can read image sizes and metadata information without dirtying memory.\n\n- ImageIO can resize images at cost of resized image only.\n\n**Do** ✅\n![922ac245.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/922ac245.png)\n\nThe bad is that you have to specify some options. \n\n## Resize image effectively\n\nThis is a function of resizing image without reading it into the memory, using ImageIO.  \n\n```swift\nfunc resize(url: NSURL, maxPixelSize: Int) -> CGImage? {\n    let imgSource = CGImageSourceCreateWithURL(url, nil)\n    guard let imageSource = imgSource else {\n        return nil\n    }\n\n    var scaledImage: CGImage?\n    let options: [NSString: Any] = [\n            // The maximum width and height in pixels of a thumbnail.\n            kCGImageSourceThumbnailMaxPixelSize: maxPixelSize,\n            kCGImageSourceCreateThumbnailFromImageAlways: true,\n            // Should include kCGImageSourceCreateThumbnailWithTransform: true in the options dictionary. Otherwise, the image result will appear rotated when an image is taken from camera in the portrait orientation.\n            kCGImageSourceCreateThumbnailWithTransform: true\n    ]\n    scaledImage = CGImageSourceCreateThumbnailAtIndex(imageSource, 0, options as CFDictionary)\n\n    return scaledImage\n}\n\n\nlet filePath = Bundle.main.path(forResource:\"large_leaves_70mp\", ofType: \"jpg\")\n\nlet url = NSURL(fileURLWithPath: filePath ?? \"\")\n\nlet image = resize(url: url, maxPixelSize: 600)\n```\n\n## Optimizing when in the background\n\n### foreground/background\n\nThe strategy is simple, when `UIApplicationDidEnterBackground`, we unload images; and when `UIApplicationWillEnterForeground`, load images. \n\n\n### on-screen/off-screen \n\nunload large resource when off-screen, `viewDidDisappear`; and load large resource when on-screen, `viewWillAppear`. \n\n## Debug \n\nUse memory graphs to further understand and reduce memory footprint\n\n\n## Ref \n\n- [An great example of how to use command line tools to find root cause of an image memory issue.](https://developer.apple.com/videos/play/wwdc2018/416/)  \n\n## Related \n\n- [An-glimpse-of-iOS-Memory-Deep-Dive](https://suelan.github.io/2020/05/03/An-glimpse-of-iOS-Memory-Deep-Dive/)\n- [Work with Wider Color ](https://suelan.github.io/2020/05/09/20190509-Work-with-Wider-Color)","tags":["Image","Debug","Memory"],"categories":["iOS"]},{"title":"A glimpse of iOS Memory Deep Dive","url":"/2020/05/03/An-glimpse-of-iOS-Memory-Deep-Dive/","content":"\nThis is an pretty good session about iOS memory. [iOS Memory Deep Dive - WWDC 2018 - Videos - Apple Developer](https://developer.apple.com/videos/play/wwdc2018/416/). I saw it and took some notes here. \n\n> Not all memory is created equal. \n\nThere are dirty memory, clean memory, compressed memory in iOS system. We have to know the differences between them. \n\n## Page  \n\nPage is typically 16KB in size and operating system gives it to you when your app requests memory.  \n\n```\nmemory in use = number of pages x page size \n```\n\n![b576f28d.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/b576f28d.png)\n\nSome pages can hold multiple objects, and some objects\ncan span multiple pages. \n\n\n\n### Pages Types \n  - Clean\n    - Data that can be paged out of memory\n    - Memory mapped files\n    - frameworks*\n     \n  - Dirty \n    - memory written by an app \n    - all heap allocations\n    - decoded image buffers\n  - Comporessed \n\n> There is no traditional disk swap in iOS \n\n\n## Memory compressor \n\nThe system will do the compression and decompression for you by memory compressor.\n\nWhat does Memory compressor do? \n\n- Compresses unaccessed pages \n- Decompresses pages upon access\n\n\nBefore being compressed: \n\n\n![cdb635fb.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/cdb635fb.png)\n\nAfter being compressed: \n![8b7d45fa.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/8b7d45fa.png)\n\n\nWhen you got Memory warning, you App is not always the cause. Maybe because the compressor freeing memory. Like, you receiving a phone call while using the App.\n\nAfter being decompressed: \n\n![f0910e00.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/f0910e00.png)\n\nAfter removing objects in `didReceiveMemoryWarning` \n\n\n![28bedf77.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/28bedf77.png)\n\n## Caching \n\n- Trade-offs between CPU and memory. Caching can reduce the CPU usage and time complexity, but it costs memory. \n- Remember the compressor. When decompressing, the used memory will be increased.\n- Prefer NSCache over dictionary. \n\n\n## Memory Profile \n\nIt is the dirty size + the compressed size that the system uses to determine how much memory the app is really using. \n\nWe should mainly focuse on these two part, dirty and compressed memory when analyzing the memory profile.  \n![8af52c4f.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/8af52c4f.png)\n\n\n\n## Tools for Profiling Footprint \n\n1. Xcode memory gauge\n  ![447accd0.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/447accd0.png)\n  \n2. Instruments\n- Allocations \n- Leaks \n- VM Tracker \n  - providing profiles for dirty and compressed memories. \n  - ![69341a61.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/69341a61.png)\n- Virtual memory trace \n  - ![1ca65c7e.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/1ca65c7e.png)\n3. Debugger \n ![cd78fa8b.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/cd78fa8b.png)\n4. memory graph \n\n![af606628.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/af606628.png)\n\n## working with memory graph using commands\n\n\n### vmmap \n\n\n\n`vmmap` helps to show some dirty memory info of your app. In general, we should look for the big number for the size. \nThere are `virtual size`, `resident size`, `dirty size`, `swapped size` columns here. \n\nAccording to this [session](https://developer.apple.com/videos/play/wwdc2018/416/), we can ignore the `virtual size`, because it is memory requested by the app, while not neccessarily be used.  `swapped size` is related to compressed memory. So we should care more about `dirty size` and `swapped size`.\n\n#### An example of using vmmap to debug a memory issue\n\nFirst, we can use summary info to look for the big numbers in `virtual size` and `swapped size` colomn. Here, we find `CG Image` takes much more memory than others. \n\n\n```\nvmmap --summary PlanetPics.memgraph\n```\n![d58088d1.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/d58088d1.png)\n\n\nThen, we use `grep` to get more info about `CG Image`. \n![751c8f78.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/751c8f78.png)\n\nThere are  two regions here, the last row is summary info. The secong CG Image region takes more takes more dirty and swapped memory. So we have to see more infomation of this region by using `--verbose` option.\n\nAll these commands can work with other shell commands, like redirecting the output stream a `output.txt` file. \n\n\n```\nvmmap --verbose PlanetPics.memgraph | grep \" CG image\" | > output.txt\n```\n![14c0b2ff.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/14c0b2ff.png)\n\n\n\nAnd we will more regions.   \n\n> It turns out that vmmap, by default, if it finds contiguous regions, it collapses. A general rule. the later region was created, the later my app's life cycle it happened. Chance are this later region is more closely tied to whatever caused that memory pike. \n\nSo, we start to look at the last region. We can use the start memory address of the last region and search it in the memory graph in XCode.\n\n![5d389834.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/5d389834.png)\n\nOr use `leak` to get the trace tree. By scanning these info, we would find more clues. \n\n![f63287f5.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/f63287f5.png)\n\nHere, using `malloc_history` to see the back trace for this object, we found the related code creating this particular VM memory. \n\n![d8143352.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/d8143352.png)\n\n\n1. vmmap and AWK\n\nThis command can work with other commands. \n![bca9bf95.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/bca9bf95.png)\n\n### leak \n\n```\nleaks App.memgraph\n```\nIt not only shows the cycle, but also the root object of the cycle. \n\n- leak circle\n![21107588.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/21107588.png)\n\n- root object\n![fbc1d8bb.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/fbc1d8bb.png)\n\n### heap \n\n- Shows objects allocated on the heap; \n- useful for indentifying large objects in memory adn what allocated it. \n```\nheap App.memgraph\nheap App.memgraph -addresses all | <classes-pattern>\n```\n\n`heap` command shows the class name  in `CLASS_NAME` column, the num of the class in `COUNT` column, the average size of the object  in the `AVG` column, the total size in the `BYTES` column. \n\n\n```\nheap App.memgraph -sortBySize | > ~/output.txt\n```\n\n\n![b0766b6a.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/b0766b6a.png)\n\n\n### malloc_history\n\nIn some cases, we not only want to know the memory size, but also want to know the how it created. So, here comes the `malloc_history` command.\n\n- enable the malloc_stack logging\n\n![1153a225.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/1153a225.png)\n\n\n```\nmalloc_history App.memgraph [address]\n```\n\n\n![a70d0d43.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/a70d0d43.png)\n\n### Which tool to pick \n\n![d68340ee.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/d68340ee.png)\n\n\nUse `vmmap` and `heap` to find some objects or regions with big number,  use `leak` to see references between objects, like finding circular reference; use `malloc_history` to see how it is created.  \n\n## Related: \n\n- [iOS-images-in-memory](https://suelan.github.io/2020/05/03/iOS-images-in-memory/)","tags":["WWDC","Image","Debug","Memory"],"categories":["iOS"]},{"title":"How to inspect network activities of your iOS application","url":"/2020/04/25/How-to-inspect-network-activity-of-your-iOS-applicatoin/","content":"\nRecently, Facebook launched [Flipper](https://github.com/facebook/flipper), A desktop debugging platform for mobile developers.  And there is an embedded network plugin, `FlipperKitNetworkPlugin` ,  which works as an inspector of network activities in our application. Let's figure out how it can achieve that. \n\n## Overview \n\nHere comes the class diagram of this network plugin. \n\n![class](class.png)\n\nIn these classes, `FLEXNetworkObserver` is the key one for this plugin. \n\nWhen the plugin starts, it will inject all the `NSURLConnectionDelegate` classes and functions to observe the remote request and response event. \n\n## Swizzle \n\nThe key idea is to swizzle any classes that implement one of the selectors in `URLSession` and `NSURLConnectionDelegate` , and get chance to get the request and response data. \n\nThe process is like this: \n\n1. find out selectors in `URLSession` and `NSURLConnectionDelegate`  which are related to network activities. \n2. Retrieve all the class definitions that have been registered with the Objective-C runtime. The Objective-C runtime library automatically registers all the classes defined in your source code. \n3. Find any class that implements one of the above selectors\n4. Inject this class\n    \n\n\n```objective-c\n+ (void)injectIntoAllNSURLConnectionDelegateClasses {\n  // Only allow swizzling once.\n  static dispatch_once_t onceToken;\n  dispatch_once(&onceToken, ^{\n    // 1. 🌟 Swizzle any classes that implement one of these selectors.  \n   const SEL selectors[] = {\n      @selector(connectionDidFinishLoading:),\n      @selector(connection:willSendRequest:redirectResponse:),\n      @selector(connection:didReceiveResponse:),\n      @selector(connection:didReceiveData:),\n      @selector(connection:didFailWithError:),\n      @selector\n      (URLSession:\n             task:willPerformHTTPRedirection:newRequest:completionHandler:),\n      @selector(URLSession:dataTask:didReceiveData:),\n      @selector(URLSession:dataTask:didReceiveResponse:completionHandler:),\n      @selector(URLSession:task:didCompleteWithError:),\n      @selector(URLSession:dataTask:didBecomeDownloadTask:),\n      @selector(URLSession:\n              downloadTask:didWriteData:totalBytesWritten\n                          :totalBytesExpectedToWrite:),\n      @selector(URLSession:downloadTask:didFinishDownloadingToURL:)\n    };\n\n    const int numSelectors = sizeof(selectors) / sizeof(SEL);\n\n    // 2. 🌟 Retrieve all the class definitions that have been registered with the Objective-C runtime. The Objective-C runtime library automatically registers all the classes defined in your source code. \n \n    Class* classes = NULL;\n    // 2.1 🌟 You can pass NULL to obtain the total number of registered class definitions without actually retrieving any class definitions.\n    int numClasses = objc_getClassList(NULL, 0);\n\n    if (numClasses > 0) {\n        // 2.2 🌟 An array of Class values. Each Class value points to one class definition\n      classes = (__unsafe_unretained Class*)malloc(sizeof(Class) * numClasses);\n      numClasses = objc_getClassList(classes, numClasses);\n      // 3. 🌟 Find any class that implements one of the above selectors\n      for (NSInteger classIndex = 0; classIndex < numClasses; ++classIndex) {\n        Class className = classes[classIndex];\n\n        if (className == [FLEXNetworkObserver class]) {\n          continue;\n        }\n\n        // Use the runtime API rather than the methods on NSObject to avoid\n        // sending messages to classes we're not interested in swizzling.\n        // Otherwise we hit +initialize on all classes. NOTE: calling\n        // class_getInstanceMethod() DOES send +initialize to the class. That's\n        // why we iterate through the method list.\n        unsigned int methodCount = 0;\n        Method* methods = class_copyMethodList(className, &methodCount);\n        BOOL matchingSelectorFound = NO;\n        for (unsigned int methodIndex = 0; methodIndex < methodCount;\n             methodIndex++) {\n          for (int selectorIndex = 0; selectorIndex < numSelectors;\n               ++selectorIndex) {\n            // Find a target method in this class \n            if (method_getName(methods[methodIndex]) ==\n                selectors[selectorIndex]) {\n              // 4. 🌟 Inject this class  \n              [self injectIntoDelegateClass:className];\n              matchingSelectorFound = YES;\n              break;\n            }\n          }\n          if (matchingSelectorFound) {\n            break;\n          }\n        }\n        free(methods);\n      }\n\n      free(classes);\n    }\n\n    [self injectIntoNSURLConnectionCancel];\n    [self injectIntoNSURLSessionTaskResume];\n\n    [self injectIntoNSURLConnectionAsynchronousClassMethod];\n    [self injectIntoNSURLConnectionSynchronousClassMethod];\n\n    [self injectIntoNSURLSessionAsyncDataAndDownloadTaskMethods];\n    [self injectIntoNSURLSessionAsyncUploadTaskMethods];\n  });\n}\n```\n\nFor example, how to inject `connection:willSendRequest:redirectResponse:`?\n\n```objective-c \n\n+ (void)injectWillSendRequestIntoDelegateClass:(Class)cls {\n  SEL selector = \n  @selector(connection:willSendRequest:redirectResponse:);\n  //  🌟 Selector with `_flex_swizzle_` prefix\n  SEL swizzledSelector = [FLEXUtility swizzledSelectorForSelector:selector];\n\n  Protocol* protocol = @protocol(NSURLConnectionDataDelegate);\n  if (!protocol) {\n    protocol = @protocol(NSURLConnectionDelegate);\n  }\n  // 🌟 Get the original method description\n  struct objc_method_description methodDescription =\n      protocol_getMethodDescription(protocol, selector, NO, YES);\n\n  typedef NSURLRequest* (^NSURLConnectionWillSendRequestBlock)(\n      id<NSURLConnectionDelegate> slf,\n      NSURLConnection* connection,\n      NSURLRequest* request,\n      NSURLResponse* response);\n\n  // 🌟 If selector `connection:willSendRequest:redirectResponse:` is not a instance method in this class, use this block as the implementation for swizzledSelector\n  NSURLConnectionWillSendRequestBlock undefinedBlock = ^NSURLRequest*(\n      id<NSURLConnectionDelegate> slf,\n      NSURLConnection* connection,\n      NSURLRequest* request,\n      NSURLResponse* response) {\n    [[FLEXNetworkObserver sharedObserver] connection:connection\n                                     willSendRequest:request\n                                    redirectResponse:response\n                                            delegate:slf];\n    return request;\n  };\n\n  // The implementation for swizzledSelector\n  NSURLConnectionWillSendRequestBlock implementationBlock = ^NSURLRequest*(\n      id<NSURLConnectionDelegate> slf,\n      NSURLConnection* connection,\n      NSURLRequest* request,\n      NSURLResponse* response) {\n    __block NSURLRequest* returnValue = nil;\n    [self sniffWithoutDuplicationForObject:connection\n        selector:selector\n        sniffingBlock:^{\n          undefinedBlock(slf, connection, request, response);\n        }\n        originalImplementationBlock:^{\n          returnValue = ((id(*)(id, SEL, id, id, id))objc_msgSend)(\n              slf, swizzledSelector, connection, request, response);\n        }];\n    return returnValue;\n  };\n  // Swizzle; \n[FLEXUtility replaceImplementationOfSelector:selector\n                                  withSelector:swizzledSelector\n                                      forClass:cls\n                         withMethodDescription:methodDescription\n                           implementationBlock:implementationBlock\n                                undefinedBlock:undefinedBlock];\n}\n```\n\nThen, replace the original implementation of `connection:willSendRequest:redirectResponse:` method with flipper's own implementation for `swizzledSelector`. \n\n```objective-c \n\n+ (void)replaceImplementationOfSelector:(SEL)selector\n                           withSelector:(SEL)swizzledSelector\n                               forClass:(Class)cls\n                  withMethodDescription:\n                      (struct objc_method_description)methodDescription\n                    implementationBlock:(id)implementationBlock\n                         undefinedBlock:(id)undefinedBlock {\n  if ([self instanceRespondsButDoesNotImplementSelector:selector class:cls]) {\n    return;\n  }\n  \n  // The implementation for swizzledSelector\n  IMP implementation = imp_implementationWithBlock((id)(\n      [cls instancesRespondToSelector:selector] ? implementationBlock\n                                                : undefinedBlock));\n\n  Method oldMethod = class_getInstanceMethod(cls, selector);\n  if (oldMethod) {\n    // Add new method to the class, whose signature has `_flex_swizzle_` prefix and custom implementation \n    class_addMethod(\n        cls, swizzledSelector, implementation, methodDescription.types);\n\n    Method newMethod = class_getInstanceMethod(cls, swizzledSelector);\n\n    method_exchangeImplementations(oldMethod, newMethod);\n  } else {\n    class_addMethod(cls, selector, implementation, methodDescription.types);\n  }\n}\n\n```\n\nThe activity diagram for the above code  might be this,\n![activity](activity_swizzle.png)\n\n## Observer and Record\n\nIf there is an network activity, a use calls `connection:willSendRequest:redirectResponse:delegate:` \nor `connection:didReceiveResponse:delegate` is called in an object adopting `NSURLConnectionDelegate` protocol. In fact, its original implementations have been replaced. And Flipper's own implementations for these two selector are called, which call the related `willSendRequest:` and `didReceiveResponse:` method in `FLEXNetworkObserver` class.  So, Flipper got the chance to observe the request and response of network activities. \n\n![a](activity_network.png)\n\n\n","tags":["Debug","Flipper"],"categories":["iOS","Network"]},{"title":"iOS Simulator from the Command Line","url":"/2020/02/05/iOS-Simulator-from-the-Command-Line/","content":"\n`xcrun simctl` is command utils to control iOS simulator, just like  [adb](https://developer.android.com/studio/command-line/adb?hl=en) for Android. Sometimes, in CI server script, We need these simulator-integration command to interact with simulators and run test cases. \n\n If we run `xcrun simctl help`, here are some subcommands. When successful, most of these commands exit with 0; when failed, most exit with a non-zero number. \n\n```\nSubcommands:\n        create              Create a new device.\n        clone               Clone an existing device.\n        upgrade             Upgrade a device to a newer runtime.\n        delete              Delete spcified devices, unavailable devices, or all devices.\n        pair                Create a new watch and phone pair.\n        unpair              Unpair a watch and phone pair.\n        pair_activate       Set a given pair as active.\n        erase               Erase a device's contents and settings.\n        boot                Boot a device.\n        shutdown            Shutdown a device.\n        rename              Rename a device.\n        getenv              Print an environment variable from a running device.\n        openurl             Open a URL in a device.\n        addmedia            Add photos, live photos, videos, or contacts to the library of a device.\n        install             Install an app on a device.\n        uninstall           Uninstall an app from a device.\n        get_app_container   Print the path of the installed app's container\n        launch              Launch an application by identifier on a device.\n        terminate           Terminate an application by identifier on a device.\n        spawn               Spawn a process by executing a given executable on a device.\n        list                List available devices, device types, runtimes, or device pairs.\n        icloud_sync         Trigger iCloud sync on a device.\n        pbsync              Sync the pasteboard content from one pasteboard to another.\n        pbcopy              Copy standard input onto the device pasteboard.\n        pbpaste             Print the contents of the device's pasteboard to standard output.\n        help                Prints the usage for a given subcommand.\n        io                  Set up a device IO operation.\n        diagnose            Collect diagnostic information and logs.\n        logverbose          enable or disable verbose logging for a device\n        status_bar          Set or clear status bar overrides\n        ui                  Get or Set UI options\n        push                Send a simulated push notification\n        privacy             Grant, revoke, or reset privacy and permissions\n        keychain            Manipulate a device's keychain\n```\nJust see I can do a lot of things with these command. If wanting to know more about a specific subcommand, we can use `xcrun simctl help [subcommand]` to seek help. Like, `xcrun simctl help boot` \n\n\n### Simulator info \n\nuse `xcrun simctl list` to see all the simulator information. We can get a list of device types, a list of info of runtime names, a list of device names. \n  \n```\n== Device Types ==\niPhone 11 Pro (com.apple.CoreSimulator.SimDeviceType.iPhone-11-Pro)\niPhone 11 Pro Max (com.apple.CoreSimulator.SimDeviceType.iP\n\n== Runtimes ==\niOS 13.3 (13.3 - 17C45) - com.apple.CoreSimulator.SimRuntime.iOS-13-3 \n\n== Devices ==\n-- iOS 13.3 --\niPhone 11 Pro Max (34C9AC6A-577D-4CEF-8B10-20011DCFBA27) (Shutdown) \n```\n\nUse `xcrun simctl list device` to see the list of device info. Or use a device name to get paired devices' info, like name, uuid, and status. For example,  \n\n```\nxcrun simctl list devices \"iPhone 11 Pro Max\"\n```\n\n```\n== Devices ==\n-- iOS 12.4 --\n-- iOS 13.3 --\n    iPhone 11 Pro Max (34C9AC6A-577D-4CEF-8B10-20011DCFBA27) (Shutdown) \n-- tvOS 13.3 --\n-- watchOS 6.1 --\n-- Unavailale: com.apple.CoreSimulator.SimRuntime.iOS-13-0 --\n    iPhone 11 Pro Max (893827B6-91E0-417C-A179-68343F695040) (Creating) (unavailable, runtime profile not found)\n-- Unavailable: com.apple.CoreSimulator.SimRuntime.iOS-13-1 --\n    iPhone 11 Pro Max (F4B573E0-4106-4FF2-ADA8-16DCC053026C) (Shutdown) (unavailable, runtime profile not found)\n-- Unavailable: com.apple.CoreSimulator.SimRuntime.iOS-13-2 --\n    iPhone 11 Pro Max (B63C96BD-1CE2-499B-8387-3B8AEBF50931) (Creating) (unavailable, runtime profile not found)\n```\n\n### Get device environment variable \n\n`xcrun simctl getenv` is for printing an environment variable from a running device. \n\n```\nUsage: simctl getenv <device> <variable name>\n```\n\n\nTake the follow command as an example, the `SIMULATOR_UDID` environment variable contains the UDID of the simulated device. But it doesn't work for physical device. \n\n```\nxcrun simctl getenv booted SIMULATOR_UDID\n9362BF90-132F-4894-A057-CEBFEC9C1FB6\n```\n\nWe can add more environment variables by ourselves in schema for debugging use. \n![](environment_variable.png)\n\n[Launch Arguments & Environment Variables](https://nshipster.com/launch-arguments-and-environment-variables/)\n\n### Create a custom simulator\n\n\n`xcrun simctl create <name> <device type> <runtime>`\nFor example, if I would like to create a iPhone 11 Pro Max with iOS 13.3, I can use the follow command.\n\n```\nxcrun simctl create \"ry\" \"iPhone 11 Pro Max\" iOS13.3  \nBE9A72F0-5793-447B-BEC4-63A73242BED5 \n```\n\n\n\nThe `uuid` of the new simulator is `BE9A72F0-5793-447B-BEC4-63A73242BED5`, which is output in standard out. And errors comes to standard error. \n\n> Tips: you should use available runtime, or you will get an error of `invalid runtime: xxx`. \n\nIf in shell scrip, we can capture the new device's name using environment variable:\n\n```\nNEW_DEVICE=$(xcrun simctl create \"Test Phone\" \"iPhone XR\" iOS13.0)\necho \"🤖 Created ${NEW_DEVICE}\"\n🤖 Created BE9A72F0-5793-447B-BEC4-63A73242BED5\n```\n\nAnother way to create a simulator using GUI is to go to `Window` -> `Devices and Simulators` \n\n![create](create.png)\n   \n### Boot a simulator \n\nBoot a device using `$uuid` \n\n`xcrun simctl boot BE9A72F0-5793-447B-BEC4-63A73242BED5` \n\nUse `simctl shutdown <device>` to shutdown a device. \n\n### Install/Uninstall app \n\n`xcrun simctl install <device> <path>`. We use this command to install an app on a device. \n\n```\n➜  xcrun simctl install booted ./demo.app\n```\n\n `booted` is the alias name of the booted device. We can also use `uuid` of a device.\n\n use ` simctl uninstall <device> <app bundle identifier>` to uninstall an app. like \n `xcrun simctl uninstall booted com.rong.lan.CubeTransitionAnimationDemo`  \n\n### Launch \n\n`xcrun simctl launch <device> <bundle> <arguments>`. \n\nLaunch command is used to launch a application in your simulator device.\n\n```\nxcrun simctl launch booted com.apple.example -MyDefaultKey YES\n```\n\n`com.apple.example` is bundle id of the application. \n\nIf we use `--console-pty`,  launch command will connect the standard output and error of the application to the terminal line.\n\n```\n➜  xcrun simctl launch --console-pty booted com.rong.lan.CubeTransitionAnimationDemo\n\ncom.rong.lan.CubeTransitionAnimationDemo: 98045\n2020-02-09 10:38:28.594 3DCubeTransitionAnimationDemo[98045:931065] gesture end translation x -281.000000; velocity-1056.111584\n2020-02-09 10:38:28.594 3DCubeTransitionAnimationDemo[98045:931065] timer current tx -281.000332\n2020-02-09 10:38:28.611 3DCubeTransitionAnimationDemo[98045:931065] timer current tx -285.030635\n2020-02-09 10:38:28.627 3DCubeTransitionAnimationDemo[98045:931065] timer current tx -289.060938\n```\n\n\n Use `xcrun simctl terminate <device> <bundle>` to terminate an application by identifier on a device.\n### Container Path \n\n`xcrun simctl simctl get_app_container <device> <app bundle identifier> [<container>]`  command is used to get the path of the installed app's container.  \n\n```\ncontainer   Optionally specify the container. Defaults to app.\n  app                 The .app bundle\n  data                The application's data container\n  groups              The App Group containers\n  <group identifier>  A specific App Group container\n```\n\n\nFor example\n\n```\n➜ xcrun simctl get_app_container booted com.rong.lan.CubeTransitionAnimationDemo \n~/Library/Developer/CoreSimulator/Devices/BE9A72F0-5793-447B-BEC4-63A73242BED5/data/Containers/Bundle/Application/135A7B46-DE38-47EC-9871-D1F3615E9CE5/3DCubeTransitionAnimationDemo.app\n➜ xcrun simctl get_app_container booted com.rong.lan.CubeTransitionAnimationDemo data \n~/Library/Developer/CoreSimulator/Devices/BE9A72F0-5793-447B-BEC4-63A73242BED5/data/Containers/Data/Application/10D64231-20B5-4DFE-B1E9-277AD9C02C4F\n```\n\n### Spawn \n\nSpawn command will pause xspawn, a process inside the simulator environment. \n\n```\nxcrun simctl spawn booted defaults write com.example.app ResetDatabase -bool YES\n```\nHere, we use `defaults` utils, because we already have a booted device `BE9A72F0-5793-447B-BEC4-63A73242BED5`, we don't have to specify the device. \n\n`com.example.app` is bundle id of my application. We reset `ResetDatabase` to YES. \nThis is a handy way to change the user defaults for the application before its running.  \n\n### Log Stream \n\nspwan command would work with log stream utility. We can pass a predicate and filter the log output. Here the predicate is `senderImagePath CONTAINS \"nsurlsessiond\"`. We can debug something wrong with URL session. \n\n```\nxcrun simctl spawn booted log stream --predicate 'senderImagePath CONTAINS \"nsurlsessiond\"'\n```\n![spwan](spawn_log.png)\n\nAlso, we can use different predicates to filter what we want.  \n\n```\nxcrun simctl spawn booted log stream — predicate ‘processImagePath endswith “xxx”’\nxcrun simctl spawn booted log stream — predicate ‘eventMessage contains “error” and messageType == info’\n\n```\n\n\n### Dignose \n\nIn a auto-test system, if having some kind of issue, by using this command, you can not only collect logs on disk but also capture ephemeral logging and dump system state. \n\n```\n➜  xcrun simctl diagnose -l                              \nWriting to /private/tmp/simctl_diagnose_2020_02_09.10-10-56+0800\nGetting Simulator component versions...\nCollecting CoreSimulator logs...\nCollecting device information (this may take some time)...\nThis operation will time-out after 300 seconds.\nGathering 15 crash reports...\nCompressing Archive...\nSuccessfully wrote simctl diagnose archive to '/private/tmp/simctl_diagnose_2020_02_09.10-10-56+0800.tar.gz'\n```\n\n![diagnose](diagnose.png)\n\n### Clone \nClone is a very powerful command. See details in [wwdc2019/418](https://developer.apple.com/videos/play/wwdc2019/418/).  \n\n`xcrun simctl clone <device> <clone name>`.  You can copy your custom device using this command. \n\n```\n// boot base simulator ry\n➜ xcrun simctl boot ry   \n➜ xcrun simctl install ry ./demo.app\n// Must shutdown it before clone \n➜ xcrun simctl shutdown all \n➜ xcrun simctl clone ry ry-1  \n➜ xcrun simctl clone ry ry-2 \n➜ xcrun simctl boot ry-1 && xcrun simctl boot ry-2 \n```\n\n\nTwo new devices are created with the same contents. \n\n![clone](clone.png)\n\n\n### Push Notification to simulator\n\n1. Create a `.apns` file, `ExamplePush.apns` \n\n```\n{\n    \"Simulator Target Bundle\": \"com.facebook.flipper\",\n    \"aps\": {\n        \"alert\": \"This is a simulated notification!\",\n        \"badge\": 3,\n        \"sound\": \"default\"\n    }\n}\n```\n\n[valid Apple Push Notification values](https://developer.apple.com/documentation/usernotifications/setting_up_a_remote_notification_server/generating_a_remote_notification). Noted that the `Target Bundle` should be the same as the `bundle identifier`  \n\n2. Drag and drop an APNs file onto the target simulator. \n\n> The file must be a JSON file with a valid Apple Push Notification Service payload, including the “aps” key. It must also contain a top-level “Simulator Target Bundle” with a string value matching the target application‘s bundle identifier. --  https://stackoverflow.com/a/60085404/4026902\n\n\n\nOr, we use command lines. \n\n```\nxcrun simctl push booted com.facebook.flipper ExamplePush.apns\n```\n\n\n```\n➜  ~ xcrun simctl push \nSend a simulated push notification\nUsage: simctl push <device> [<bundle identifier>] (<json file> | -)\n\n        bundle identifier\n             The bundle identifier of the target application\n             If the payload file contains a 'Simulator Target Bundle' top-level key this parameter may be omitted.\n             If both are provided this argument will override the value from the payload.\n        json file\n             Path to a JSON payload or '-' to read from stdin. The payload must:\n               - Contain an object at the top level.\n               - Contain an 'aps' key with valid Apple Push Notification values.\n               - Be 4096 bytes or less.\n\nOnly application remote push notifications are supported. VoIP, Complication, File Provider, and other types are not supported.\n\n```\n\n### Manipulate a device's keychain \n\n```\n➜  ~ xcrun simctl keychain\nManipulate a device's keychain\nUsage: simctl keychain <device> <action> [arguments]\n\n    add-root-cert [path]\n        Add a certificate to the trusted root store.\n\n    add-cert [path]\n        Add a certificate to the keychain.\n\n    reset\n        Reset the keychain.\n```\n\n```\nxcrun simctl keychain booted add-root-cert myCA.cer\n```\n\n### Privacy and Permissions \n\nThese commands, introduced in Xcode 11.4,  could be very useful when you are developing some features and have to test the permissions.  \n\n```\n➜  ~ xcrun simctl privacy                                         \nGrant, revoke, or reset privacy and permissions\nUsage: simctl privacy <device> <action> <service> [<bundle identifier>]\n\n        action\n             The action to take:\n                 grant - Grant access without prompting. Requires bundle identifier.\n                 revoke - Revoke access, denying all use of the service. Requires bundle identifier.\n                 reset - Reset access, prompting on next use. Bundle identifier optional.\n             Some permission changes will terminate the application if running.\n        service\n             The service:\n                 all - Apply the action to all services.\n                 calendar - Allow access to calendar.\n                 contacts-limited - Allow access to basic contact info.\n                 contacts - Allow access to full contact details.\n                 location - Allow access to location services when app is in use.\n                 location-always - Allow access to location services at all times.\n                 photos-add - Allow adding photos to the photo library.\n                 photos - Allow full access to the photo library.\n                 media-library - Allow access to the media library.\n                 microphone - Allow access to audio input.\n                 motion - Allow access to motion and fitness data.\n                 reminders - Allow access to reminders.\n                 siri - Allow use of the app with Siri.\n        bundle identifier\n             The bundle identifier of the target application.\n\nExamples:\n        reset all permissions: privacy <device> reset all\n        grant test host photo permissions: privacy <device> grant photos com.example.app.test-host\n```\nFor example,\n\n```\n➜  ~ xcrun simctl privacy booted grant location com.facebook.flipper\n➜  ~ xcrun simctl privacy booted grant photos com.facebook.flipper\n```\n\nand use `revoke` to revoke the permissions. \n\n\n### Switch the appearance style in a device between light and dark.\n\n```\nxcrun simctl ui booted appearance dark\nxcrun simctl ui booted appearance light\n```\n\n### StatsBar override \n\n`Usage: simctl status_bar <device> [list | clear | override <override arguments>]`\n\nIt seems it can support a lot of overrides variables in status bar. But I have figure out the scenarios to use them. \n\n```\n➜  ~ xcrun simctl status_bar                                    \nSet or clear status bar overrides\nUsage: simctl status_bar <device> [list | clear | override <override arguments>]\n\nSupported Operations:\n    list\n        List existing overrides.\n\n    clear\n        Clear all existing status bar overrides.\n\n    override <override arguments>\n        Set status bar override values, according to these flags.\n        You may specify any combination of these flags (at least one is required):\n\n        --time <string>\n             Set the date or time to a fixed value.\n             If the string is a valid ISO date string it will also set the date on relevant devices.\n        --dataNetwork <dataNetworkType>\n             If specified must be one of 'wifi', '3g', '4g', 'lte', 'lte-a', or 'lte+'.\n        --wifiMode <mode>\n             If specified must be one of 'searching', 'failed', or 'active'.\n        --wifiBars <int>\n             If specified must be 0-3.\n        --cellularMode <mode>\n             If specified must be one of 'notSupported', 'searching', 'failed', or 'active'.\n        --cellularBars <int>\n             If specified must be 0-4.\n        --operatorName <string>\n             Set the cellular operator/carrier name. Use '' for the empty string.\n        --batteryState <state>\n             If specified must be one of 'charging', 'charged', or 'discharging'.\n        --batteryLevel <int>\n             If specified must be 0-100.\n```\n\n```\n// change the `dataNetwork` from `wifi` to `4g`\n➜  ~ xcrun simctl status_bar booted override --dataNetwork '4g'\n```\n\n```\nxcrun simctl status_bar booted override --time 15:42 --cellularBars 1 --dataNetwork '3g' --wifiMode 'failed' --batteryState 'charging'\n```\n![status bar](status_bar_test.png)\n\nand use `clear` option to clear all the settings.\n\n```\nxcrun simctl status_bar booted clear\n```\n\nhttps://developer.apple.com/videos/play/wwdc2020/10647/\n\n### Record Video \n\nWe can run `xcrun simctl io --help` to see more. \n\n```\nxcrun simctl io <device> recordVideo <file>\n```\n\n```\nxcrun simctl io booted recordVideo video.mp4\n```\nThis command records the content of the screen of the current booted simulator, and save it to the video.mp4 file.  To stop recording, we have to use `ctl+c` in the terminal. \n\n```\nxcrun simctl io booted recordVideo  -f video.mp4\n```\n`recordVideo` cannot save recorded video output into a file that already exists unless we use  `-f` flag to override the existing file. \n\n```\nxcrun simctl io booted recordVideo video.mp4 --codec h264 --mask ignored video.mp4\n```\n - By default, codec type is `hevc`. \n - Ignore the mask when the mask is rendered black because of compatibility issues. \n\n\nAnd we can also capture the out of the external display of the simulator. \n```\nxcrun simctl io booted recordVideo --display external external.mp4 \n```\n\n![](record_video.gif)\n\n### Other useful commands\n\n```\n// Open a URL in a device.\nsimctl openurl <device> <URL>\n// add a photo or movie to the Photos library of the specified simulator \nxcrun simctl addmedia <device> <file1> <file2>\n// Set up a device IO operation. screenshot or recordVideo \nxcrun simctl io <device> screenshot <output.png>\n\n```\n\n> Ref: \n> https://developer.apple.com/videos/play/wwdc2019/418/\n> https://www.iosdev.recipes/simctl/\n> https://nshipster.com/simctl/ \n> https://developer.apple.com/documentation/xcode_release_notes/xcode_11_4_release_notes\n","tags":["WWDC","Debug","Simulator"],"categories":["iOS"]},{"title":"Understand onViewableItemsChanged in FlatList","url":"/2020/01/21/onViewableItemsChanged/","content":"\n## What is onViewableItemsChanged\n\n`onViewableItemsChanged` is a prop in [VirtualizedList](https://facebook.github.io/react-native/docs/virtualizedlist#onviewableitemschanged) and [FlatList](https://facebook.github.io/react-native/docs/flatlist#onviewableitemschanged). When we scroll a FlatList, the items showing on the FlatList change. Then, this function is called, telling you what current `viewableItems` are and what `changed` items are. \n\nThis function should be used together with [viewabilityConfig](https://facebook.github.io/react-native/docs/virtualizedlist#viewabilityconfig). A specific `onViewableItemsChanged` will be called when its corresponding `ViewabilityConfig`'s conditions are met.\n\nHere is [ViewabilityConfig](https://facebook.github.io/react-native/docs/flatlist#viewabilityconfig)\n```js \nexport type ViewabilityConfig = {\n  /**\n   * Minimum amount of time (in milliseconds) that an item must be physically viewable before the\n   * viewability callback will be fired. A high number means that scrolling through content without\n   * stopping will not mark the content as viewable.\n   */\n  minimumViewTime?: number,\n\n  /**\n   * Percent of viewport that must be covered for a partially occluded item to count as\n   * \"viewable\", 0-100. Fully visible items are always considered viewable. A value of 0 means\n   * that a single pixel in the viewport makes the item viewable, and a value of 100 means that\n   * an item must be either entirely visible or cover the entire viewport to count as viewable.\n   */\n  viewAreaCoveragePercentThreshold?: number,\n\n  /**\n   * Similar to `viewAreaPercentThreshold`, but considers the percent of the item that is visible,\n   * rather than the fraction of the viewable area it covers.\n   */\n  itemVisiblePercentThreshold?: number,\n\n  /**\n   * Nothing is considered viewable until the user scrolls or `recordInteraction` is called after\n   * render.\n   */\n  waitForInteraction?: boolean,\n|};\n```\nHere is the type of `onViewableItemsChanged` function: \n```js\n /**\n   * Called when the viewability of rows changes, as defined by the\n   * `viewabilityConfig` prop.\n   */\n  onViewableItemsChanged?: ?(info: {\n    viewableItems: Array<ViewToken>,\n    changed: Array<ViewToken>,\n    ...\n  }) => void,\n  \nexport type ViewToken = {\n  item: any,\n  // The key of this item\n  key: string,\n  index: ?number,\n  // indicated whether this item is viewable or not\n  isViewable: boolean,\n  section?: any,\n  ...\n};\n```\n\n## How to use it\n\nLet's look at two simple example.\n\n```javascript\n  viewabilityConfig = {\n    waitForInteraction: true,\n    // At least one of the viewAreaCoveragePercentThreshold or itemVisiblePercentThreshold is required.\n    viewAreaCoveragePercentThreshold: 95,\n    itemVisiblePercentThreshold: 75\n  }\n\n  onViewableItemsChanged = ({viewableItems, changed}) => {\n    console.log(\"Visible items are\", viewableItems);\n    console.log(\"Changed in this iteration\", changed);\n  };\n\n  render() {\n    return (\n      <FlatList\n        viewabilityConfig={this.viewabilityConfig}\n        onViewableItemsChanged={this.onViewableItemsChanged}\n        data={this._items}\n        renderItem={this._renderItem}\n        keyExtractor={item => item.id}\n      />\n    )\n  }\n```\n\nBesides, supposed you have to implement different logic for items with 60% viewable region and those with 75% viewable region. You can use `viewabilityConfigCallbackPairs`, which contains an list of key/value objects, which define different `viewability` configurations and `onViewableItemsChanged` callbacks.  \n\n```javascript\n<FlatList\n    data={this._items}\n    renderItem={this._renderItem}\n    keyExtractor={(item) => item.id }\n    viewabilityConfigCallbackPairs={this._viewabilityConfigCallbackPairs}\n/>\n\nthis._viewabilityConfigCallbackPairs = [{\n    viewabilityConfig: {\n      minimumViewTime: 600,\n      itemVisiblePercentThreshold: 60\n    },\n    onViewableItemsChanged: this.handleItemsPartiallyVisible60\n  },\n  {\n    viewabilityConfig: {\n      minimumViewTime: 700,\n      itemVisiblePercentThreshold: 75\n    },\n    onViewableItemsChanged: this.handleItemsPartiallyVisible75\n  }\n];\n```\n\n## How does onViewableItemsChanged works\n\n### Viewable Region \n\n  The layout and viewable region information for VirtualizedList is stored in `_scrollMetrics` object. Through the `nativeEvent` in `onScroll` callback, VirtualizedList gets these layout information.\n\n```js\nconst timestamp = e.timeStamp;\nlet visibleLength = this._selectLength(e.nativeEvent.layoutMeasurement);\nlet contentLength = this._selectLength(e.nativeEvent.contentSize);\nlet offset = this._selectOffset(e.nativeEvent.contentOffset);\nlet dOffset = offset - this._scrollMetrics.offset;\n\n// ... more code here\n\n this._scrollMetrics = {\n      contentLength,\n      dt,\n      dOffset,\n      offset,\n      timestamp,\n      velocity,\n      visibleLength,\n    };\n\n```\n\nIf it is a vertical VirtualizedList, the  `layout.layoutMeasurement.height` in the `nativeEvent` is assigned to `visibleLength`; which is the height of viewable region here.  Also, in a vertical VirtualizedList, the  `layout.layoutMeasurement.height`  is equal to viewportHeight.\n\n![5d152b82.png](/img/9af4f3b0-fe64-4a98-b94e-d456f65ae7cc/5d152b82.png)\n\n### Overview \n\n![a0336b02.png](/img/9af4f3b0-fe64-4a98-b94e-d456f65ae7cc/a0336b02.png)\n\n#### Different `viewabilityConfig`  in one `VirtualizedList`  \n\n`_viewabilityTuples` is an array inside `VirtualizedList` to store `ViewabilityHelper/onViewableItemsChanged` pairs. This array is initialized in the `constructor` function.\n\n```js\n_viewabilityTuples: Array<ViewabilityHelperCallbackTuple> = [];\n\ntype ViewabilityHelperCallbackTuple = {\n  viewabilityHelper: ViewabilityHelper,\n  onViewableItemsChanged: (info: {\n    viewableItems: Array<ViewToken>,\n    changed: Array<ViewToken>,\n    ...\n  }) => void,\n  ...\n};\n```\n\nIf you define [viewabilityConfigCallbackPairs](https://facebook.github.io/react-native/docs/flatlist#viewabilityconfigcallbackpairs),  each `viewabilityConfig` will be used to initialize a different `ViewabilityHelper` object.\n\n[ref code](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/VirtualizedList.js#L743).\n\n```js\n if (this.props.viewabilityConfigCallbackPairs) {\n      this._viewabilityTuples = this.props.viewabilityConfigCallbackPairs.map(\n        pair => ({\n          viewabilityHelper: new ViewabilityHelper(pair.viewabilityConfig),\n          onViewableItemsChanged: pair.onViewableItemsChanged,\n        }),\n      );\n    } else if (this.props.onViewableItemsChanged) {\n      this._viewabilityTuples.push({\n        viewabilityHelper: new ViewabilityHelper(this.props.viewabilityConfig),\n        onViewableItemsChanged: this.props.onViewableItemsChanged,\n      });\n    }\n\n```\n\n`ViewabilityHelper` is `a utility class for calculating viewable items based on the viewabilityConfig and metrics, like the scroll position and layout.`\n\nAs I mentioned before, in a `VirtualizedList` could has several `ViewabilityHelper` objects in `_viewabilityTuples`, containing different `viewabilityConfig` to handle different viewability conditions. Let's take a look at some important props in `ViewabilityHelper`.\n\n```js\nclass ViewabilityHelper {\n  _config: ViewabilityConfig;\n  _hasInteracted: boolean = false;\n  /* A set of `timeoutID`, used for memory management */\n  _timers: Set<number> = new Set();\n  // Indexes of the viewable items\n  _viewableIndices: Array<number> = [];\n  // A map for viewable items\n  _viewableItems: Map<string, ViewToken> = new Map();\n}\n```\n\n#### Items' layout\n\nIn the overview graph, you can see a func `_updateViewableItems` called in many scenarios. For example, it is called in `onScroll` callback. Then, It calls `viewabilityHelper.onUpdate` to find out the viewable items, which appear in the viewport for VirtualizedList.\n\n```js\n_updateViewableItems(data: any) {\n    const {getItemCount} = this.props;\n\n    this._viewabilityTuples.forEach(tuple => {\n      tuple.viewabilityHelper.onUpdate(\n        getItemCount(data),\n        // contentOffset of the list \n        this._scrollMetrics.offset,\n        // 🌟 viewportHeight \n        this._scrollMetrics.visibleLength, \n        this._getFrameMetrics,\n        this._createViewToken,\n        tuple.onViewableItemsChanged,\n        this.state,\n      );\n    });\n  }\n\n```\n- `this._scrollMetrics.visibleLength` is used as `viewportHeight`\n- `this._createViewToken` is used to construct a `ViewToken` object, which contains `item` data, `index`, `key` and `isViewable` flag of the `item`. \n- [this._getFrameMetrics](1864) is a function to get layout information of the item cell by index. The item layout is from `getItemLayout` prop of  `VirtualizedList` or `this._frames` map. `this._frames` stores the itemKey/itemLayout pairs.  \n\n```js\n// this._frames stores the item cell layout info\n{ [cellKey]: {\n      // offset of the item cell\n      offset: number, \n      // length of the item cell. width or height determined by the direction of the VirtualizedList\n      length: number, \n      index: number,\n      inLayout: boolean,\n    }\n}\n```\n\n- By `this.state`, we know the range of the rendered items by  `first` and `last` value. `VirtualizedList` updates these two values when the rendered items are changed.\n\n```js\ntype State = {\n  // The range of the rendered items, \n  // used for the optimization to reduce the scan size\n  first: number,\n  last: number,\n  ...\n};\n```\n\n### How to find out viewable items\n \nIn `onUpdate` method, it calls `computeViewableItems` to get `viewableIndices`. `viewableIndices` is an array of indexes of the viewable items.  So, how does `computeViewableItems`  work?  \n\n#### How to get the indexes of viewable items\n\nIn `computeViewableItems` in the `ViewabilityHelper` class, it iterates items from `${first}` to `${last}`. If an item is viewable, it will be stored in an array named `viewableIndices`.\n\n```js\n  for (let idx = first; idx <= last; idx++) {\n      const metrics = getFrameMetrics(idx);\n      if (!metrics) {\n        continue;\n      }\n      // The top of current item cell, relative to the screen coordinate\n      const top = metrics.offset - scrollOffset;\n      // The bottom of current item cell, relative to the screen coordinate\n      const bottom = top + metrics.length;\n      if (top < viewportHeight && bottom > 0) {\n        firstVisible = idx;\n        if (\n          _isViewable(\n            viewAreaMode,\n            viewablePercentThreshold,\n            top,\n            bottom,\n            viewportHeight,\n            metrics.length,\n          )\n        ) {\n          viewableIndices.push(idx);\n        }\n      } else if (firstVisible >= 0) {\n        break;\n      }\n    }\n    return viewableIndices;\n  }\n```\n\nFrom the code, we can see the `top` and `bottom` value is related to the screen coordinate. I drew a graph to show the relationship between `metrics.offset`, `scrollOffset`, `metrics.length` , `top` and `bottom`, to help you better understand the above code.\n\n![layout.png](/img/9af4f3b0-fe64-4a98-b94e-d456f65ae7cc/3252d60e.png)\n\n### What kind of item is viewable\n\n An item is said to be viewable when it meets the following conditions\n for longer than `${minimumViewTime}` milliseconds (after an interaction if `waitForInteraction`\n is true):\n \n1. the fraction of the item visible in the view area >= `itemVisiblePercentThreshold`.\nWhen it comes to the fraction of the item visible in the view area, we need to care about\n cases shown in the following graph. RN use `Math.min(bottom, viewportHeight) - Math.max(top, 0)` to calculate the viewable length. \n    \n  ![partial](viewable-partial.png)\n\n1. Entirely visible on screen when the height of a item is bigger than the `viewportHeight`.\n\n![7c4f2df0.png](entire-viewable.png)\n\n[ref](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/ViewabilityHelper.js#L64)\n\n```js\nfunction _isViewable(\n  viewAreaMode: boolean,\n  viewablePercentThreshold: number,\n  top: number,\n  bottom: number,\n  viewportHeight: number,\n  itemLength: number,\n): boolean {\n  if (_isEntirelyVisible(top, bottom, viewportHeight)) {\n    // Entirely visible \n    return true;\n  } else {\n    // Get viewable height of this item cell \n    const pixels = _getPixelsVisible(top, bottom, viewportHeight);\n    // Get the viewable percentage of this item cell \n    const percent =\n      100 * (viewAreaMode ? pixels / viewportHeight : pixels / itemLength);\n    return percent >= viewablePercentThreshold;\n  }\n}\n\nfunction _getPixelsVisible(\n  top: number,\n  bottom: number,\n  viewportHeight: number,\n): number {\n  const visibleHeight = Math.min(bottom, viewportHeight) - Math.max(top, 0);\n  return Math.max(0, visibleHeight);\n}\n\nfunction _isEntirelyVisible(\n  top: number,\n  bottom: number,\n  viewportHeight: number,\n): boolean {\n  return top >= 0 && bottom <= viewportHeight && bottom > top;\n}\n```\n[code here](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/ViewabilityHelper.js#L300)\n\n### Timer and Schedule \n\nIn [`onUpdate` func in ViewabilityHelper](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/ViewabilityHelper.js#L228), if we define `minimumViewTime` value, the `_onUpdateSync` is scheduled to be called. It is the handler of the `timeout`.\n\n```js\n this._viewableIndices = viewableIndices;\n if (this._config.minimumViewTime) {\n      const handle = setTimeout(() => {\n        this._timers.delete(handle);\n        // filter out  indices that have gone out of view after minimumViewTime \n        // figure out which items are gone, which items are showing \n        this._onUpdateSync(\n          viewableIndices,\n          onViewableItemsChanged,\n          createViewToken,\n        );\n      }, this._config.minimumViewTime);\n      this._timers.add(handle);\n    } else {\n      this._onUpdateSync(\n        viewableIndices,\n        onViewableItemsChanged,\n        createViewToken,\n      );\n    }\n```\n\nAnd, If after a few seconds, ${minimumViewTime}, if some items aren't longer viewable, the [_onUpdateSync](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/ViewabilityHelper.js#L267) func, filter out these indices that have gone out of viewport.\n\n```js\n    // Filter out indices that have gone out of view after `minimumViewTime`\n    viewableIndicesToCheck = viewableIndicesToCheck.filter(ii =>\n      this._viewableIndices.includes(ii),\n    );\n\n```\n![99830c30.png](/img/9af4f3b0-fe64-4a98-b94e-d456f65ae7cc/99830c30.png)\n\nIn the above graph, at first, the `_viewableIndices` is from 1 to 9. Then the user scrolls the `VirtualizedList`  and the `_onUpdateSync` is triggered after `minimumViewTime`. At this moment, the current `_viewableIndices` is from 2 to 10. So the item indexed 1 is filtered out.\n\n### 6. How to get changed items \n\nComparing with the last time when  `onViewableItemsChanged` is triggered, at this time to trigger  `onViewableItemsChanged`. Some viewable items will be out of the screen, some hidden items will become viewable. In `_onUpdateSync` function, the `preItems`  map stores the information about previous visible items, the previous means last time when `VirtualizedList` calls `onViewableItemsChanged`. Now it has a `nextItems` map, which stores the information about viewable items this time. Then it figures out the `changed` items by comparing these two maps. Then, it calls `onViewableItemsChanged`, passing `viewableItems` and `changed` items. \n\n```js\n_onUpdateSync(\n    viewableIndicesToCheck,\n    onViewableItemsChanged,\n    createViewToken,\n  ) {\n    // Filter out indices that have gone out of view since this call was scheduled.\n    viewableIndicesToCheck = viewableIndicesToCheck.filter(ii =>\n      this._viewableIndices.includes(ii),\n    );\n    const prevItems = this._viewableItems;\n    // Using map, so the time complexity would be o(n) \n    const nextItems = new Map(\n      viewableIndicesToCheck.map(ii => {\n        const viewable = createViewToken(ii, true);\n        return [viewable.key, viewable];\n      }),\n    );\n\n    const changed = [];\n    for (const [key, viewable] of nextItems) {\n      if (!prevItems.has(key)) {\n        changed.push(viewable);\n      }\n    }\n    for (const [key, viewable] of prevItems) {\n      if (!nextItems.has(key)) {\n        changed.push({...viewable, isViewable: false});\n      }\n    }\n    if (changed.length > 0) {\n      this._viewableItems = nextItems;\n      onViewableItemsChanged({\n        viewableItems: Array.from(nextItems.values()),\n        changed,\n        viewabilityConfig: this._config,\n      });\n    }\n  }\n}\n```","tags":["Dive into React Native"],"categories":["React Native"]},{"title":"Gaussian Filter","url":"/2019/07/12/Gaussian-Filter/","content":"\n高斯函数在学术领域运用的非常广泛。 写工程产品的时候，经常用它来去除图片或者视频的噪音，平滑图片, Blur处理。我们今天来看看高斯滤波, Gaussian Filter。 \n**1D的高斯函数**\n一维的高斯函数（或者叫正态分布）方程跟图形如下: \n$$G(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}}$$\n![image.png](/img/Gaussian-Filter/gaussian.png)\n\n$\\mu$是均值；$\\sigma$ 是标准方差。它有个重要特点是 -$\\sigma$ 到+$\\sigma$ 之间的G(x)与x轴围成的面积占全部面积的68.2%.  -2$\\sigma$ 到+2$\\sigma$之间的面积占95%。-3$\\sigma$ 到+3$\\sigma$之间的面积占99.7%。\n如果我们给-3$\\sigma$ 到+3$\\sigma$区间, 它几乎包括了所有可能的点。这个特性对Filter kernel的生成很重要。\n\n\n**2D的高斯函数**\n$$G(x, y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}$$\n\n![image.png](/img/Gaussian-Filter/2d-gaussian.png)\n\n\n**所谓高斯滤波操作，其实就是用高斯函数对image做卷积计算**。但一般图像在计算机中一般是离散的3D矩阵，而高斯函数是连续函数，所以我们要从连续高斯函数中采样生成离散的2D矩阵，即Gaussian Filter Kernel。 我们可以控制Kernal的size，让它的点都落在-3$\\sigma$ 到+3$\\sigma$区间内。\n### 生成高斯kernel \n\n```c++\n// Function to create Gaussian filter; sigma is standard deviation\nMatrix getGaussian(int height, int width, double sigma)\n{\n    Matrix kernel(height, Array(width));\n    // sum is for normalization \n    double sum=0.0;\n    int i,j;\n    \n   // generating the kernel \n    for (i=0 ; i<height ; i++) {\n        for (j=0 ; j<width ; j++) {\n            // using gaussian function to generate gaussian filter \n            kernel[i][j] = exp(-(i*i+j*j)/(2*sigma*sigma))/(2*M_PI*sigma*sigma);\n            sum += kernel[i][j];\n        }\n    }\n   \n   // normalising the Kernel \n    for (i=0 ; i<height ; i++) {\n        for (j=0 ; j<width ; j++) {\n            kernel[i][j] /= sum;\n        }\n    }\n\n    return kernel;\n}\n```\n[代码来源](https://gist.github.com/OmarAflak/aca9d0dc8d583ff5a5dc16ca5cdda86a)\n比如，我们用高斯函数生成了一个5x5， $\\sigma$是1的高斯核2D矩阵:\n![image.png](/img/Gaussian-Filter/gaussian_matrix.png)\n它有几个特点： \n1. 最中间的值最大，值向周围递减\n2. $\\sigma$越大，高斯函数的峰越宽，临接的数值差越大\n\n### 对图片应用高斯Filter\n对某个像素点image[i][j]，Fitler对原图对应的像素点做点乘，相加。 生成新的值。\n![https://www.youtube.com/watch?v=C_zFhWdM4ic](/img/Gaussian-Filter/convoltion.gif)\n[材料来源](https://www.youtube.com/watch?v=C_zFhWdM4ic)\n```c++\nImage applyFilter(Image &image, Matrix &filter){\n    assert(image.size()==3 && filter.size()!=0);\n\n    int height = image[0].size();\n    int width = image[0][0].size();\n    int filterHeight = filter.size();\n    int filterWidth = filter[0].size();\n    int newImageHeight = height-filterHeight+1;\n    int newImageWidth = width-filterWidth+1;\n    int d,i,j,h,w;\n\n    Image newImage(3, Matrix(newImageHeight, Array(newImageWidth)));\n    \n   // iter the image pixel\n    for (d=0 ; d<3 ; d++) {\n        for (i=0 ; i<newImageHeight ; i++) {\n            for (j=0 ; j<newImageWidth ; j++) {\n                // using filter convolute the image matrix\n                for (h=i ; h<i+filterHeight ; h++) {\n                    for (w=j ; w<j+filterWidth ; w++) {\n                        newImage[d][i][j] += filter[h-i][w-j]*image[d][h][w];\n                    }\n                }\n            }\n        }\n    }\n\n    return newImage;\n}\n```\n如下图，图片被平滑处理了。\n![image.png](/img/Gaussian-Filter/blur_image.png)\n\n#### More: \n[https://gist.github.com/OmarAflak/aca9d0dc8d583ff5a5dc16ca5cdda86a](https://gist.github.com/OmarAflak/aca9d0dc8d583ff5a5dc16ca5cdda86a)\n\n","tags":["CV"],"categories":["Algorithm"]},{"title":"792. Number of Matching Subsequences","url":"/2019/07/06/792-Number-of-Matching-Subsequences/","content":"\n## [题目](https://leetcode-cn.com/problems/number-of-matching-subsequences/)\n\n## Solution 1 \n思路：存储 + 二分查找\n1. 首先将字符一集对应的下标存储在26 * n的二维数组中。比如对字符串 'abcdea'存储为\n\n| Char | Index |\n| --- | --- |\n| 0 | [0, 5] |\n| 1 | [1] |\n| 2 | [2] |\n| 3 | [3] |\n| 4 | [4] |\n| ... |  |\n| 25 |  |\n\n对应代码: \n\n```c++\n  vector<vector<int>> store(26, vector<int>());\n    for (int i = 0; i < S.size(); ++i) {\n        // 存储字母跟index\n        store[S[i] - 'a'].push_back(i);\n    }\n```\n\n1. 对某个word，查找它的字符是否在二维数组中。\n\n```c++\nint numMatchingSubseq(string S, vector<string>& words) {\n    vector<vector<int>> store(26, vector<int>());\n    for (int i = 0; i < S.size(); ++i) {\n        // 存储字母跟index\n        store[S[i] - 'a'].push_back(i);\n    }\n\n    int res = 0;\n    for (auto &word: words) {\n        int x = -1;\n        bool found = true;\n        for (auto c: word) {\n            // search\n            auto it = upper_bound(store[c - 'a'].begin(), store[c - 'a'].end(), x);\n            if (it == store[c - 'a'].end()) {\n                found = false;\n                break;\n            } else {\n                // 更新最新的下标位置\n                x = *it;\n            }\n        }\n        if (found) res++;\n    }\n\n    return res;\n}\n```\n## Solution 2 \n第二种思路，来自[Stefan大神](https://leetcode.com/problems/number-of-matching-subsequences/discuss/117634/Efficient-and-simple-go-through-words-in-parallel-with-explanation)。 \n这种思路，存储的是words中等待匹配的字符的index pair。比如 words = [\"a\", \"bb\", \"acd\", \"ace\"]存储的结果是: \n|  idx | pair |\n| --- | --- |\n| ‘a' | [(0, 1), (2, 1), (3, 1)] |\n| ‘b' | [(1, 1)] |\n\n\n\n```c++\nint numMatchingSubseq(string S, vector<string>& words) {\n    vector<pair<int, int>> waiting[128];\n    for (int i = 0; i < words.size(); i++)\n        waiting[words[i][0]].emplace_back(i, 1);\n    for (char c : S) {\n        auto advance = waiting[c];\n        waiting[c].clear();\n        for (auto it : advance)\n            waiting[words[it.first][it.second++]].push_back(it);\n    }\n\n    return waiting[0].size();\n}\n```\n\n"},{"title":"1011. Capacity To Ship Packages Within D Days","url":"/2019/06/14/1011-Capacity-To-Ship-Packages-Within-D-Days/","content":"## [题目](https://leetcode.com/problems/capacity-to-ship-packages-within-d-days/)\n## 分析\n来自Vlad神的解答https://leetcode.com/problems/capacity-to-ship-packages-within-d-days/discuss/256737/C%2B%2B-Binary-Search \n\n先定下可能的承重范围: \n1. 最大 maxCap 是所有包裹的重量和\n2. 最小 minCap = max{ maxCap/D, 最重的包裹重量) \n3. 用 Binary Search 查找 `the least weight capacity of the ship`, 该船能在D天内运送完所有货物\n\n```c++\n// 求载货力为 capacity 的船运完所有货物的天数\nint countDays(vector<int>& weights, int capacity) {\n    int count = 1, load = 0;\n    for (auto w: weights) {\n        load += w;\n        if (load > capacity) {\n            // 超过载重能力，第二天继续运载\n            load = w;\n            count++;\n        }\n    }\n\n    return count;\n}\n\nint shipWithinDays(vector<int>& weights, int D) {\n    auto maxCap = std::accumulate(weights.begin(), weights.end(), 0);\n    auto minCap = max(*max_element(weights.begin(), weights.end()), maxCap / D);\n    // Binary Search \n    while (minCap < maxCap) {\n        int mid = (minCap + maxCap) / 2;\n        if (countDays(weights, mid) <= D) {\n            maxCap = mid;\n        } else {\n            minCap = mid + 1;\n        }\n    }\n\n    return minCap;\n}\n\n```","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode:1014. Best Sightseeing Pair","url":"/2019/06/11/LeetCode-1014-Best-Sightseeing-Pair/","content":"\n## 题目： [1014. Best Sightseeing Pair](https://leetcode.com/problems/best-sightseeing-pair/)\n \n\n### 分析\n这道题求 `the maximum score of a pair of sightseeing spots`; score = A[i] + A[j] + i - j)。 是个最优解问题。  \n迭代中，当前idx为i; 要考虑 (0, i-1)的数中对score增益最大的数的下标是max_idx。 计算 (max_idx, i)的score， 并跟之前最大值做比较。\n\n```c++\nint maxScoreSightseeingPair(vector<int> & A) {\n    // 2<= A.length <= 50000\n    int max_idx = 0, res = A[0], inc = 0;\n    for (int i = 1; i < A.size(); ++i) {\n        inc = A[max_idx] - i + max_idx;\n        res = max(res, A[i] + inc);\n        max_idx = A[i] > inc ? i : max_idx;\n    }\n\n    return res;\n}\n```\n\n**更为简约的写法：**\nmax_inc每次迭代后都自减1，是因为进入下一次迭代i+1的时候，它对分数的增益只剩下了A[max_inc] + i - (i+1)。\n```c++\nint maxScoreSightseeingPair2(vector<int>& A) {\n    int max_inc = A[0] - 1, res = 0;\n    for (int i = 1; i < A.size(); ++i, max_inc--) {\n        res = max(res, max_inc + A[i]);\n        max_inc = max(A[i], max_inc);\n    }\n\n    return res;\n}\n```\n\n时间复杂度: $o(n)$","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"ExpoKit模式配置Push Notification","url":"/2019/06/10/React-Native-ExpoKit-Notification/","content":"\nExpo sdk已经有一套Push Notifications的方案，接入方便, 但需要服务端配合接入对应sdk.而expo-server-sdk中默认使用Google Cloud Messaging 和 APNS； 因为Android国内无法用谷歌的服务，再加上没有服务端对应开发语言的sdk, 我们最后还是选了传统的方式。\n\n## Expo Eject \n用expo创建的RN项目已经不再有ios/ & android/的工程配置文件夹。 所以我们要先用 `expo eject`命名生成iOS跟Android的工程配置文件, 。\n\n`expo eject`会改变开发流程，比如，要运行一个项目，不止要`expo start`， 还要用Xcode或者AndroidStudio Run一个native项目。 所以真的要通读这个文档，仔细考虑要不要这么做[Ejecting to ExpoKit - Expo Documentation](https://docs.expo.io/versions/latest/expokit/eject/#__next)\n\n1. 首先，我们要check一下app.json对不对https://docs.expo.io/versions/latest/distribution/building-standalone-apps/#2-configure-appjson\n\n2. 接着，运行`expo eject`命令，会有如下提示, 我选第三个，ExpoKit。 ExpoKit是Objective-C 和Java库， 将native开发跟expo平台开发结合起来。\n\n```\nIt's recommended to commit all your changes before proceeding,\nso you can revert the changes made by this command if necessary.\n\n? How would you like to eject your app?\n  Read more: https://docs.expo.io/versions/latest/expokit/eject/\n  React Native: I'd like a regular React Native project.\n❯ ExpoKit: I'll create or log in with an Expo account to use React Native and the Expo SDK.\n  Cancel: I'll continue with my current project structure.\n```\n你会发现多了两个目录\n```\nrn-project/\n  - ios/\n  - android/\n```\n## 运行Native工程\n\nReact Native packager方面，要像以前那样，运行`expo start`。 \n接着配置native工程。以iOS为例: \n\n1. 进入ios文件夹, pod install (如果遇到undefined method'native_target', 请参考[Issues · expo/expo · GitHub](https://github.com/expo/expo/issues/2401d), 将cocoapods降到1.5.3版本。 \n2. 打开xcwordspace文件，正常buid & run iOS项目\n\n app启动的时候，它会自动请求并加载JS bundle。如果我们修改了js文件，再保存，hot-update也生效的.\n \n## 配置 PushNotificationIOS \n[官方教程PushNotificationIOS · React Native](https://facebook.github.io/react-native/docs/pushnotificationios) 很是麻烦，还容易报一堆这个那个找不到的错误。\n\n```\nRCTPushNotificationManager.h not found\nReact/RCTEventEmitter.h file not found\n```\n其实它本质上是xcodeproject要手动link RCTPushNotification lib，我们大可以直接修改Podfile文件，如下: \n- 最后一行，添加`RCTPushNotification`\n- 再run一下`pod install`\n- 重新`build`.\n\n```\n  pod 'React',\n    :path => \"../node_modules/react-native\",\n    :inhibit_warnings => true,\n    :subspecs => [\n      \"Core\",\n      \"ART\",\n      \"RCTActionSheet\",\n      \"RCTAnimation\",\n      \"RCTCameraRoll\",\n      \"RCTGeolocation\",\n      \"RCTImage\",\n      \"RCTNetwork\",\n      \"RCTText\",\n      \"RCTVibration\",\n      \"RCTWebSocket\",\n      \"DevSupport\",\n      \"CxxBridge\",\n      \"RCTPushNotification\"\n    ]\n```","categories":["React Native"]},{"title":"理解手机GPS定位原理","url":"/2019/06/08/理解GPS定位原理/","content":"\n本文取材自 TED教学视频[How does your smartphone know your location? - Wilton L. Virgo](https://www.youtube.com/watch?v=70cDSUI4XKE)\n我们的手机是如何准确定位的呢？ 答案在离我们2000多英里的卫星上。\n\n第一个问题： 为啥卫星上的时间对GPS定位如此重要？ 因为我们要知道手机跟卫星的距离。 每个卫星在不断对外广播信号。信号中记录自己的创建时间。\n\n\n![48bce392.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/48bce392.png)\n\n手机收到信号后，利用收到信号的到达时间， 计算自己跟卫星的距离: \n\n$$distance = c * \\Delta T $$\n\nc: 光的速度\n$\\Delta T$: 信号传播的时间间隔 $time_{arrive} - time_{create}$\n\n但是c = 299,792,458 m/s, 非常大。 如果用秒做单位计算$\\Delta T$， 地球上所有点，甚至有些远离我们的位置，计算出来的distance都是一样的值。 \n\n![f8edfbb6.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/f8edfbb6.png)\n\n\n所以我们需要非常非常非常精确的时钟计算时间. 于是原子钟粉墨登场. 就像机械钟靠嘀嗒嘀嗒摇摆来计时， 原子钟也有这种间隔时间固定的滴答滴答计时方式。 \n\n## 原子钟\n\n![782d2620.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/782d2620.png)\n原子钟依赖原子跃迁所释放或吸收的电磁波来计时。原子在一个轨道跑了一圈后，跃迁到另一个轨道的时候会以电磁波形式释放出能量。\n\n![a68ec7af.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/a68ec7af.png)\n\n能量计算公式： $\\Delta E = h \\nu$ $\\Delta E$ 变化的能量; h是常量(h=6.626x$10^{-34}$ Js)。 $\\nu$是频率。 比如铯原子钟，它的频率是个固定值 9,192,631,770Hz，你可以想象为一个每秒跑9billion圈的时钟。所以用原子钟可以每秒精确到 1/1billion。 \n\n![0bc32fc3.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/ca6ea804.png)\n这张图的detector是用来检测probe laser固定频率发出的电磁波。\n\n\n有了精确的时间，我们可以知道手机跟卫星的距离。 以卫星为中心，distance为半径画圆(球)\n\n![f58c51ad.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/f58c51ad.png)\n\n如果多几个卫星，我们可以用几何公式计算出它们的空间交叉点\n\n![293478f1.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/293478f1.png)\n\n![6cbd0ed3.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/6cbd0ed3.png)\n\n","categories":["LBS"]},{"title":"714. Best Time to Buy and Sell Stock with Transaction Fee","url":"/2019/06/06/714-Best-Time-to-Buy-and-Sell-Stock-with-Transaction-Fee/","content":"\n##  [题目](https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee)\n\n## 分析\n\n### 定义两个状态变量: \n- buy_profit: 若i-1天，持有股票，最大利润是 $(buy_profit)\n- sell_profit: 若i-1天，卖出股票, 最大利润是 $(sell_profit)\n\n### 买卖利润情况： \n\n**最开始**: i == 0;  `int buy_profit = -prices[0], sell_profit = 0`\n**第i天**: \n\n- 当天买: \n    - 维持i-1天持有, 不变； $buy\\_profit_i == buy\\_profit_{i-1}$ \n    - i-1天卖出，i天买进 (因为题目要求每次只能买1 share of stock, 买入前必须把手上的stock都卖出); $buy\\_profit_i = sell\\_profit_{i-1} - prices[i]$\n- 当天卖:  \n    - i-1天持有，i天卖出; 当天的利润为 $sell\\_profit_i=buy\\_profit_i-1 + prices[i] - fee$\n    - i-1天已经卖出，当天不操作；利润为 $sell\\_profit_i == sell\\_profit_{i-1}$ \n    \n每个i迭代，我们都要考虑这四种情况，计算出buy_profit跟sell_profit的局部最优. \n\n\n### 例子\nInput: prices = [1, 3, 2, 8, 4, 9], fee = 2\n\n最优操作： \n\n|  | 1 | 3 | 2 | 8 | 4 | 9 |\n| --- | --- | --- | --- | --- | --- | --- |\n| max buy_profit | -1 | -1 max{-1, -3} | -1 max{-1, -2}| -1 max{-1, 8}| 1 max{1, -4} | 1 max{1, -4}|\n| max sell_profit | 0 | 0 max{0, 0}| 0 max{0, -1}| 5 max{0, 5}| 5 max{5, 3}| 8 {5, 8}|\n\n### 贪心算法\nA greedy algorithm always makes the choice that `looks best at the moment` That is, it makes a `locally optimal choice` in the hope that this choice will `lead to a globally optimal solution`. \n\n\n## Greedy Algorithm   \n\n\n```c++\nint maxProfit(vector<int>& prices, int fee) {\n    if (prices.empty()) return 0;\n    int buy_profit = -prices[0], sell_profit = 0;\n    for (int i = 1; i < prices.size(); ++i) {\n        buy_profit = max(buy_profit, sell_profit - prices[i]);\n        sell_profit = max(sell_profit, buy_profit + prices[i] - fee);\n     }\n\n    return sell_profit;\n}\n```\n或者\n\n```c++\n    int maxProfit(vector<int>& prices, int fee) {\n      int n = prices.size();\n      if (n <= 1 ) return 0; // need at least 2 days to make a transactions\n      \n      vector<int> buys (n); // buys [i] means max money on day i ending in buy  state (have stock in hand)\n      vector<int> sells(n); // sells[i] means max money on day i ending in sell state (no stock in hand)\n      \n      buys [0] = -prices[0];\n      sells[0] = 0;\n      \n      for (int i = 1; i < n; ++i) {\n        buys [i] = max(buys [i-1], sells[i-1]-prices[i]);     // buy  state to buy  state: continue holding onto stock\n                                                              // sell state to buy  state: buy on day i\n        sells[i] = max(sells[i-1], buys [i-1]+prices[i]-fee); // sell state to sell state: continue not holding any stock\n                                                              // buy  state to sell state: sell on day i\n      }\n      return sells[n-1];\n    }\n```\n时间复杂度: $o(n)$","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode:413. Arithmetic Slices","url":"/2019/06/04/LeetCode-413-Arithmetic-Slices/","content":"\n##  [413. Arithmetic Slices](https://leetcode.com/problems/arithmetic-slices/)\n这道题，简而言之，求数组里，等差序列的个数。 \n\n比如\n```\nA = [1, 2, 3, 4]\n有3个等差数列\n[1, 2, 3], [2, 3, 4], [1, 2, 3, 4]\n```\n\n题目没有说明A是等差数列，所以也要考虑A不是等差数列，但是其子数组是等差数列的情况。\n```\nA = [1, 3, 5, 7, 9, 15, 20, 25]\n1, 3, 5\n\n3, 5, 7\n1, 3, 5, 7\n\n5, 7, 9\n3, 5, 7, 9\n1, 3, 5, 7, 9\n\n15, 20, 25\n```\n\n## Solution \n\n```c++\nint numberOfArithmeticSlices(vector<int>& A) {\n    int dp = 0;\n    int sum = 0;\n\n    for (int i = 2; i < A.size(); ++i) {\n        if (A[i] - A[i-1] == A[i-1] - A[i-2])  {\n           dp = 1+dp;\n           sum += dp;\n        } else {\n           dp = 0;\n        }\n    }\n    return sum;\n}\n```","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"ReactNative开发-神器Reactoron","url":"/2019/05/23/ReactNative-reactoron/","content":"Reactoron能改善React Native开发体验。 \n<!--more--> \n \nReactoron这个开发工具，把我们输出的日志像twitter信息流一样保存起来，等我们需要的时候，可以回过头过滤找到日志，展开日志详情查看。提高ReactNative开发效率。 看日志会特别方便，体验也不错。\n\n![image](https://github.com/infinitered/reactotron/raw/master/docs/images/quick-start-react-native/react-demo-native-reactotron.jpg)\n\n项目地址： [GitHub - infinitered/reactotron: A desktop app for inspecting your React JS and React Native projects. macOS, Linux, and Windows.](https://github.com/infinitered/reactotron)\n\n下载最新的release包，本地安装。\n\n## 使用\n\n### 1. 集成在React Native项目中\n\n```sh\nnpm i --save-dev reactotron-react-native\n// or\nyarn add reactotron-react-native --dev\n```\n\n### 2. 配置文件\n\n创建`ReactotronConfig.js`\n\n基础用法：\n```js\nimport Reactotron from 'reactotron-react-native'\n\nReactotron\n  .configure() // controls connection & communication settings\n  .useReactNative() // add all built-in react native plugins\n  .connect() // let's connect!\n```\n高级配置: \n\n```js\nimport Reactotron from 'reactotron-react-native'\n\nReactotron\n  .configure({\n    name: \"React Native Demo\"\n  })\n  .useReactNative({     \n      asyncStorage: {ignore: []},\n      networking: {\n          ignoreUrls: new RegExp(`http://127.0.0.1:19000/logs`)\n      },\n      editor: false,\n      errors: {veto: (stackFrame) => false},\n      overlay: false,})\n  .connect();\n```\n\n#### asyncStorage \n\n参数类型：\n\n```js\nexport interface AsyncStorageOptions {\n    ignore?: string[];\n}\n```\n\n`ignore`的值，传入key数组，`reactotron`不会展示这些key的存储数据\n\n#### networking\n参数类型： \n```js\nexport interface NetworkingOptions {\n    ignoreContentTypes?: RegExp; // 如果response的Content-Type匹配上这个正则表达式，不展示response，\n    ignoreUrls?: RegExp; //  要忽略的urls\n}\n```\n例子：\n```js networking({\n  ignoreContentTypes: /^(image)\\/.*$/i,\n  ignoreUrls: /\\/(logs|symbolicate)$/,\n})\n```\n\n\n#### Error \n参数类型：\n```js\nexport interface TrackGlobalErrorsOptions {\n    veto?: (frame: any) => boolean;\n}\n```\n`veto`函数，我们可以通过它指定我们不想看到的堆栈信息.这里的frame指stack frame.\n\n比如： 如下忽略报错时所有react-native module里头的stack frame.\n```js\nReactotron\n  .configure()\n  .use(trackGlobalErrors({\n    veto: frame => frame.fileName.indexOf('/node_modules/react-native/') >= 0\n   }))\n  .connect()\n```\n### 3. improt\n\n 在`App.js` 或者`index.js`文件头中引入：\n \n```js\nif(__DEV__) {\n  import('./ReactotronConfig').then(() => console.log('Reactotron Configured'))\n}\n```\n\n### 4. 打点\n\n像用`console.log`一样，调用 `Reactotron.log`\n\nReactNative项目跑起来后，可以在Reactotron面板上看到： \n\n![9b1dbee4.png](https://github.com/infinitered/reactotron/raw/master/docs/images/quick-start-react-native/hello-1.jpg)\n\n其他API： \n```js\nReactotron.log({ numbers: [1, 2, 3], boolean: false, nested: { here: 'we go' } })\n\nReactotron.warn('*glares*')\nReactotron.error('Now you\\'ve done it.')\nReactotron.display({\n  name: 'KNOCK KNOCK',\n  preview: 'Who\\'s there?',\n  value: 'Orange.'\n})\n\nReactotron.display({\n  name: 'ORANGE',\n  preview: 'Who?',\n  value: 'Orange you glad you don\\'t know me in real life?',\n  important: true\n})\n\n```\n\n## Redux的数据信息\n[reactotron/plugin-redux.md at master · infinitered/reactotron · GitHub](https://github.com/infinitered/reactotron/blob/master/docs/plugin-redux.md)\n![](https://github.com/infinitered/reactotron/raw/master/docs/images/redux/redux-keys-values.jpg)\n\n[YouTube](https://www.youtube.com/watch?v=UiPo9A9k7xc)\n\n\n","tags":["React Native Dev"],"categories":["React Native"]},{"title":"LeetCode:542. 01 Matrix-DP","url":"/2019/05/23/LeetCode-542-01-Matrix-DP/","content":"Given a matrix consists of 0 and 1, find the distance of the nearest 0 for each cell.\n\n<!--more-->\n \n\n## 题目: [01-matrix](https://leetcode.com/problems/01-matrix/)\nGiven a matrix consists of 0 and 1, find the distance of the nearest 0 for each cell.\n\nThe distance between two adjacent cells is 1.\n```\nExample:\nInput:\n[[0,0,0],\n [0,1,0],\n [1,1,1]]\n\nOutput:\n[[0,0,0],\n [0,1,0],\n [1,2,1]]\n```\n## 分析： \n题目有点没讲明白，这道题，求值为1的cell到最近的0的最短距离。\n\n这道题，我的第一想法是BFS，后来看到DP写法更优雅。[Simple-Java-solution](https://leetcode.com/problems/01-matrix/discuss/101051/Simple-Java-solution-beat-99-(use-DP))\n\n可以发现规律。对matrix[i][j], 如果知道它上下左右四个cell到0的最短距离，那么\n$$matrix[i][j] = min(left, top, right, bottom) + 1$$\n\n1. 遍历matrix矩阵，matrix[i][j]不为0，计算 leftCell 跟 topCell最小值，再加1. \n2. 再倒叙遍历matrix, matrix[i][j]不为0, 先计算rightCell 跟 topCell的最小值，再跟min(left, top)的值比较\n\n```c++\n vector<vector<int>> updateMatrix(vector<vector<int>>& matrix) {\n     if (matrix.empty()) return {};\n     int n = (int)matrix.size(), m = (int)matrix[0].size(), MAX_LEN = 10002;\n     for (int i = 0; i < n; ++i) {\n         for (int j = 0; j < m; ++j) {\n             if (matrix[i][j] != 0) {\n                 int top = (i - 1 < 0) ? MAX_LEN : matrix[i-1][j];\n                 int left = (j - 1 < 0) ? MAX_LEN : matrix[i][j-1];\n                 matrix[i][j] = 1 + min(top, left);\n             }\n         }\n    \n     for (int i = n - 1; i >= 0; i--) {\n         for (int j = m - 1; j >= 0; j--) {\n             if(matrix[i][j] != 0) {\n                 int right = (j + 1 >= m) ? MAX_LEN: matrix[i][j+1];\n                 int bottom = (i + 1 >= n) ? MAX_LEN: matrix[i+1][j];\n                 matrix[i][j] = min(min(right, bottom) + 1, matrix[i][j]);\n             }\n         }\n     }\n     return matrix;\n }\n```\n### 时间复杂度 $o(n^2)$\n### 空间复杂度 $o(1)$\n\n```\nRuntime: 184 ms, faster than 96.53% of C++ online submissions for 01 Matrix.\nMemory Usage: 20.9 MB, less than 91.39% of C++ online submissions for 01 Matrix.\n```\n有人问，为啥要两次遍历？ 不能像下面这么写吗？\n\n```c++\n// 错误的写法\n vector<vector<int>> updateMatrix(vector<vector<int>>& matrix) {\n       if (matrix.empty()) return {};\n       int n = (int)matrix.size(), m = (int)matrix[0].size();\n       for (int i = 0; i < n; ++i) {\n           for (int j = 0; j < m; ++j) {\n               if (matrix[i][j] != 0) {\n                   int top = (i - 1 < 0) ? INT32_MAX : matrix[i-1][j];\n                   int left = (j - 1 < 0) ? INT32_MAX : matrix[i][j-1];\n                   int right = (j + 1 >= m) ? INT32_MAX : matrix[i][j+1];\n                   int bottom = (i + 1 >= n) ? INT32_MAX : matrix[i+1][j];\n                   matrix[i][j] = 1 + min(min(top, left), min(right, bottom));\n               }\n           }\n       }\n       return matrix;\n   }\n```\n问题在于，顺序遍历时候，bottom跟right还没更新为正确的值。比如下图，遍历到matrix[3][0]的时候，matrix[3, 1] 还是1， 而matrix[2][0] == 2; 结果就出错了。\n```\n0 0 0 0 0 \n1 0 0 0 0 \n1 1 1 0 0 \n1 1 1 1 0 \n```\n","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode:650. 2 Keys Keyboard","url":"/2019/05/20/LeetCode-650-2-Keys-Keyboard/","content":"\n## 题意: \nnotepad里只有一个'A'字符串。 只能允许两个操作: \n\n1. Copy All: 把notepad里所有的字符串copy\n2. Paste: 复制上次copy的内容\n\n问，最少的步骤（copy & paste) 能生成n个'A'\n\n## 分析\n\n可以发现规律: \n\n\n| n | op | cur char |\n| --- | --- | --- |\n| 2 | c | A |\n|  | p | AA |\n| 3 | c | A |\n|  | p | AA |\n|  | p | AAA |\n| 4 | c | A |\n|  | p | AA |\n|  | c | AA |\n|  | p | AAAA |\n| 5 | c | A |\n|  | p | AA |\n|  | p | AAA |\n|  | p | AAAA |\n|  | p | AAAAA |\n| 6 | c | A |\n|  | p | AA |\n|  | c | AA |\n|  | p | AAAAA |\n|  | p | AAAAAA |\n\n当n为质数， 所需最少步骤为n; 当n不是质数， 所需步骤为 n的质因数相加之和。比如6 = 2 x 3;它所需最小步骤 2+3 = 5\n\n## Solution 1： 质因数分解\n```c++\nint minSteps(int n) {\n    int ans = 0, d = 2;\n    while (n > 1) {\n        while (n % d == 0)  {\n            ans += d;\n            n /= d;\n        }\n        d++;\n    }\n\n    return ans;\n}\n```\n\n## Solution 2: \n\n```c++\nint minSteps(int n) {\n    if (n <= 1) return 0;\n    if (n <= 5) return n;\n    // n>1的操作，前两步骤都是copy & paste, 从'A'变成 'AA', 所以 cur_len == 2, res == 2, 上次copy的字符数量 == 1, 如果下一次要copy & paste, 要一次copy'AA' 2个字符  \n    int cur_len = 2, res = 2, next_cp_num = 2, copy_num = 1;\n    while (cur_len < n) {\n        if ((n - cur_len) % next_cp_num == 0) {\n           // copy + paste\n           cur_len += next_cp_num;\n           copy_num = next_cp_num;\n           // copy + paste; 2 steps\n           res += 2;\n        } else {\n            // paste the characters copied last time \n            cur_len += copy_num;\n            // only paste, 1 step\n            res += 1;\n        }\n\n        // 题目要求：Copy操作要Copy所有字符\n        next_cp_num = cur_len;\n    }\n\n    return res;\n}\n```\n","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"小白读论文:Semantic Image Synthesis with Spatially-Adaptive Normalization","url":"/2019/05/18/Semantic-Image-Synthesis-with-Spatially-Adaptive-Normalization/","content":"[GauGAN: Changing Sketches into Photorealistic Masterpieces](https://www.youtube.com/watch?v=p5U4NgVGAwg&feature=youtu.be) 3月的时候，英伟达发布了一个视频挺火的： 你只要粗略勾勒简单的线条，AI就能生成逼真的写实图片。\n\n\n  \n  \n\n\n<!--more-->\n[GauGAN: Changing Sketches into Photorealistic Masterpieces](https://www.youtube.com/watch?v=p5U4NgVGAwg&feature=youtu.be) 3月的时候，英伟达发布了一个视频挺火的： 你只要粗略勾勒简单的线条，AI就能生成逼真的写实图片。\n\n![68747470733a2f2f6e766c6162732e6769746875622e696f2f53504144452f2f696d616765732f6f6365616e2e676966](https://camo.githubusercontent.com/a295a79daea9d1dd0cb16b48055607d0f17258b2/68747470733a2f2f6e766c6162732e6769746875622e696f2f53504144452f2f696d616765732f6f6365616e2e676966)\n[GitHub地址](https://github.com/NVlabs/SPADE)\n那它是怎么实现的呢？ 这个项目用的是GAN算法。\n## GAN模型的任务： \n**学习任务** : 输入semantic segmentation mask, 合成 photorealistic images。 \n\n`Semantic Image` 是啥叻？ 直观上理解，如下图： \n\n![31085460.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/31085460.png)\n\n`Image segmentation`呢？ \n```\nImage segmentation is a computer vision task in which we label specific regions of an image according to what's being shown. \nthe goal of semantic image segmentation is to label each pixel of an image with a corresponding class of what is being represented.\n```\n如下图里的每个像素都被分类归属到不同的class\n![Screen-Shot-2018-05-17-at-9.02.15-PM.png](https://www.jeremyjordan.me/content/images/2018/05/Screen-Shot-2018-05-17-at-9.02.15-PM.png)\n[图片来源](https://www.jeremyjordan.me/semantic-segmentation/#representing)\n\n## SPADE:  SPatially-Adaptive (DE)normalization\n\n### [Normalizaing training sets](https://mooc.study.163.com/learn/2001281003?tid=2001391036&_trace_c_p_k2_=5c39b3d9b1544824a0675bd3f4ed78d5#/learn/content?type=detail&id=2001701046)\n首先，要了解一下Normalization的处理跟好处。\n\n**处理**： 以逻辑回归为例, 它的输入特征$X$,权重$W$, map函数如下\n$$f(x) = \\sum_{i=1}^{n}x_i*w_i$$\n\n1. 先求输入的特征$x$的期望\n$$\\mu=\\frac{1}{n}\\sum_{i=1}^{n}x_i$$\n\n2. 再求$x$的方差\n\n$$\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n}(x_i - \\mu)^2$$\n\n3. 再对输入特征做Normalization: \n$$\\frac{x-u}{\\sigma^2}$$\n\n**好处**是，经过处理的input特征值分布更集中均匀， 如下图的第三个坐标系， \n![826f032b.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/826f032b.png)\n\n对于损失函数，\n$$J(w, x) = \\frac{1}{m}\\sum_{i=1}^{m}L(\\hat{y}, y)$$\n用梯度下降训练W，B的时候，Normalization后，形状更圆一些，更容易优化。无论初始从哪个位置开始，你都可以用较大的步长,比较容易找到适合的w,b的值，使得J（w,b)的值最小。\n![6ad7add2.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/6ad7add2.png)\n\n### [Batch Normalization](https://mooc.study.163.com/learn/2001281003?tid=2001391036&_trace_c_p_k2_=f3e0afd9612c439a9f25d08040d39eab#/learn/content?type=detail&id=2001701055) \n[改善深层神经网络：超参数调试、正则化以及优化 - 网易云课堂](https://mooc.study.163.com/learn/2001281003?tid=2001391036&_trace_c_p_k2_=f3e0afd9612c439a9f25d08040d39eab#/learn/content?type=detail&id=2001701055)\n\nBatch Norm不止normailize input feature;也可将normalization process应用在神经网络中的hidden layer上。\n\n![747a0d26.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/747a0d26.png)\n\n比如对隐藏层$a^{[2]}$的输出进行正则化处理，加速下一层的参数$w^{[3]}$,$b^{[3]}$的训练速度。比如$a^{[2]}$层的神经单元分别是 $z^{(1)}, z^{(2)}...z^{(m)}$\n\n对它的处理是\n1. 求期望:\n$$\\mu = \\frac{1}{m}\\sum_{i=1}^{m}z_i$$\n2. 求方差:\n$$\\sigma^2 = \\frac{1}{m}\\sum_{i=1}^{m}(z_i - u)^2$$\n3. norimal\n$$z_i = \\frac{z_i-u}{\\sqrt{\\sigma^2 + \\varepsilon}}$$\n加上$\\varepsilon$是防止$\\sigma^2$为0\n4. 加上 $\\gamma$ 跟 $\\beta$； `scale and shift the normalized value`\n$$\\hat{z} = \\gamma z_i + \\beta$$\n \n\n$\\gamma$ 跟 $\\beta$ 也是参数，跟`w, b`一样在训练过程中迭代学习。 神经网络中他们也常在激活层之前进行Batch Normalization处理。 \n\n### (Spatially-Adaptive normalization)SPADE\n这篇论文提出自己的normalization思路，$h^i$是 i-th层的激活函数输出。\n正则化处理:\n$$\\gamma_{c, y, x}^i (m)\\frac{h_{n, c, y, x}^i - \\mu_c^i}{\\sigma_c^i} + \\beta_{c, y, x}^{i}(m)$$\n\nc: $c \\epsilon C^i, C^i$是i-th层的channel个数\nx: $x \\epsilon W^i, W^i$是i-th层的宽\ny: $y \\epsilon H^i$, 高\nm: segmentation mask m\n$\\gamma_{c, y, x}^i$跟$\\beta_{c, y, x}^{i}$ 是函数，用卷积网络实现\n\n**结构图**： \n\n![2f3fe4e8.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/1ec7011c.png)\n- `3x3-Conv-k`是 3x3卷积层，有k个卷积filter, filter size 3x3\n- `ReLU` 激活函数 \n- 这里的`Resize`用的是`nearest-neighbor downsampling`，不细说了。\n\n它的处理流程是这样，对sematic image 进行resize、卷积、ReLU激活处理， 即$\\gamma_{c, y, x}^i(m)$跟$\\beta_{c, y, x}^{i}(m)$， 乘、加上`Batch Normalization`的输出数据$\\frac{h_{n, c, y, x}^i - \\mu_c^i}{\\sigma_c^i}$ ， \n![ab4c46cb.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/ad9094aa.png)\n\n比起传统Batch Normal,SPADE的$\\gamma_{c, y, x}^i(m)$跟$\\beta_{c, y, x}^{i}(m)$是对sematic image做卷积操作，它在normalization过程中保存更多semantic的信息。论文中也认为这是SPADE效果更好的原因。\n\n#### 相关代码： \n`normalization.py`\n\n```python\n//  用传统的normalization method正则化激活函数输出\n  if param_free_norm_type == 'instance':\n      self.param_free_norm = nn.InstanceNorm2d(norm_nc, affine=False)\n  elif param_free_norm_type == 'syncbatch':\n      self.param_free_norm = SynchronizedBatchNorm2d(norm_nc, affine=False)\n  elif param_free_norm_type == 'batch':\n      self.param_free_norm = nn.BatchNorm2d(norm_nc, affine=False)\n  else:\n      raise ValueError('%s is not a recognized param-free norm type in SPADE'\n                             % param_free_norm_type)\n\n \n```\n```python\n   // 构建gamma,beta函数, 卷积层实现\n   self.mlp_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)\n   self.mlp_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)\n```\n\n```python\n  def forward(self, x, segmap):\n\n        # Part 1. generate parameter-free normalized activations\n        normalized = self.param_free_norm(x)\n\n        # ✨✨✨ Part 2. produce scaling and bias conditioned on semantic map\n        segmap = F.interpolate(segmap, size=x.size()[2:], mode='nearest')\n        actv = self.mlp_shared(segmap)\n        gamma = self.mlp_gamma(actv)\n        beta = self.mlp_beta(actv)\n\n        # apply scale and bias\n        out = normalized * (1 + gamma) + beta\n\n        return out\n```\n\n\n## 模型架构 GANs\n\nGANs由两部分组成： \n\n1. generator：负责合成写实风格的图片\n2. discriminator: 负责找茬。认出这是张合成图片， 而不是真实的照片（or 写实图片）\n### generator 架构\n\n首先\n\n![d3313a9e.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/d3313a9e.png)\n\n这幅图里好多SPADE ResBlk啊，啥是SPADE ResBlk? 下面是它的结构图： \n\n![630b2d2a.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/630b2d2a.png)\n\n- `3x3-Conv-k`是 3x3卷积层，有k个卷积filter, filter size 3x3\n- `ReLU` 激活函数\n- SPADE激活见上文分析\n\n\n那`ResBlk`呢？ \n这要从大名鼎鼎的残差网络说起 [Residual block](https://mooc.study.163.com/learn/2001281004?tid=2001392030&_trace_c_p_k2_=5c60eb2c1e0d4adbb2516471e9ebb431#/learn/content?type=detail&id=2001728692) （强烈推荐Andrew Ng公开课; 弄明白几个点： 1. Residual Block要解决什么问题;  2. 它的设计;  3. 为啥有效。 再回来看SPADE ResBlk)\n\n![fd021761.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/fd021761.png)\n```python\n    def __init__(self, fin, fout, opt):\n        super().__init__()\n        # Attributes\n        self.learned_shortcut = (fin != fout)\n        fmiddle = min(fin, fout)\n\n        # create conv layers\n        self.conv_0 = nn.Conv2d(fin, fmiddle, kernel_size=3, padding=1)\n        self.conv_1 = nn.Conv2d(fmiddle, fout, kernel_size=3, padding=1)\n        if self.learned_shortcut:\n            self.conv_s = nn.Conv2d(fin, fout, kernel_size=1, bias=False)\n\n        # apply spectral norm if specified\n        if 'spectral' in opt.norm_G:\n            self.conv_0 = spectral_norm(self.conv_0)\n            self.conv_1 = spectral_norm(self.conv_1)\n            if self.learned_shortcut:\n                self.conv_s = spectral_norm(self.conv_s)\n\n        # ✨✨✨ define normalization layers\n        spade_config_str = opt.norm_G.replace('spectral', '')\n        self.norm_0 = SPADE(spade_config_str, fin, opt.semantic_nc)\n        self.norm_1 = SPADE(spade_config_str, fmiddle, opt.semantic_nc)\n        if self.learned_shortcut:\n            self.norm_s = SPADE(spade_config_str, fin, opt.semantic_nc)\n```\n## Discriminator \n\ndiscriminator架构图。 (segmentation image,  image)作为输入， 任务是识别image是不是假的。\n![c5347e81.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/c5347e81.png)\n\nimage encoder将图片encode生成均值向量跟方差向量， 计算出noise input输入给generator, segmentation mask也会通过SPADE ResBlks输入给generator。 generator生成image跟segmentation image contact后，再输入给discriminator, discriminator来辨别真伪。 \n![f4341bd9.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/f4341bd9.png)\n\n### Training Data \n\n成对的segmentation masks跟真实图片。 (segmentation mask, real image) \n\n### Test \n\n1.安装:\n\n```sh\ngit clone https://github.com/NVlabs/SPADE.git\ncd SPADE/\n```\n2.这个项目依赖PyTorch 1.0跟python3.0+. 还依赖Synchronized-BatchNorm-PyTorch仓库。\n\n```\n// SPADE目录下\ncd models/networks/\ngit clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\ncp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\ncd ../../\n```\n3.用PyCharm打开这个项目, Preference -> Project Interpreter -> Project -> Project Interpreter; 选python3.+的解释器, PyCharm会提示安装依赖的package。依赖包安装好后，如下图: \n\n![ed349b19.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/ed349b19.png)\n\n4.下载提前训练好的模型\n[checkpoints.tar.gz - Google 云端硬盘](https://drive.google.com/file/d/12gvlTbMvUcJewQlSEaZdeb2CdOB-b8kQ/view)\n\n```\ncd checkpoints\ntar xvf checkpoints.tar.gz\ncd ../\n\nls\n// checkpoints目录如下:\nade20k_pretrained     checkpoints.tar.gz    cityscapes_pretrained coco_pretrained\n```\n5.编辑Configuration, 运行test.py脚本。\n```sh\npython test.py --name [type]_pretrained --dataset_mode [dataset] --dataroot [path_to_dataset]\n```\n\n参数： \n- `[type]_pretrained` 先渲染好的模型，coco_pretrained， ade20k_pretrained， cityscapes_pretrained中任选一个。\n- `[dataset]` 填coco, ade20k, 或者cityscapes \n- `[path_to_dataset]` 数据，比如./datasets/coco_stuff\n\n比如，我的参数: \n```\n--name\ncoco_pretrained\n--dataset_mode\ncoco\n--dataroot\n./datasets/coco_stuff\n--gpu_ids\n-1\n```\n输出的路径： `./results/[type]_pretrained/` 我的是`./results/coco_pretrained/`\n\n![412b71cb.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/412b71cb.png)\n\n这几张图片真是看的我有点失望，再看看下图论文的图片。 果然论文的图片都是精挑细选, 套路满满。\n\n![b037261d.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/b037261d.png)\n\n- [An overview of semantic image segmentation.](https://www.jeremyjordan.me/semantic-segmentation/)","tags":["Image Segment"],"categories":["Neural Network"]},{"title":"React Native调试:Expo + WebStorm","url":"/2019/05/14/React-Native调试-Expo-WebStorm/"},{"title":"The Weights of the YOLO Neural Network","url":"/2019/05/12/The-Weights-of-the-YOLO-Neural-Network/","content":"\n## Load Weights\n\nFirst, see this C library function:  \n```c\nsize_t fread ( void * ptr, size_t size, size_t count, FILE * stream );\n```\n**Parameters**\n- **ptr** − Pointer to a block of memory with a size of at least (size*count) bytes, converted to a void*.\n\n- **size** − This is the size in bytes of each element to be read.\n\n- **count** − This is the number of elements, each one with a size of size bytes.\n\n- **stream** − This is the pointer to a FILE object that specifies an input stream.\n\nThen, in the `load_weights_upto` function in `parser.c`, it begins to load weights for layers from xxx.weights. \n```c\nvoid load_weights_upto(network *net, char *filename, int start, int cutoff) {\n ...\n     // Begin to load weights for layers\n    for(i = start; i < net->n && i < cutoff; ++i){\n        layer l = net->layers[i];\n        if (l.dontload) continue;\n        if(l.type == CONVOLUTIONAL || l.type == DECONVOLUTIONAL){\n            load_convolutional_weights(l, fp);\n        }\n  ...\n}\n```\n\n### Convolutional Layer\nIn `load_convolutional_weights` function, it loads values of biases for filters. One bias for one filter. \n\n```c\n    fread(l.biases, sizeof(float), l.n, fp);\n```\n`l.n` is the number of filter in this layer. \n\nAssign the values to scales, rolling_mean and rooling_variance \n```\n if (l.batch_normalize && (!l.dontloadscales)){\n        fread(l.scales, sizeof(float), l.n, fp);\n        fread(l.rolling_mean, sizeof(float), l.n, fp);\n        fread(l.rolling_variance, sizeof(float), l.n, fp);\n```\n        \nAnd load weights for filters in this layer. The default value of `l.groups` is 1.\n```c\n    int num = l.c/l.groups*l.n*l.size*l.size;\n    fread(l.weights, sizeof(float), num, fp);\n```\n\n`l.c` is input channel. The number of input channel equal to the number of channel of a filter in this layer. Thus, `l.size` is the size of a filter.\n\nFor a 3x3x3 filter (size=3, channel=3), it has 3x3x3=27 parameters as follow  \n\n![-w208](/img/15576478323378/15576531132966.jpg)\n\nIf a convolutional layer has 3 such filters, it will have 3 values for bias, 3x3x3x3 .Its weight layout in memory is like this: \n\n![-w746](/img/15576478323378/15576535368751.jpg)\n\n## Write Weights \n\n`save_weights_upto` and `save_convolutional_weights`functions show how to save weights into a xxx.weights file. It's just a reverse process. \n\n```c\nvoid save_convolutional_weights(layer l, FILE *fp)\n{\n    if(l.binary){\n        //save_convolutional_weights_binary(l, fp);\n        //return;\n    }\n    int num = l.nweights;\n    fwrite(l.biases, sizeof(float), l.n, fp);\n    if (l.batch_normalize){\n        fwrite(l.scales, sizeof(float), l.n, fp);\n        fwrite(l.rolling_mean, sizeof(float), l.n, fp);\n        fwrite(l.rolling_variance, sizeof(float), l.n, fp);\n    }\n    fwrite(l.weights, sizeof(float), num, fp);\n}\n```\n\n```\nsize_t fwrite ( const void * ptr, size_t size, size_t count, FILE * stream );\n\n```\n\n**Parameters**\n- **ptr**\nPointer to the array of elements to be written, converted to a const void*.\n- **size**\nSize in bytes of each element to be written.\nsize_t is an unsigned integral type.\n- **count**\n Number of elements, each one with a size of size bytes.\nsize_t is an unsigned integral type.\n- **stream**\nPointer to a FILE object that specifies an output stream.\n","tags":["YOLO"],"categories":["Neural Network"]},{"title":"LeetCode:237. Delete Node in a Linked List","url":"/2019/05/12/LeetCode-237-Delete-Node-in-a-Linked-List/","content":"\nWrite a function to delete a node (except the tail) in a singly linked list, given only access to that node.\n\n<!--more-->\n\n## [题目](https://leetcode.com/problems/delete-node-in-a-linked-list/)\n\nWrite a function to delete a node (except the tail) in a singly linked list, given only access to that node.\n\nGiven linked list -- head = [4,5,1,9], which looks like following:\n\n![237_example.png](https://assets.leetcode.com/uploads/2018/12/28/237_example.png)\n\n## 分析： \n\n如果我们有一个如下的Linked List，想删除值是5的节点. 这道题要求 ，`only access to that node`。\n\n```\n4 -> 5 -> 1\n```\n\n![48d29b19.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/48d29b19.png)\n留意图中，要删除的对象的地址是0x7ff07ae00090\n\n```c++\n    void deleteNode(ListNode* node) {\n        *node = *(node->next);\n    }\n```\n\n`*node`对node指针取内容，返回是一个对象, 对象地址0x7ff07ae00090\n\n![f94bba4f.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/f94bba4f.png)\n\n`*node->next`对node指针取内容，返回是一个对象， 对象地址0x7ff07ae000a0\n\n![69411ad8.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/69411ad8.png)\n\n执行\n```\n*node = *(node->next);\n```\n结果如下： \n\n![83d8670d.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/83d8670d.png)\n\nnode指针所执行的对象地址不变，但是对象内容发生变化。就像三个房子，位置没变， 但是第三个房子里的住户搬到了第二个房子里住了。 node指针指向的对象的地址依旧是0x7ff07ae00090, val不再是5而是1， next指针也执向NULL。但是我们也丢失了对0x7ff07ae000a0对象的指针引用。\n\n![e8798a20.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/e8798a20.png)","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode  Flatten a Multilevel Doubly Linked List","url":"/2019/05/12/LeetCode-Flatten-a-Multilevel-Doubly-Linked-List/","content":"Flatten the list so that all the nodes appear in a single-level, doubly linked list. You are given the head of the first level of the list.\n\n<!--more-->\n\n题目： [430. Flatten a Multilevel Doubly Linked List]([Loading...](https://leetcode.com/problems/flatten-a-multilevel-doubly-linked-list/)\n)\n\n分析： \n![da80f35a.png](/img/ed6ee62a-3dcb-4189-9404-14b91692d436/da80f35a.png)\n\n 当遇到有child的Node，先用`*next`存cur->next; 把cur->next指针指向child, child->pre指向cur； 接着以child为起点找到该曾最后一个Node，让它指向`*next`的节点。 接着以原来的child为cur Node重新开始一轮。 \n\n```c++\n    class Node {\n    public:\n        int val;\n        Node *prev;\n        Node *next;\n        Node *child;\n\n        Node() {}\n\n        Node(int _val, Node *_prev, Node *_next, Node *_child) {\n            val = _val;\n            prev = _prev;\n            next = _next;\n            child = _child;\n        }\n    };\n\n    Node *flatten(Node *head) {\n        Node *cur = head;\n        while (cur) {\n            if (cur->child) {\n                Node *next = cur->next;\n                cur->next = cur->child;\n                cur->child = nullptr;\n                cur->next->prev = cur;\n\n                // iter the children \n                Node *p = cur->next;\n                while (p->next) p = p->next;\n                  \n                p->next = next;\n                if (next) next->prev = p;\n            }\n            cur = cur->next;\n        }\n\n        return head;\n    }\n```\n\n时间复杂度： $O(n)$","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"YOLO - From Configuration File to Convolutional Layers","url":"/2019/05/08/The-Implementation-of-Convolutional-and-MaxPool-layer/","content":"\n Let's firstly see how `Darknet` construct a neural network. See at `detector.c` `test_detector` function, it construct a network by parsing  the `xxx.cfg` file and `xxx.weights` file. In my case, they are yolo3-tiny.cfg and yolo3-tiny.weights \n <!-- more --> \n\n\nI am trying to understand [Darknet source code](https://pjreddie.com/darknet/yolov2/) that implements YOLO algorithm. First, I run the detector.\n\n```\n./darknet detect cfg/yolov3-tiny.cfg yolov3-tiny.weights data/dog.jpg\n```\n## Parse the argumenets \n\nIn `main` function, it goes to function `test_detector` according to the first argument`detect`. \n\n```c\nif (0 == strcmp(argv[1], \"detect\")){\n   float thresh = find_float_arg(argc, argv, \"-thresh\", .5);\n   char *filename = (argc > 4) ? argv[4]: 0;\n   char *outfile = find_char_arg(argc, argv, \"-out\", 0);\n   int fullscreen = find_arg(argc, argv, \"-fullscreen\");\n   test_detector(\"cfg/coco.data\", argv[2], argv[3], filename, thresh, .5, outfile, fullscreen);\n   }   \n```\n\nHere is the architecture of neural network defined by yolov3-tiny.cfg\n\n```\n\nlayer     filters    size              input                output\n    0 conv     16  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  16  0.150 BFLOPs\n    1 max          2 x 2 / 2   416 x 416 x  16   ->   208 x 208 x  16\n    2 conv     32  3 x 3 / 1   208 x 208 x  16   ->   208 x 208 x  32  0.399 BFLOPs\n    3 max          2 x 2 / 2   208 x 208 x  32   ->   104 x 104 x  32\n    4 conv     64  3 x 3 / 1   104 x 104 x  32   ->   104 x 104 x  64  0.399 BFLOPs\n    5 max          2 x 2 / 2   104 x 104 x  64   ->    52 x  52 x  64\n    6 conv    128  3 x 3 / 1    52 x  52 x  64   ->    52 x  52 x 128  0.399 BFLOPs\n    7 max          2 x 2 / 2    52 x  52 x 128   ->    26 x  26 x 128\n    8 conv    256  3 x 3 / 1    26 x  26 x 128   ->    26 x  26 x 256  0.399 BFLOPs\n    9 max          2 x 2 / 2    26 x  26 x 256   ->    13 x  13 x 256\n   10 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512  0.399 BFLOPs\n   11 max          2 x 2 / 1    13 x  13 x 512   ->    13 x  13 x 512\n   12 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n   13 conv    256  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 256  0.089 BFLOPs\n   14 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512  0.399 BFLOPs\n   15 conv    255  1 x 1 / 1    13 x  13 x 512   ->    13 x  13 x 255  0.044 BFLOPs\n   16 yolo\n   17 route  13\n   18 conv    128  1 x 1 / 1    13 x  13 x 256   ->    13 x  13 x 128  0.011 BFLOPs\n   19 upsample            2x    13 x  13 x 128   ->    26 x  26 x 128\n   20 route  19 8\n   21 conv    256  3 x 3 / 1    26 x  26 x 384   ->    26 x  26 x 256  1.196 BFLOPs\n   22 conv    255  1 x 1 / 1    26 x  26 x 256   ->    26 x  26 x 255  0.088 BFLOPs\n   23 yolo\n```\nNow, let's see how Darknet construct a nerual network. See  `detector.c` `test_detector` function, it construct a network by parsing  the `xxx.cfg` file and `xxx.weights` file. In my case, they are yolo3-tiny.cfg and yolo3-tiny.weights \n\n\n## Parse the configuration file\n\n### Sections in the file \n\nThe code to parse the yolo.cfg file is here:\n\n```c\nlist *read_cfg(char *filename)\n{\n    FILE *file = fopen(filename, \"r\");\n    if(file == 0) file_error(filename);\n    char *line;\n    int nu = 0;\n    list *options = make_list();\n    section *current = 0;\n    while((line=fgetl(file)) != 0){\n        ++ nu;\n        strip(line);\n        switch(line[0]){\n            case '[':\n                current = malloc(sizeof(section));\n                list_insert(options, current);\n                current->options = make_list();\n                current->type = line;\n                break;\n            case '\\0':\n            case '#':\n            case ';':\n                free(line);\n                break;\n            default:\n                if(!read_option(line, current->options)){\n                    fprintf(stderr, \"Config file error line %d, could parse: %s\\n\", nu, line);\n                    free(line);\n                }\n                break;\n        }\n    }\n    fclose(file);\n    return options;\n}\n```\n\n\nfor exmaple: \n\n```js\n[net]              // '[' is a tag for a section, the type of current setion is '[net]'\n# Testing          // ignore\nbatch=1         \nsubdivisions=1\n# Training\n# batch=64\n# subdivisions=2\nwidth=416\nheight=416\nchannels=3\nmomentum=0.9\ndecay=0.0005\nangle=0\nsaturation = 1.5\nexposure = 1.5\nhue=.1\n                 // ignore\nlearning_rate=0.001\n...\n\n[convolutional]    // [convoltional] \n...\n\n[maxpool]      // [maxpool] \n\n...\n[yolo]\n...\n\n[route]\n...\n\n```\n\n#### `[net]`\n\nIn section '[net]', `batch=1` is a option stored in `kvp`(option_list.c line 70) structure. Its key is batch, value is 1. Then this kvp object will be inserted into a node list (see it at option_list.c line76 & list.c line 40).\nAfter parsing the yolo3-tiny.cfg file, We will get a section list; its size is 25. Because there are 25 \\'[\\' tags in yolo3-tiny.cfg\n\n\nIn `parse_network_cfg` function, it parses the `[net]` section to get the params for the whole network. \n\n```c\nnetwork *parse_network_cfg(char *filename)\n{\n    list *sections = read_cfg(filename);\n    node *n = sections->front;\n    if(!n) error(\"Config file has no sections\");\n    network *net = make_network(sections->size - 1);\n    // other codes ...\n    \n}\n```\n\n#### `[convolutional]`\n\nThen parse the different sections. \n\n```c\n        s = (section *)n->val;\n        options = s->options;\n        layer l = {0};\n        LAYER_TYPE lt = string_to_layer_type(s->type);\n        if(lt == CONVOLUTIONAL){\n            l = parse_convolutional(options, params);\n        }else if(lt == DECONVOLUTIONAL){\n            l = parse_deconvolutional(options, params);\n        }else if(lt == LOCAL){\n            l = parse_local(options, params);\n        }else if(lt == ACTIVE){\n            l = parse_activation(options, params);\n        // other code here ...\n       \n```\n\n\nFor the first `[convolutional]` section in the yolo3-tiny.cfg as follow, the darknet will construct a `convolutional_layer` using thess params (see function `parse_convolutional` in parse.c and  function `make_convolutional_layer` in convolutional_layer.c)\n\n```js\n[convolutional]\nbatch_normalize=1\nfilters=16\nsize=3\nstride=1\npad=1\nactivation=leaky\n```\n\nIn this layer, there are 16 filters; the size of each filter is 3X3Xnum_channel; what is num_channel? well, `the number of channels in a filter must match the number of channels in input volume`, so here num_channel is equal to 3. The stride value for filters is 1, padding value is 1. \n\n\nLet's see how darknet calculate the output size of convolutional_layer by the input size(`l.h`) and filter params (`l.size`, `l.pad`, `l.stride`). There is a formula that shows how size of input volume relates to the one of output volume\n \n\n```c\n\nint convolutional_out_height(convolutional_layer l)\n{\n    return (l.h + 2*l.pad - l.size) / l.stride + 1;\n}\n\nint convolutional_out_width(convolutional_layer l)\n{\n    return (l.w + 2*l.pad - l.size) / l.stride + 1;\n}\n\n```\n\n As for yolo3-tiny.cfg, for this first convolutional_layer, its input size is 416 x 416 and channel is 3. So its ouput height is (416+2x1 - 3)/1 + 1 = 416, its output width is 416 too. `What about its output channel? It equals to the number of filters (16)`. \n \n ```c\n \n  l.out_c = n    // in func make_convolutional_layer\n  \n ```\n So its output volume size is 416 X 416 X 16.\n \n \n ![02b028d9.png](/img/995676c2-24ed-4165-8224-0bc01148242a/9b76325f.png)\n \n For a beginner, I strongly recommend these courses: [Strided Convolutions - Foundations of Convolutional Neural Networks \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/strided-convolutions-wfUhx) and  [One Layer of a Convolutional Network - Foundations of Convolutional Neural Networks \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/one-layer-of-a-convolutional-network-nsiuW)\n  \nNow, we have 16 filters that are 3X3X3 in this layer, `how many parameters does this layer have`?  Each filter is a 3X3X3 volume, so it's 27 numbers tp be learned, and then plus the bias, so that was the b parameters. it's 28 parameters. There are 16 filters so that would be 448 parameters to be learned in this layer. \n \n```c\n\n    // c: the number of channels; n: the number of filters; \n    // size: the number of filter width or height; groups: default is 1 \n    l.weights = calloc(c/groups*n*size*size, sizeof(float));\n    l.weight_updates = calloc(c/groups*n*size*size, sizeof(float));\n\n    l.biases = calloc(n, sizeof(float));\n    l.bias_updates = calloc(n, sizeof(float));\n\n    l.nweights = c/groups*n*size*size;\n    l.nbiases = n;\n\n```\n \n \n#### Activation \n \n In this convolution layer, it choose leaky ReLU as activation function. The function is defined as follow  where α is a small constant.\n \n $$\nf(x)=\\begin{cases}\nαx,\\quad x\\leq 0 \\\\\\\\ \nx,\\quad x>0\n\\end{cases}\n$$\n\n \n Still, I recommend this course for a beginner. [Activation functions - Shallow neural networks \\| Coursera](https://www.coursera.org/lecture/neural-networks-deep-learning/activation-functions-4dDC1)\n\n \nThere are `forward_activation_layer` and `backward_activation_layer` in Darknet. Both of them handle batch inputs. \n\nFor forward activation layer, leaky_activate is to computes f(x)\n\n ```c\n static inline float leaky_activate(float x){return (x>0) ? x : .1*x;}\n ```\n For backward activation layer, leaky_gradient returns the slop of the function \n\n```c\nstatic inline float leaky_gradient(float x){return (x>0) ? 1 : .1;}\n```\n\n\n \n \n#### [maxpool]\n \n Maxpool layer is used to reduce the size of representation to speed up computation as well as to make some of the features it detects a bit more robust. Look at the `tiny-yolo3.cfg`\n \n ```js\n [maxpool]\nsize=2\nstride=2\n\n ```\n ```c\n maxpool_layer make_maxpool_layer(int batch, int h, int w, int c, int size, int stride, int padding)\n{\n    maxpool_layer l = {0};\n    l.type = MAXPOOL;\n    l.batch = batch;\n    l.h = h;\n    l.w = w;\n    l.c = c;         // output channel equals to input one \n    l.pad = padding;  // default value is size - 1\n    l.out_w = (w + padding - size)/stride + 1;\n    l.out_h = (h + padding - size)/stride + 1;\n    l.out_c = c;\n    l.outputs = l.out_h * l.out_w * l.out_c;\n    // other codes ...\n    return l;\n}\n\n \n ```\n This `[maxpool]` sections comes after the `[convolutional]` section. Its input size(416 x 416 x 16) equal to the output size of the former layer (416 x 416 x  16). The filter size is 2 x 2, stride is 2. Each time, the filter would move 2 steps, for a 4x4x1 input volume, its output is 2x2x1 volume. \n![e65fb56d.png](/img/995676c2-24ed-4165-8224-0bc01148242a/e65fb56d.png)\n```\n9 == max(1, 3, 2, 9)\n2 == max(2, 1, 1, 1)\n6 == max(1, 3, 5, 6)\n3 == max(2, 3, 1, 2)\n```\nSo in this layer, its ouput width equals to (int)((416+ 1 - 2)/2 + 1), 208. And the number of its output channels equals to the number of input channels. Now, we know its output volume size is 208 X 208 X 16. There is no parameter to be learned. \n\n**input volume size**: \n\n$$ n_H . n_W . n_c$$\n\n  $n_c$ : the number of channels\n\n**output volume size**: \n\n$$(\\frac{n_H + padding-f}{stride} + 1) . (\\frac{n_W + padding-f}{stride} +1) . n_c$$\n \n$f$: the width or height of a filter\n \n [Pooling Layers - Foundations of Convolutional Neural Networks \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/pooling-layers-hELHk)\n \n #### Why does 1 x 1 convolution do? \n \n [Networks in Networks and 1x1 Convolutions - Deep convolutional models: case studies \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/networks-in-networks-and-1x1-convolutions-ZTb8x)\n \n \n For example, in this picture, the number of input volume channels ,192, has gotten too big, we can shrink it to a 28x28x32 dimension volume using 32 filters that are 1x1x192. So this is a way to shrink the number of channels .\n \n ![a085e0e4.png](/img/995676c2-24ed-4165-8224-0bc01148242a/a085e0e4.png)\n \n \n In YOLO, it implements fully connected layer by two convolutional layer. \n \n ```\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nsize=1\nstride=1\npad=1\nfilters=255\nactivation=linear\n ```\n \n [Convolutional Implementation of Sliding Windows - Object detection \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/convolutional-implementation-of-sliding-windows-6UnU4)\n \n","tags":["YOLO"],"categories":["Neural Network"]},{"title":"LeetCode Unique Paths 1-2","url":"/2019/05/08/Leetcode-Unique-Paths-1-2/","content":"Leetcode Unique Paths 1-2 \n<!-- more --> \n\n# Unique Paths 1-2\n\n## 题目1： [Unique Paths 1](https://leetcode.com/problems/unique-paths/)\n\n![e2ca2848.png](/img//c5619f25-13a6-4e38-b7f8-d87ff624f5b5/e2ca2848.png)\n\n### 动态规划解题步骤要点: \n\n1. 找到最优解的结构\n2. 递归方案\n3. bottom-up 或者 top-down方式求最优解\n4. 优化，空间换时间\n\n### 分析\n\n这道题很简单。\n1. 定义一个 mxn 的二维数组grides[m][n]， 对应格子地图。对应途中grides[2][6]\n\n![e594b650.png](/img//c5619f25-13a6-4e38-b7f8-d87ff624f5b5/e594b650.png)\n比如，我们想知道从(0,0)到(1, 2)有几条路。根据题目要求，只能往右走或者下走一个格子。\n我们先看从(1, 1)到（1，2），两种走法： \n- (2, 0) -> (1, 2)\n- (1, 1) -> (1, 2)\n\n再看从(0, 0)到(2， 0) 只有一条路: (0, 0) -> (1, 1) -> (2, 0)； grides[2][0] = 1。\n\n从(0, 0)格子到(1,1)格子，有两种路: \n- (0,0) -> (0, 1)-> (1, 1)\n- (0,0) -> (1, 0)-> (1, 1)\n那么grides(1, 1) = 2. \n \n很容易发现规律， grids[m][n] = grids[m - 1][n] + grides[m][n -1]; 可用递归求解。但是纯碎的递归有很多重复计算。 如下图的递归树： \n![72a3d4ef.png](/img//c5619f25-13a6-4e38-b7f8-d87ff624f5b5/72a3d4ef.png)\n所以我们引入一个record数组，记录已经计算的结果，省去重复计算。\n\n时间复杂度: \no(m* n)\n\n```c++\nint inner_path(int i, int j, int m, int n, vector<vector<int>>& record) {\n    if (i < 0 || j < 0) {\n        return 0;\n    }\n\n    if (record[i][j]) {\n        return record[i][j];\n    }\n\n    if ((i == 0) && (j == 0)) {\n        return 1;\n    }\n\n    record[i][j] = inner_path(i-1, j, m, n, record) + inner_path(i, j-1, m, n, record);\n    return record[i][j];\n}\n\nint uniquePaths(int m, int n) {\n    vector<vector<int>> res(m, vector<int>(n, 0));\n    return inner_path(m-1, n-1, m, n, res);\n}\n```\n\n### [Unique Paths 2](https://leetcode.com/problems/unique-paths-ii/)\n\n分析： \n跟Unique Paths 1比起来，多了障碍物。如果(i, j)是障碍物，那么grid(i, j) = 0, 表示我们无法经由(i, j) 到达终点。\n\n\n\n```c++\nint path_helper(int i, int j, int m, int n, vector<vector<int>>& record, vector<vector<int>> &obstacleGrid) {\n        if (i < 0 || j < 0 || obstacleGrid[i][j] == 1) {\n            return 0;\n        }\n\n        if (record[i][j]) {\n            return record[i][j];\n        }\n\n        if ((i == 0) && (j == 0)) {\n            return 1;\n        }\n\n        record[i][j] = path_helper(i - 1, j, m, n, record, obstacleGrid) + path_helper(i, j - 1, m, n, record, obstacleGrid);\n        return record[i][j];\n    }\n\n    int uniquePathsWithObstacles(vector<vector<int>>& obstacleGrid) {\n        if (obstacleGrid.empty()) return 0;\n        int m = (int)obstacleGrid.size();\n        int n = (int)obstacleGrid[0].size();\n\n        vector<vector<int>> res(m, vector<int>(n, 0));\n        return path_helper(m - 1, n - 1, m, n, res, obstacleGrid);\n    }\n```\n\n自底向上的写法： \n\n```c++\n   int uniquePathsWithObstacles(vector<vector<int>>& grid) {\n        int rows = grid.size();\n        if(rows == 0) return 0;\n        int cols = grid[0].size();\n        vector<vector<long>> res(rows+1, vector<long>(cols+1, 0));\n        for(int i=rows-1; i>=0;i--){\n            for(int j=cols-1; j>=0;j--){\n                if(grid[i][j] == 1) res[i][j] = 0;\n                else if(i == rows-1 && j == cols-1) res[i][j] = 1;\n                else res[i][j] = res[i][j+1] + res[i+1][j];\n            }\n        }\n        return res[0][0];\n    }\n```","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode 959. Regions Cut By Slashes 笔记","url":"/2019/04/23/Leetcode-959-Regions-Cut-By-Slashes/","content":"\n题目：https://leetcode.com/problems/regions-cut-by-slashes/description/\n\n## Solution1: DFS \n\nTime Complexity::  $O(n^2)$\n\n### 分析： \n[这个神奇的思路](https://leetcode.com/problems/regions-cut-by-slashes/discuss/205674/C++-with-picture-DFS-on-upscaled-grid)分割格子，转化为图的DFS问题。\n```json\nInput:\n[\n  \"\\\\/\",\n  \"/\\\\\"\n]\n```\n\n把`\\\\`，`/`或者` `分别分割成3*3的格子。图转化为: \n\n```json\n[\n 1,0,0,0,0,1,\n 0,1,0,0,1,0,\n 0,0,1,1,0,0\n 0,0,1,1,0,0\n 0,1,0,0,1,0\n 1,0,0,0,0,1\n]\n```\n\n问题就变成： 计算被1分割开的区域的数量。\n\n类似的[孤岛数量问题](https://www.geeksforgeeks.org/find-number-of-islands/) 都是同一个问题的变种：[Counting the number of connected components in an undirected graph](https://www.geeksforgeeks.org/connected-components-in-an-undirected-graph/)\n\n```c++\nvoid dfs(vector<vector<int>>& board, int i, int j ) {\n    // index out of range\n    if (i < 0 || j < 0 || i >= board.size() || j >= board[0].size()) return;\n    // this grid has been visited or it was part of a slash character\n    if (board[i][j] == 1) return;\n\n    // mark this grid visited\n    board[i][j] = true;\n\n    dfs(board, i - 1, j);\n    dfs(board, i + 1, j);\n    dfs(board, i, j - 1);\n    dfs(board, i, j + 1);\n}\n\nint regionsBySlashes(vector<string>& grid) {\n    if (grid.empty())\n        return 0;\n    int row = (int)grid.size(), col = (int)grid[0].size();\n    vector<vector<int>> board (row * 3, vector<int>(col * 3, 0));\n\n    // n*n graph represented as 3n*3n graph\n    for (int i = 0; i < row; ++i) {\n        for (int j = 0; j < col; ++j) {\n            if (grid[i][j] == '/') board[i * 3][j * 3 + 2] = board[i * 3 + 1][j * 3 + 1] = board[i * 3 + 2][j * 3] = 1;\n            if (grid[i][j] == '\\\\') board[i * 3][j * 3] = board[i * 3 + 1][j * 3 + 1] = board[i * 3 + 2][j * 3 + 2] = 1;\n        }\n    }\n\n    int cnt = 0;\n    for (int i = 0; i < row * 3; ++i) {\n        for (int j = 0; j < col * 3; ++j) {\n            // only count components connected by space\n            if (!board[i][j]) {\n               dfs(board, i, j);\n               cnt++;\n            }\n        }\n    }\n\n    return cnt;\n}\n\n```\n\n如果分割为2*2的格子，会遇到这个问题:\n```\nInput:\n[\n  \"//\",\n  \"/ \"\n]\nOutput: 5\nExpected: 3\n\n0101\n1010\n0100\n1000\n```\n01**0**1\n1**0**10\n**0**100\n1000\n\n加粗的这三个0，被分割开了。题意要求是连在一起的。\n\n\n## Solution2: DSU\n\nTime Complexity:  $O(n^2*\\alpha(n))$\nSpace Complexity: $O(n^2)$\n\n### 分析： \n\n#### DSU: \nhttps://www.youtube.com/watch?v=YKE4Vd1ysPI\nhttps://www.youtube.com/watch?v=gpmOaSBcbYA\n\nDSU中用数组来表示树， 如下： \n\n| idx | 0 |  1 | 2 |\n| --- | --- | --- | --- |\n| parent | 1 | -1 | 1 |\n\n \nparent[0] = 1, 代表node 0的parent是1； parent[2] = 1代表node 2的parent是1; parent[1] = -1, 代表它是root。 \n\n```\n   1\n /  \\\n0    2\n```\n\n两个operation： \n**find(x)**: find root of cluster in which x is \n\n```\n   1                   5\n  / \\                 / \\\n 0   2               6   7\n    / \\                   \\\n   3   4                  8\n```\n比如： 我们想找3跟8所在cluster的root， find(3) == 1,  find(8) == 5\n\n```c\n/*递归查找root*/\nint find(int x, int parent[]) {\n    int x_root = x; \n    while (parent[x_root]!= -1) {\n        x_root = parent[x_root];\n    }\n    return x_root;\n}\n```\n**union(x, y)**: union two cluster where x, y are in \n\n比如： 我们想union(3, 8),  就要先找到3的x_root， 跟8的y_root，然后合并两个root.\n\n```c\nint union(int x, int y, int parent[]) {\n    int x_root = find(x, parent);\n    int y_root = find(y, parent); \n    if (x_root == y_root) {\n        return 0; \n    } else {\n        // y_root 变成 x_root的根\n        parent[x_root] = y_root;\n        return 1\n    }\n}\n```\n\n```\n              5\n         /   / \\\n        1   6   7\n       / \\       \\\n      0   2       8\n         / \\ \n        3   4 \n```\n\n                                \nDSU腻害的一点是优化后，用$O(1)$的average time cost, 检测图里有咩有环\n\n两种优化： \n- Make tree flat \n- Union by rank\n\nhttps://www.youtube.com/watch?v=VJnUwsE4fWA\n\n\n### 分割成4个三角形， 上下左右\n每个格子分割成上下左右四个三角形。\nhttps://assets.leetcode.com/uploads/2018/12/15/3.png\n\n每个三角形给个idx: 0, 1, 2, 3分别对应 top, right, bottom, left\n```\n\\ 0 /\n3 \\ 1\n/ 2 \\\n```\nn*n的图；变成 4*n*n的数组。 初始化时数组parent的每个值都是-1, 代表每个点都是独立的。我们遍历grid中的每个点, grid[i][j]， 分别进行如下操作： \n\n'/':  上、左连接； 下、右连接\n'\\\\': 上、右连接； 左、下连接\n' ': 四个部分连接\n\n对每个grid[i][j], 合并grid[i-1][j]的bottom三角形根grid[i][j]的top 三角形；合并grid[i][j-1]的right三角形跟grid[i][j]的left三角形。\n\n最终代码如下:\n\n```c++\nclass DSU {\nprivate:\n    // use array represents a graph\n    vector<int> parent;\n    int row = 0;\npublic:\n    // num of root of independent cluster\n    int num_root = 0;\n\n    DSU(int n) {\n        parent = vector<int>(n * n * 4, -1);\n        num_root = n * n * 4;\n        row = n;\n    }\n\n    int find(int x) {\n        // find the root of the cluster where x is iteratively\n        while (parent[x] != -1) {\n            x = parent[x];\n        }\n        return x;\n    }\n\n    /**\n    * return: 1: successfully; 0: failed\n    */\n    int union_cluster(int x, int y) {\n        int x_root = find(x);\n        int y_root = find(y);\n        if (x_root == y_root) {\n            return 0;\n        } else {\n            int min_ = min(x_root, y_root);\n            int max_ = max(x_root, y_root);\n            parent[min_] = max_;\n            \n            num_root--;\n            return 1;\n        };\n    }\n\n    /**\n     * 将图中（i,j)位置的点，映射到数组的idx\n     * @param i\n     * @param j\n     * @param part\n     * @param n\n     * @return\n     */\n    int idx(int i, int j, int part) {\n        return (i * row + j) * 4 + part;\n    }\n};\n\n\n// https://leetcode.com/problems/regions-cut-by-slashes/discuss/205680/JavaC%2B%2BPython-Split-4-parts-and-Union-Find\nint regionsBySlashes(vector<string> &grid) {\n    if (grid.empty()) return 0;\n    int n = (int) grid.size();\n\n    DSU dsu = DSU(n);\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < n; ++j) {\n            // merge the bottom part of the (i-1, j) grid and the top part of the grid (i, j)\n            if (i > 0) dsu.union_cluster(dsu.idx(i - 1, j, 2), dsu.idx(i, j, 0));\n            // merge the right part of the (i, j-1) grid and the left part of the grid(i,j)\n            if (j > 0) dsu.union_cluster(dsu.idx(i, j - 1, 1), dsu.idx(i, j, 3));\n\n            if (grid[i][j] == '/') {\n                // union the top and the left part of this cell\n                dsu.union_cluster(dsu.idx(i, j, 3), dsu.idx(i, j, 0));\n                // union the right and the bottom of this cell\n                dsu.union_cluster(dsu.idx(i, j, 2), dsu.idx(i, j, 1));\n            }\n\n            if (grid[i][j] == '\\\\') {\n                dsu.union_cluster(dsu.idx(i, j, 0), dsu.idx(i, j, 1));\n                dsu.union_cluster(dsu.idx(i, j, 2), dsu.idx(i, j, 3));\n            }\n\n            if (grid[i][j] == ' ') {\n                dsu.union_cluster(dsu.idx(i, j, 0), dsu.idx(i, j, 2));\n                dsu.union_cluster(dsu.idx(i, j, 1), dsu.idx(i, j, 3));\n                dsu.union_cluster(dsu.idx(i, j, 1), dsu.idx(i, j, 2));\n            }\n        }\n    }\n\n    return dsu.num_root;\n}\n\n```\n\nhttps://leetcode.com/problems/regions-cut-by-slashes/discuss/205680/JavaC%2B%2BPython-Split-4-parts-and-Union-Find\n","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"XMPP(6):XMPP-消息存储与拉取历史消息","url":"/2019/04/10/XMPP-6-XMPP-消息存储与拉取历史消息/","content":"\n\nXEP-0313定义了XMPP消息存储的规则。\n\n### 场景需求\n0313协议主要有这些场景： \n- 同账号多客户端之间的历史消息同步\n- 客户端拉取历史消息，按日期排序展示（想想我们在微信的历史消息）\n- 分页拉取消息\n\n### 存储\n\n1. 单条消息存储包括： \n- 消息发送跟接收的时间戳\n- from 跟 to 的JID\n- server-assigned UID\n- message stanza \n\n2. 消息的顺序要保存： 依赖timestamp要小心，因为多条消息可能共享时间戳\n3. 超过一定数量，可删除旧信息\n4. 群聊记录用MAM服务\n5. archive id ` <stanza-id/>`\n被archived过的消息，server要给它加上stanza-id\nExample 1. Client receives a message that has been archived\n\n```xml\n<message to='juliet@capulet.lit/balcony'\n         from='romeo@montague.lit/orchard'\n         type='chat'>\n  <body>Call me but love, and I'll be new baptized; Henceforth I never will be Romeo.</body>\n  <stanza-id xmlns='urn:xmpp:sid:0' by='juliet@capulet.lit' id='28482-98726-73623' />\n</message>\n\n```\nstanza-id: archive ID \n\n### 查询\n\n#### 1. A user queries their archive for messages\n用消息UID查询\n\n'urn:xmpp:mam:2' namespace, indicating the UID of the first and last message of the (possibly limited) result set. \n\n```xml\n<iq type='set' id='juliet1'>\n  <query xmlns='urn:xmpp:mam:2' queryid='f27' />\n</iq>\n```\n\n#### 2. Their server sends the matching messages\n\n\n\n```xml\n<message id='aeb213' to='juliet@capulet.lit/chamber'>\n  <result xmlns='urn:xmpp:mam:2' queryid='f27' id='28482-98726-73623'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2010-07-10T23:08:25Z'/>\n      <message xmlns='jabber:client' from=\"witch@shakespeare.lit\" to=\"macbeth@shakespeare.lit\">\n        <body>Hail to thee</body>\n      </message>\n    </forwarded>\n  </result>\n</message>\n\n```\n\n#### 3. Server returns the result IQ to signal the end\n\n\n```xml\n<iq type='result' id='juliet1'>\n  <fin xmlns='urn:xmpp:mam:2'>\n    <set xmlns='http://jabber.org/protocol/rsm'>\n      <first index='0'>28482-98726-73623</first>\n      <last>09af3-cc343-b409f</last>\n    </set>\n  </fin>\n</iq>\n```\n\nserver的这条iq stanza标记查询结果结束。\n\n### 过滤器\n\n#### 1. 根据JID过滤\n\n`with` 字段 + JID(Bare JID)： 会拿到to或from地址匹配JID的信息; 如果没有with, 服务端返回query指定的时间段内的消息。 \n\n```xml \nExample 6. Querying for all messages to/from a particular JID¶\n<iq type='set' id='juliet1'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field var='FORM_TYPE' type='hidden'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field var='with'>\n        <value>juliet@capulet.lit</value>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n\n**使用场景：**\nA想查询跟B的聊天记录，with字段的value设为B, 服务端返回的messages中，既有B发送给A的msg，也有A发送给B的msg。 \n\n![3c4760c7.png](/img/f3eaaed1-370f-4abc-93b2-a3312d3ebcd4/3c4760c7.png)\n#### 2. 根据接收时间过滤\n\n`start` 跟 `end` 字段标记时间戳。 时间戳格式见https://xmpp.org/extensions/xep-0082.html\n\n```xml\nExample 7. Querying the archive for all messages in a certain timespan¶\n<iq type='set' id='juliet1'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field var='FORM_TYPE' type='hidden'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field var='start'>\n         // UTC格式\n        <value>2010-06-07T00:00:00Z</value>\n      </field>\n      <field var='end'>\n        <value>2010-07-07T13:23:54Z</value>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n如果`end` 缺失， server会自动认为是最近的消息的存储时间\n\n``` xml\nExample 8. Querying the archive for all messages after a certain time¶\n<iq type='set' id='juliet1'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field var='FORM_TYPE' type='hidden'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field var='start'>\n        <value>2010-08-07T00:00:00Z</value>\n      </field>\n    </x>\n  </query>\n</iq>   \n```\n\n#### 3. 限定results的数量\n\n[Result Set Management (XEP-0059)](https://xmpp.org/extensions/xep-0059.html) \n\n```xml\nExample 9. A query using Result Set Management¶\n<iq type='set' id='q29302'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field var='FORM_TYPE' type='hidden'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field var='start'>\n        <value>2010-08-07T00:00:00Z</value>\n      </field>\n    </x>\n    <set xmlns='http://jabber.org/protocol/rsm'>\n      <max>10</max>\n    </set>\n  </query>\n</iq>\n```\n\n这个请求，指定客户端最多只能收到10条stanzas。但服务端的返回结果可能回改变`set`的内容，返回自己限定的数量，比如： 这是返回`start`时间跟`end`时间段内的20条消息。\n\n```xml\nExample 10. Server responds to client with limited results using RSM¶\n<!-- result messages -->\n<iq type='result' id='q29302'>\n  <fin xmlns='urn:xmpp:mam:2'>\n    <set xmlns='http://jabber.org/protocol/rsm'>\n      <first index='0'>28482-98726-73623</first>\n      <last>09af3-cc343-b409f</last>\n      <count>20</count>\n    </set>\n  </fin>\n</iq>\n```\n\n#### 4. 分页拉取消息\n\n如果之前已经获取了m条消息，客户端可以再发送同样的请求，拉取下一页消息。`set`中要带上`after`(上次拉取到的最后一条消息的UID)\n\n```xml\nExample 11. A page query using Result Set Management¶\n<iq type='set' id='q29303'>\n  <query xmlns='urn:xmpp:mam:2'>\n      <x xmlns='jabber:x:data' type='submit'>\n        <field var='FORM_TYPE' type='hidden'><value>urn:xmpp:mam:2</value></field>\n        <field var='start'><value>2010-08-07T00:00:00Z</value></field>\n      </x>\n      <set xmlns='http://jabber.org/protocol/rsm'>\n         <max>10</max>\n         <after>09af3-cc343-b409f</after>\n      </set>\n  </query>\n</iq>\n```\n\nserver返回最后一页消息，会在 fin里头带上`complete`属性，值为`ture`\n\n```xml\nExample 12. Server completes a result with the last page of messages¶\n<!-- result messages -->\n<iq type='result' id='u29303'>\n  <fin xmlns='urn:xmpp:mam:2' complete='true'>\n    <set xmlns='http://jabber.org/protocol/rsm'>\n      <first index='0'>23452-4534-1</first>\n      <last>390-2342-22</last>\n      <count>16</count>\n    </set>\n  </fin>\n</iq>\n    \n```\n\n**使用场景：**\n\nA客户端本地存储跟B的聊天信息， 最后一条message的id是`09af3-cc343-b409f`。 现在A想看看最近的消息（`09af3-cc343-b409f`后的message，可以发送iq请求中带上`<after>09af3-cc343-b409f</after>`。差量请求最新消息，基于游标的分页。\n#### 5.其他字段的筛选\n\n客户端查询服务端支持的其他字段\n```xml\nExample 13. Client requests supported query fields¶\n<iq type='get' id='form1'>\n  <query xmlns='urn:xmpp:mam:2'/>\n</iq>\n```\n\n```xml\nExample 14. Server returns supported fields¶\n<iq type='result' id='form1'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='form'>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field type='jid-single' var='with'/>\n      // 按消息received时间查询\n      <field type='text-single' var='start'/>\n      <field type='text-single' var='end'/>\n      // 按文本查询\n      <field type='text-single' var='urn:example:xmpp:free-text-search'/>\n      // stanza内容\n      <field type='text-single' var='urn:example:xmpp:stanza-content'/>\n    </x>\n  </query>\n</iq>\n```\n### 返回的message stanza 结构\n\n- `message`被封装在`forwarded`元素中。 [XEP-0297: Stanza Forwarding](https://xmpp.org/extensions/xep-0297.html)\n- 带`result` 元素， 其属性id是这条message的UID\n- delay元素 [XEP-0203: Delayed Delivery](https://xmpp.org/extensions/xep-0203.html) message被收到的时间, UTC时间戳格式\n\n\n```xml\nExample 16. Server returns two matching messages¶\n<message id='aeb213' to='juliet@capulet.lit/chamber'>\n  <result xmlns='urn:xmpp:mam:2' queryid='f27' id='28482-98726-73623'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2010-07-10T23:08:25Z'/>\n      <message xmlns='jabber:client'\n        to='juliet@capulet.lit/balcony'\n        from='romeo@montague.lit/orchard'\n        type='chat'>\n        <body>Call me but love, and I'll be new baptized; Henceforth I never will be Romeo.</body>\n      </message>\n    </forwarded>\n  </result>\n</message>\n\n<message id='aeb214' to='juliet@capulet.lit/chamber'>\n  <result xmlns='urn:xmpp:mam:2' queryid='f27' id='5d398-28273-f7382'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2010-07-10T23:09:32Z'/>\n      <message xmlns='jabber:client'\n         to='romeo@montague.lit/orchard'\n         from='juliet@capulet.lit/balcony'\n         type='chat' id='8a54s'>\n        <body>What man art thou that thus bescreen'd in night so stumblest on my counsel?</body>\n      </message>\n    </forwarded>\n  </result>\n</message>\n    \n```\n\n## MUC Archive\n\n- 存储所有发送给roomJid的message\n- 不包含`private message`\n- user需要权限查询群历史聊天记录\n- `forward` stanza中带有`to`属性,值是roomJid，`from`值是userJid \n- `x`里有该消息的发送者Jid\n```xml\nExample 17. Server returns MUC messages¶\n<message id='iasd207' from='coven@chat.shakespeare.lit' to='hag66@shakespeare.lit/pda'>\n  <result xmlns='urn:xmpp:mam:2' queryid='g27' id='34482-21985-73620'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2002-10-13T23:58:37Z'/>\n      <message xmlns=\"jabber:client\"\n        from='coven@chat.shakespeare.lit/firstwitch'\n        id='162BEBB1-F6DB-4D9A-9BD8-CFDCC801A0B2'\n        type='groupchat'>\n        <body>Thrice the brinded cat hath mew'd.</body>\n        <x xmlns='http://jabber.org/protocol/muc#user'>\n          <item affiliation='none'\n                jid='witch1@shakespeare.lit'\n                role='participant' />\n        </x>\n      </message>\n    </forwarded>\n  </result>\n</message>\n\n<message id='iasd207' from='coven@chat.shakespeare.lit' to='hag66@shakespeare.lit/pda'>\n  <result xmlns='urn:xmpp:mam:2' queryid='g27' id='34482-21985-73620'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2002-10-13T23:58:43Z'/>\n      <message xmlns=\"jabber:client\"\n        from='coven@chat.shakespeare.lit/secondwitch'\n        id='90057840-30FD-4141-AA44-103EEDF218FC'\n        type='groupchat'>\n        <body>Thrice and once the hedge-pig whined.</body>\n        <x xmlns='http://jabber.org/protocol/muc#user'>\n          <item affiliation='none'\n                jid='witch2@shakespeare.lit'\n                role='participant' />\n        </x>\n      </message>\n    </forwarded>\n  </result>\n</message>\n```\n[XEP-0313: Message Archive Management](https://xmpp.org/extensions/xep-0313.html#intro)","tags":["XMPP"],"categories":["XMPP"]},{"title":"XMPP(5): 消息","url":"/2019/04/09/XMPP-5-消息/","content":"\n \n## Message消息体构造\n\n属性： \n1. to ：接收方地址， JID \n2. from ： 发送方， JID\n3. type \n  - chat: 一对一聊天\n  - error: 出错\n  - groupchat: 群聊\n  - headline: 通知、临时消息这种不需要回复的系统消息\n  - normal: 之前没有聊天的记录， 客户端可以回复的消息\n\n子元素\n1. body: 消息内容\n\n```xml\n<message\n    from='juliet@example.com/balcony'\n    id='b4vs9km4'\n    to='romeo@example.net'\n    type='chat'\n    xml:lang='en'>\n  <body>Wherefore art thou, Romeo?</body>\n</message>\n\n```\n2. Subject: 聊天的话题\n\n```xml\n\n<message\n    from='juliet@example.com/balcony'\n    id='c8xg3nf8'\n    to='romeo@example.net'\n    type='chat'\n    xml:lang='en'>\n  <subject>I implore you!</subject>\n  <body>Wherefore art thou, Romeo?</body>\n</message>\n```\n\n3. Thread: 聊天会话的唯一标识\n\n## Example \n\n对话： \n\n```xml\nCC: <message\n        from='juliet@example.com/balcony'\n        to='romeo@example.net'\n        type='chat'\n        xml:lang='en'>\n      <body>My ears have not yet drunk a hundred words</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\nCC: <message\n        from='juliet@example.com/balcony'\n        to='romeo@example.net'\n        type='chat'\n        xml:lang='en'>\n      <body>Of that tongue's utterance, yet I know the sound:</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\nCC: <message\n        from='juliet@example.com/balcony'\n        to='romeo@example.net'\n        type='chat'\n        xml:lang='en'>\n      <body>Art thou not Romeo, and a Montague?</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\nUC: <message\n        from='romeo@example.net/orchard'\n        to='juliet@example.com/balcony'\n        type='chat'\n        xml:lang='en'>\n      <body>Neither, fair saint, if either thee dislike.</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\nCC: <message\n        from='juliet@example.com/balcony'\n        to='romeo@example.net/orchard'\n        type='chat'\n        xml:lang='en'>\n      <body>How cam'st thou hither, tell me, and wherefore?</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\n```\n\n在[xmpp.js](https://github.com/xmppjs/xmpp.js/)中，客户端与服务端建立了WebSocket长链接后，发消息，需要自己构造消息体\n\n``` js \nconst {client, xml} = require('@xmpp/client')\n\nconst xmpp = client({\n  service: 'ws://localhost:5280/xmpp-websocket',\n  domain: 'localhost',\n  resource: 'example',\n  username: 'username',\n  password: 'password',\n})\n\n const message = xml(\n    'message',\n    {type: 'chat', to: address},\n    xml('body', 'hello world')\n  )\n  await xmpp.send(message)\n\n```\n\n如果收到消息会走到一个回调里, chat-sdk就可以根据type字段来分发。\n\n\n```js \nself.xmppClient.on('stanza', function (stanza: any) {\n    Utils.DLog('[Chat] RECV:', stanza.toString());\n    /**\n     * Detect typeof incoming stanza\n     * and fire the Listener\n     */\n    if (stanza.is('presence')) {\n        self._onPresence(stanza);\n    } else if (stanza.is('iq')) {\n        self._onIQ(stanza);\n    } else if (stanza.is('message')) {\n        if (stanza.attrs.type === 'headline') {\n            self._onSystemMessageListener(stanza);\n        } else if (stanza.attrs.type === 'error') {\n            self._onMessageErrorListener(stanza);\n        } else {\n            self._onMessage(stanza);\n        }\n    }\n});\n```\n\n- ref: https://xmpp.org/rfcs/rfc6121.html#message","tags":["XMPP"],"categories":["XMPP"]},{"title":"JWT 入门","url":"/2019/04/03/JWT-入门/","content":"\n\n## 什么是JSON Web Tokens (JWT)？ \n\n\n```\n  JSON Web Token (JWT) is a compact, URL-safe means of representing\n   claims to be transferred between two parties.  The claims in a JWT\n   are encoded as a JSON object that is used as the payload of a JSON\n   Web Signature (JWS) structure or as the plaintext of a JSON Web\n   Encryption (JWE) structure, enabling the claims to be digitally\n   signed or integrity protected with a Message Authentication Code\n   (MAC) and/or encrypted.\n   \n\n```\n\n## 怎么用？ \n\nauthentication时，当user成功登录，server生成access token, 发送给user；user请求server时带上JWT，server通过JWT验证是否是可信任的客户端请求了。\n\n\n![1*SSXUQJ1dWjiUrDoKaaiGLA.png](https://cdn-images-1.medium.com/max/1600/1*SSXUQJ1dWjiUrDoKaaiGLA.png)\n\n## 结构\n\n在客户端看来JWT是一串encode加密过的字符串,`header.payload.signature`，如下图左边。但它decode后其实是下图右边的JSON结构体\n\n![legacy-app-auth-5.png](https://cdn.auth0.com/blog/legacy-app-auth/legacy-app-auth-5.png)\n\n#### 1. 生成header\n\ne.g.\n```json\n{\n  \"alg\": \"HS256\",\n  \"typ\": \"JWT\"\n}\n```\n\n这里，alg的值指定用HMAC-SHA256算法签名\n\n#### 2. 生成payload\n\n包含用户相关的信息\n```\nThe second part of the token is the payload, which contains the claims. \nClaims are statements about an entity (typically, the user) and additional data. \n```\n有三种[claims](https://tools.ietf.org/html/rfc7519#section-4.1): registered, public, and private claims.\n\ne.g.\n```json\n\n{\n  \"sub\": \"1234567890\",\n  \"name\": \"John Doe\",\n  \"iat\": 1516239022\n}\n```\n\n#### 3.生成signature\n\n```js\n\nHMACSHA256(\n  base64UrlEncode(header) + \".\" +\n  base64UrlEncode(payload),\n  your-256-bit-secret\n) \n```\n把header跟payload encode结构后，用'.'连接，生成: <span style=\"color:#fb015b\"> eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</span><span>.</span>\n<span style=\"color:#d63aff\"> eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ</span>\n\n再用指定的hash算法(例子是HS256),用私钥（服务端的）生成签名:<span style=\"color:#00b9f1\">SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c<span>\n\n\n## 验证\n\n如图1， JWT由Authentication server生成， 在client认证后发给client； client请求application server的时候带上JWT，application server在认证阶段从Authentiation server那儿拿到scret key；用同样算法生成signature， 跟client发来的JWT的signature做比较，看是否match。\n\n\n\n\n\n\n\n\n\n\n\n\n[5 Easy Steps to Understanding JSON Web Tokens (JWT)](https://medium.com/vandium-software/5-easy-steps-to-understanding-json-web-tokens-jwt-1164c0adfcec)\n[JSON Web Token Introduction - jwt.io](https://jwt.io/introduction/) \n[RFC 7519 - JSON Web Token (JWT)](https://tools.ietf.org/html/rfc7519)","tags":["Auth"],"categories":["NetWork"]},{"title":"XMPP(4):Search 和 vCard","url":"/2019/03/31/XMPP-4-Search-vCard/","content":"`jabber:iq:search`协议用来查找用户信息。\n\n1. 我们先查询可以用哪些字段查找用户\n<!-- more -->\n\n# XMPP Search \n\n`jabber:iq:search`协议用来查找用户信息。\n\n1. 我们先查询可以用哪些字段查找用户\n\n```xml\n// Requesting Search Fields\n\n<iq type='get'\n    from='romeo@montague.net/home'\n    to='characters.shakespeare.lit'\n    id='search1'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'/>\n</iq>\n```\n\n2. service 返回\n\n```xml\n// Receiving Search Fields\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search1'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <instructions>\n      Fill in one or more fields to search\n      for any matching Jabber users.\n    </instructions>\n    <first/>\n    <last/>\n    <nick/>\n    <email/>\n  </query>\n</iq>\n```\n3. 服务端返回，可以用`first` `last` `nick` `email` 这几个字段找人。接着就用last查人.\n\n```xml\n// Submitting a Search Request\n\n<iq type='set'\n    from='romeo@montague.net/home'\n    to='characters.shakespeare.lit'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <last>Capulet</last>\n  </query>\n</iq>\n```\n\n服务端可以能会返回好多个last匹配的item\n```xml\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <item jid='juliet@capulet.com'>\n      <first>Juliet</first>\n      <last>Capulet</last>\n      <nick>JuliC</nick>\n      <email>juliet@shakespeare.lit</email>\n    </item>\n    <item jid='tybalt@shakespeare.lit'>\n      <first>Tybalt</first>\n      <last>Capulet</last>\n      <nick>ty</nick>\n      <email>tybalt@shakespeare.lit</email>\n    </item>\n  </query>\n</iq>\n```\n没有结果的话，query就没有子元素\n\n```xml\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'/>\n</iq>\n```\n\nXMPP Search \n\n`jabber:iq:search`协议用来查找用户信息。\n\n我们先查询可以用哪些字段查找用户\n\n```xml\n// Requesting Search Fields\n\n<iq type='get'\n    from='romeo@montague.net/home'\n    to='characters.shakespeare.lit'\n    id='search1'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'/>\n</iq>\n```\n\nservice 返回\n\n```xml\n// Receiving Search Fields\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search1'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <instructions>\n      Fill in one or more fields to search\n      for any matching Jabber users.\n    </instructions>\n    <first/>\n    <last/>\n    <nick/>\n    <email/>\n  </query>\n</iq>\n```\n服务端返回，可以用`first` `last` `nick` `email` 这几个字段找人。接着就用last查人.\n\n```xml\n// Submitting a Search Request\n\n<iq type='set'\n    from='romeo@montague.net/home'\n    to='characters.shakespeare.lit'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <last>Capulet</last>\n  </query>\n</iq>\n```\n\n服务端可以能会返回好多个last匹配的item\n```xml\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <item jid='juliet@capulet.com'>\n      <first>Juliet</first>\n      <last>Capulet</last>\n      <nick>JuliC</nick>\n      <email>juliet@shakespeare.lit</email>\n    </item>\n    <item jid='tybalt@shakespeare.lit'>\n      <first>Tybalt</first>\n      <last>Capulet</last>\n      <nick>ty</nick>\n      <email>tybalt@shakespeare.lit</email>\n    </item>\n  </query>\n</iq>\n```\n没有结果的话，query就没有子元素\n\n```xml\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'/>\n</iq>\n```\n\n# vCard \nvCard协议主要负责用户信息存储，就像个人名片。\n\n1. 查看自己的vCard\n如果客户端想查询自己的vCard, 需要发送IQ-set stanza，注意没有to地址哦。\n\n```xml\n<iq from='stpeter@jabber.org/roundabout'\n    id='v1'\n    type='get'>\n  <vCard xmlns='vcard-temp'/>\n</iq>\n```\n\n2. 返回信息\n接着服务端返回一堆的用户信息\n\n```xml\n\n<iq id='v1'\n    to='stpeter@jabber.org/roundabout'\n    type='result'>\n  <vCard xmlns='vcard-temp'>\n    <FN>Peter Saint-Andre</FN>\n    <N>\n      <FAMILY>Saint-Andre</FAMILY>\n      <GIVEN>Peter</GIVEN>\n      <MIDDLE/>\n    </N>\n    <NICKNAME>stpeter</NICKNAME>\n    <URL>http://www.xmpp.org/xsf/people/stpeter.shtml</URL>\n    <BDAY>1966-08-06</BDAY>\n    <ORG>\n      <ORGNAME>XMPP Standards Foundation</ORGNAME>\n      <ORGUNIT/>\n    </ORG>\n    <TITLE>Executive Director</TITLE>\n    <ROLE>Patron Saint</ROLE>\n    <TEL><WORK/><VOICE/><NUMBER>303-308-3282</NUMBER></TEL>\n    <TEL><WORK/><FAX/><NUMBER/></TEL>\n    <TEL><WORK/><MSG/><NUMBER/></TEL>\n    <ADR>\n      <WORK/>\n      <EXTADD>Suite 600</EXTADD>\n      <STREET>1899 Wynkoop Street</STREET>\n      <LOCALITY>Denver</LOCALITY>\n      <REGION>CO</REGION>\n      <PCODE>80202</PCODE>\n      <CTRY>USA</CTRY>\n    </ADR>\n    <TEL><HOME/><VOICE/><NUMBER>303-555-1212</NUMBER></TEL>\n    <TEL><HOME/><FAX/><NUMBER/></TEL>\n    <TEL><HOME/><MSG/><NUMBER/></TEL>\n    <ADR>\n      <HOME/>\n      <EXTADD/>\n      <STREET/>\n      <LOCALITY>Denver</LOCALITY>\n      <REGION>CO</REGION>\n      <PCODE>80209</PCODE>\n      <CTRY>USA</CTRY>\n    </ADR>\n    <EMAIL><INTERNET/><PREF/><USERID>stpeter@jabber.org</USERID></EMAIL>\n    <JABBERID>stpeter@jabber.org</JABBERID>\n    <DESC>\n      More information about me is located on my\n      personal website: http://www.saint-andre.com/\n    </DESC>\n  </vCard>\n</iq>\n```\n如果没有相关vCard，会返回error\n```xml\n// item-not-found\n<iq id='v1'\n    to='stpeter@jabber.org/roundabout'\n    type='error'>\n  <vCard xmlns='vcard-temp'/>\n  <error type='cancel'>\n    <item-not-found xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n```\n\n```xml\n// empty element\n<iq id='v1'\n    to='stpeter@jabber.org/roundabout'\n    type='result'>\n  <vCard xmlns='vcard-temp'/>\n</iq>\n\n```\n\n3. 查看别人的vCard\n\n用IQ-get stanza, 带上to地址\n\n```xml \n\n<iq from='stpeter@jabber.org/roundabout'\n    id='v3'\n    to='jer@jabber.org'\n    type='get'>\n  <vCard xmlns='vcard-temp'/>\n</iq>\n```\n\n```xml\n<iq from='jer@jabber.org'\n    to='stpeter@jabber.org/roundabout'\n    type='result'\n    id='v3'>\n  <vCard xmlns='vcard-temp'>\n    <FN>JeremieMiller</FN>\n    <N>\n      <GIVEN>Jeremie</GIVEN>\n      <FAMILY>Miller</FAMILY>\n      <MIDDLE/>\n    </N>\n    <NICKNAME>jer</NICKNAME>\n    <EMAIL><INTERNET/><PREF/><USERID>jeremie@jabber.org</USERID></EMAIL>\n    <JABBERID>jer@jabber.org</JABBERID>\n  </vCard>\n</iq>\n\n```\n\n4. 更新vCard\n\n客户端可以用IQ-set stanza 更新自己的vCard信息\n\n```xml\n<iq id='v2' type='set'>\n  <vCard xmlns='vcard-temp'>\n    <FN>Peter Saint-Andre</FN>\n    <N>\n      <FAMILY>Saint-Andre</FAMILY>\n      <GIVEN>Peter</GIVEN>\n      <MIDDLE/>\n    </N>\n    <NICKNAME>stpeter</NICKNAME>\n    <URL>http://www.xmpp.org/xsf/people/stpeter.shtml</URL>\n    <BDAY>1966-08-06</BDAY>\n    <ORG>\n      <ORGNAME>XMPP Standards Foundation</ORGNAME>\n      <ORGUNIT/>\n    </ORG>\n    <TITLE>Executive Director</TITLE>\n    <ROLE>Patron Saint</ROLE>\n    <TEL><WORK/><VOICE/><NUMBER>303-308-3282</NUMBER></TEL>\n    <TEL><WORK/><FAX/><NUMBER/></TEL>\n    <TEL><WORK/><MSG/><NUMBER/></TEL>\n    <ADR>\n      <WORK/>\n      <EXTADD>Suite 600</EXTADD>\n      <STREET>1899 Wynkoop Street</STREET>\n      <LOCALITY>Denver</LOCALITY>\n      <REGION>CO</REGION>\n      <PCODE>80202</PCODE>\n      <CTRY>USA</CTRY>\n    </ADR>\n    <TEL><HOME/><VOICE/><NUMBER>303-555-1212</NUMBER></TEL>\n    <TEL><HOME/><FAX/><NUMBER/></TEL>\n    <TEL><HOME/><MSG/><NUMBER/></TEL>\n    <ADR>\n      <HOME/>\n      <EXTADD/>\n      <STREET/>\n      <LOCALITY>Denver</LOCALITY>\n      <REGION>CO</REGION>\n      <PCODE>80209</PCODE>\n      <CTRY>USA</CTRY>\n    </ADR>\n    <EMAIL><INTERNET/><PREF/><USERID>stpeter@jabber.org</USERID></EMAIL>\n    <JABBERID>stpeter@jabber.org</JABBERID>\n    <DESC>\n      Check out my blog at https://stpeter.im/\n    </DESC>\n  </vCard>\n</iq>\n```\n\n服务端返回结果\n\n```xml\n<iq id='v2'\n    to='stpeter@jabber.org/roundabout'\n    type='result'/>\n```\n\nref: https://xmpp.org/extensions/xep-0054.html#intro\nref: https://xmpp.org/extensions/xep-0055.html#intro","tags":["XMPP"],"categories":["XMPP"]},{"title":"影响曝光的3个因素","url":"/2019/03/31/影响曝光的几个因素/","content":"\n\n\n## 进光量\n\n`曝光`也指单位面积上光子的数量。\n\n- 如果我们没有捕获足够的光，那么相片就会`欠曝`:\n\n<img src=\"/img/15000130641224/15000133443588.jpg\" width = \"368\" height = \"500\" alt=\"图片名称\" align=center />\n\n\n- 如果我们捕获的光太多，图像就会`过曝`:\n\n<img src=\"/img/15000130641224/15000133832576.jpg\" width = \"368\" height = \"500\" alt=\"图片名称\" align=center />\n\n\n\n## 三个要素可以影响曝光的进光量\n\n- 快门速度\n- 光圈\n- 感光度 (ISO)\n\n![](/img/15000130641224/15006272782478.jpg)\n\n想象相机是黑暗房间，有个窗户（光圈）， 有块窗帘（快门），窗户越大进光量越大，窗帘拉开的时间越久。 窗户对面有面镜子（感官元件），捕获光子成像。\n\n## 1.快门速度\n当我们捕捉图片时，图像传感器需要捕捉一段时间的光。 这个时间段曝光时间（也叫快门速度。相机中一般用`1/400、8`这样的形式表示）这个数值越大，快门开启的时间越长，进入相机的光线就越多，但运动的物体很可能模糊.\n\n看下图： \n\n![](/img/15000130641224/15006271573170.jpg)\n\n\n## 2.感光度 (ISO)\n\n它被用来衡量图像传感器对光的`灵敏程度`，以及因此带来的曝光噪音。ISO越大，传感器越灵敏，捕获光能力越强，照片越亮，但噪点也越多。\n\n![](/img/15000130641224/15006272197963.jpg)\n\n####左： ISO 32 和 1/3 秒曝光\n####右： ISO 1600 和 1/180 秒\n![](/img/15000130641224/15000247388896.jpg)\n\n\n**图像传感器**\n这个部分就相当于我们眼睛里的视网膜。图像传感器可以将光或者光子转换为电信号。\n\n**图像传感器是由海量的独个的像素传感器串起来的巨大矩形区域** 我们可以将每个像素传感器想象成一个装电荷的桶。当光子撞击到像素传感器的光二极管时，它们将在这个像素的桶中缓慢地积攒电荷。最后，每个像素都会有它自己的一小桶电子。这些电荷的数量是依赖于光子数量的 -- 或者说是决定于打到这个特定的点上的光的强度。\n\n因为我们有一个像素传感器的二维阵列，我们现在就拥有能够反应出所有这些位置的光的强度的一组二维电荷阵列了。**在 iPhone 6 上，我们有八百万个这样的微小的像素传感器**，以及它们所对应的电荷桶。\n\n\n## 3.光圈\n\n相机的镜头的光圈(Aperture)是用来衡量到达图像感应器的光所通过的`通孔的大小`的\n\n\n#### 曝光值\n\n曝光值（Exposure Value，EV）代表能够给出同样曝光的所有相机光圈快门组合\n\n![](/img/15000130641224/15026013567638.jpg)\n其中N是光圈（f值）；t是曝光时间（快门），单位秒。曝光值0（EV0）对应于曝光时间为1秒而光圈为f/1.0的组合或其等效组合。\n\n`曝光值 != 曝光量`\n\n####曝光量（photometric exposure）\n\n![](/img/15000130641224/15026015278605.jpg)\n其中  H是曝光量， E是影像平面的照度，而  t是曝光时间。照度 E由f值所控制，但也取决于环境亮度。\n\n## 光圈与景深\n\n##### 景深\n\n![](/img/15000130641224/15026018990936.jpg)\n\n![](/img/15000130641224/15026016717518.jpg)\n\n![](/img/15000130641224/15026016975426.jpg)\n\n光圈系数= `镜头焦距/光圈孔径`；常用的镜头的光圈数序列为\n`1， 1.4， 2， 2.8， 4， 5.6， 8， 11， 16， 22， 32， 45， 64，90，128`\n\n\n\n\n","tags":["CV"]},{"title":"XMPP(3):Roster&联系人","url":"/2019/03/31/Roster-联系人/","content":"\n\n\n\nXMPP中联系人模块协议是`jabber:iq:roster`. Roster直接翻译叫花名册，其实它就是联系人列表啦。\n\n## 客户端获取联系人列表\n\n比较简单，发送IQ stanza给server. xmlns=`jabber:iq:roster`;type='get'\n\n```xml\n\n<iq from='user@server.com/balcony'\n       id='bv1bs71f'\n       type='get'>\n    <query xmlns='jabber:iq:roster'/>\n  </iq>\n\n```\n返回结果的item中有联系人Jid\n\n```xml\n<iq id='bv1bs71f'\n       to='user@server.com/balcony'\n       type='result'>\n    <query xmlns='jabber:iq:roster' ver='ver7'>\n      <item jid='contact1@server.com'/>\n      <item jid='contact2@server.com'/>\n    </query>\n  </iq>\n\n```\n\n## 添加联系人(加好友）的流程 \n\n方法有两种，第一种用IQ set, 见[rfc6121](https://xmpp.org/rfcs/rfc6121.html#roster-add).\n\n1. 客户端请求添加联系人\n\nxmlns用`jabber:iq:roster`; 带上想添加的用户jid. name可以不带; `group`分组用。\n\n\n```xml\n<iq from='user@server.com/balcony' type='set' id='roster_2'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com'\n          name='contact'>\n      <group>Servants</group>\n    </item>\n  </query>\n</iq>\n```\n\n2.1. server通知同一个账户关联的所有客户端: 联系人列表更新了。\n\n```xml\n\n<iq to='user@server.com/balcony'\n    type='set'\n    id='a78b4q6ha463'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com'\n          name='contact'\n          subscription='none'>\n      <group>Servants</group>\n    </item>\n  </query>\n</iq>\n\n<iq to='user@server.com/chamber'\n    type='set'\n    id='a78b4q6ha464'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com'\n          name='contact'\n          subscription='none'>\n      <group>Servants</group>\n    </item>\n  </query>\n</iq>\n```\n\nserver回复IQ stanza给请求添加联系人的客户端balcony\n```xml\n<iq to='user@server.com/balcony' type='result' id='roster_2'/>\n```\n\n\n##  删除联系人\n\n给server发送个IQ set， subscription一定是'remove'.\n\n```xml\n\n<iq from='user@server.com/balcony' type='set' id='roster_4'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com' subscription='remove'/>\n  </query>\n</iq>\n\n```\n\n## Presence\n\n增删联系人的另一种方法是Presence订阅机制.Presence stanza其实有两种功能：\n- 广播online/offline状态, [之前文章](https://suelan.github.io/2019/03/26/XMPP-Overview/#The-Presence-Stanza)提过\n- 控制联系人订阅. 就是增删好友功能咯\n\n我们用type来区分这两种功能。type是`available| unavailable`， presence stanza表达online/offline状态。type若是`subscribe | subscribed | unsubscribe| unsubscribed`，就跟联系人有关啦。\n\n\nsubscribtion有四种状态：\n- NONE :  \n- TO  :  user订阅contact的状态\n- FROM : contact被user订阅\n- BOTH : user跟contact相互subcribe\n\n![flow](https://www.blikoontech.com/wp-content/uploads/2018/03/XMPP_Subscription_Flow.png)\n\n如上图：一开始user跟contact没啥关系，subscription状态都是none。 接着user发送了一条Presence stanza给contact，想subscribe他的状态。如下：\n```xml\n// from user\n<presence to='contact@server.com' type='subscribe'/>\n```\n现在user用`jabber:iq:roster` 查询所有联系人的时候，会发现item多了一条, contact还没确认, 所以 ask='subscribe', subscribtion='none'\n\n```xml\n// user's roster\n<item ask='subscribe' subscription='none' jid='contact@server.com'/>\n```\nserver要将消息转发给contact客户端, contact登录时，会收到一条来自user的presence stanza; type是'subscribe'。 我们可以用这条消息来做“收到来自user添加好友的请求”这样的功能\n```xml\n<presence from='user@server.com' to='contact@server.com' type='subscribe' xmlns='jabber:client'></presence>\n```\n\n同时contact/dev设备会收到Roster更新的信息. \n```xml\n<iq  from='contact@server.com' to='contact@server.com/dev' id='13a99ca5' type='result' xmlns='jabber:client'>\n    <query  xmlns='jabber:iq:roster'>\n         <item  ask='subscribe' subscription='none' jid='user@server.com'/>\n       </query>\n</iq>\n```\n#### 接受请求\n如果contact接受请求，他要发送一条presence给user. type值是'subscribed'\n\n```xml\n<presence to='user@server.com' type='subscribed'/>\n```\n\nuser这边的roster会更新\n```xml\n// user's roster\n<item subscription='to' jid='contact@server.com'/>\n```\n这时在contact的roster列表里，user的subscription是from。 ```xml\n// contact's roster\n<item ask='subscribe' subscription='from' jid='user@server.com'/>\n```\n\n接着contact也请求订阅user \n\n```xml\n<iq from='user@server.com/balcony' type='set' id='roster_2'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com'\n          name='contact'>\n      <group>Servants</group>\n    </item>\n  </query>\n</iq>\n```\n\nContact同样流程后，他两的subscription都变成了both。\n\n#### 拒绝\n如果contact想拒绝user的请求，也是发送presence \n```xml\n<presence to='user@server.com' type='unsubscribed'/>\n```\n如果user想取消对contact的订阅, 发送presence stanza，type 是unsubscribed\n```xml\n<presence to='contact@server.com' type='unsubscribed'/>\n```\n\n\nref: https://xmpp.org/rfcs/rfc3921.html#roster","tags":["XMPP"],"categories":["XMPP"]},{"title":"XMPP(2):注册账户","url":"/2019/03/29/XMPP-2-注册账户/","content":"\n\n\n## XMPP注册流程\n\n\n#### 1. client发送消息体, 去服务端查询注册需要的字段\n\n\n```xml\n<iq type='get' id='reg1' to='localhost'>\n  <query xmlns='jabber:iq:register'/>\n</iq>\n```\n\nxmlns是 `jabber:iq:register`, type是`get`\n\n#### 2.1. 未注册：返回注册需要的字段\n\n```xml\n<iq type='result' id='reg1'>\n  <query xmlns='jabber:iq:register'>\n    <instructions>\n      Choose a username and password for use with this service.\n      Please also provide your email address.\n    </instructions>\n    <username/>\n    <password/>\n    <email/>\n  </query>\n</iq>\n```\n\n`<instructions/>` element：SHOULD contain an <instructions/> element (whose XML character data MAY be modified to reflect the fact that the entity is currently registered)\n\n#### 2.2. 已注册：服务端的返回结果\n\n```xml\n<iq  xmlns='jabber:client' xml:lang='en' to='olivia@localhost/180244803852118156522754' from='localhost' type='result' id='reg1'>\n    <query  xmlns='jabber:iq:register'>\n        <username>olivia</username>\n        <registered/>\n        <password/>\n        <instructions>Choose a username and password to register with this server</instructions>\n    </query>\n</iq>\n```\n\nhost会根据\"from\"的地址判断entity是否已经注册了，IQ result消息有一个空的`<registered/>`， 标示该entiry已经注册过了。\n\n#### 3.client 注册 \n\niq stanza的type是`set`, xmlns`jabber:iq:register`\n\n```xml\n<iq type='set' id='reg2'>\n  <query xmlns='jabber:iq:register'>\n    <username>bill</username>\n    <password>Calliope</password>\n    <email>bard@shakespeare.lit</email>\n  </query>\n</iq>\n```\n\n#### 4.1 注册成功 \n\n```xml\n<iq type='result' id='reg2'/>\n\n```\n\n#### 4.2 注册失败，命名冲突\n\n```xml\n<iq type='error' id='reg2'>\n  <query xmlns='jabber:iq:register'>\n    <username>bill</username>\n    <password>m1cro$oft</password>\n    <email>billg@bigcompany.com</email>\n  </query>\n  <error code='409' type='cancel'>\n    <conflict xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n```\n\n#### 4.3 消息不全 ` <not-acceptable/> `\n\n```xml\n<iq type='error' id='reg2'>\n  <query xmlns='jabber:iq:register'>\n    <username>bill</username>\n    <password>Calliope</password>\n  </query>\n  <error code='406' type='modify'>\n    <not-acceptable xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n```\n\n#### 4.4 服务端访问权限问题\n\n```xml\n<iq  xmlns='jabber:client' xml:lang='en' to='olivia@localhost/180244803852118156522754' from='olivia@localhost' type='error' id='reg2'>\n    <query  xmlns='jabber:iq:register'>\n        <email>bard@shakespeare.lit</email>\n        <username>bill</username>\n        <password>Calliope</password>\n    </query>\n    <error  code='403' type='auth'>\n        <forbidden  xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n        <text  xmlns='urn:ietf:params:xml:ns:xmpp-stanzas' xml:lang='en'>Access denied by service policy</text>\n    </error>\n</iq>\n```\n\n#### 5.如果用第三方注册的方式，可能需要补充一些额外的信息\n\n客户端查询\n\n```xml\n<iq type='get'\n    from='juliet@capulet.com/balcony'\n    to='contests.shakespeare.lit'\n    id='reg3'>\n  <query xmlns='jabber:iq:register'/>\n</iq>\n```\n\n#### 6.服务端返回消息， 提示需要提供的信息\n\n```xml\n<iq type='result'\n    from='contests.shakespeare.lit'\n    to='juliet@capulet.com/balcony'\n    id='reg3'>\n  <query xmlns='jabber:iq:register'>\n    <instructions>\n      Use the enclosed form to register. If your Jabber client does not\n      support Data Forms, visit http://www.shakespeare.lit/contests.php\n    </instructions>\n    <x xmlns='jabber:x:data' type='form'>\n      <title>Contest Registration</title>\n      <instructions>\n        Please provide the following information\n        to sign up for our special contests!\n      </instructions>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>jabber:iq:register</value>\n      </field>\n      <field type='text-single' label='Given Name' var='first'>\n        <required/>\n      </field>\n      <field type='text-single' label='Family Name' var='last'>\n        <required/>\n      </field>\n      <field type='text-single' label='Email Address' var='email'>\n        <required/>\n      </field>\n      <field type='list-single' label='Gender' var='x-gender'>\n        <option label='Male'><value>M</value></option>\n        <option label='Female'><value>F</value></option>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n\n#### 7.客户端提供信息\n\n```xml\n<iq type='set'\n    from='juliet@capulet.com/balcony'\n    to='contests.shakespeare.lit'\n    id='reg4'>\n  <query xmlns='jabber:iq:register'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>jabber:iq:register</value>\n      </field>\n      <field type='text-single' label='Given Name' var='first'>\n        <value>Juliet</value>\n      </field>\n      <field type='text-single' label='Family Name' var='last'>\n        <value>Capulet</value>\n      </field>\n      <field type='text-single' label='Email Address' var='email'>\n        <value>juliet@capulet.com</value>\n      </field>\n      <field type='list-single' label='Gender' var='x-gender'>\n        <value>F</value>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n\n## Cancellation of Existing Registration\n\n#### 1. cilent req: \n```xml\n<iq type='set' from='bill@shakespeare.lit/globe' id='unreg1'>\n  <query xmlns='jabber:iq:register'>\n    <remove/>\n  </query>\n</iq>\n```\n跟注册不同的是 `query` 的child多了个`<remove/>`\n\n#### 2.1. 成功注销,server response: \n  \n```xml\n\n<iq type='result' to='bill@shakespeare.lit/globe' id='unreg1'/>\n\n```\n\n#### 2.2.Error Case  \n\n|Condition | Description  |\n| --- | --- |\n| ``<bad-request/>``|\tThe <remove/> element was not the only child element of the <query/> element.|\n|``<forbidden/>``\t| 权限不够|\n|``<not-allowed/>``\t|不允许用户注销账户|\n|``<registration-required/>``|要注销的账户本来就不存在|\n|``<unexpected-request/>``\t| The host is an instant messaging server and the IQ get does not contain a 'from' address because the entity is not registered with the server.|\n\n## 用户修改密码\n\n#### 1. Client:\n```xml\n<iq type='set' to='shakespeare.lit' id='change1'>\n  <query xmlns='jabber:iq:register'>\n    <username>bill</username>\n    <password>newpass</password>\n  </query>\n</iq>\n\n```\n\n这里的密码是明文， 要留意客户端服务端通信是否用SSL或者TLS加密，而且服务端证书可信。\n\n#### 2.1. 成功, Server: \n\n```xml\n<iq type='result' id='change1'/>\n\n```\n\n\n#### 2.2. 失败 Case \n\n\n|Condition | Description  |\n| --- | --- |\n| ``<bad-request/>``| request请求体拼写有问题，比如没带username |\n|``<not-authorized/>`` | 没通过server的安全验证 |\n|``<not-allowed/>`` |\tserver 不允许|\n|``<unexpected-request/>`` | The host is an instant messaging server and the IQ set does not contain a 'from' address because the entity is not registered with the server. |\n\n比如：\n```xml\n// Bad  request\n<iq type='error' from='shakespeare.lit' to='bill@shakespeare.lit/globe' id='change1'>\n  <error code='400' type='modify'>\n    <bad-request xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n\n// Not Authorized\n<iq type='error' from='shakespeare.lit' to='bill@shakespeare.lit/globe' id='change1'>\n  <error code='401' type='modify'>\n    <not-authorized xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n\n// Not Allowed\n<iq type='error' from='shakespeare.lit' to='bill@shakespeare.lit/globe' id='change1'>\n  <error code='405' type='cancel'>\n    <not-allowed xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n```\n\n有时候，服务端需要更多的信息来改密码，这时候它会返回信息提示客户端\n\n```xml\n<iq type='error' from='shakespeare.lit' to='bill@shakespeare.lit/globe' id='change1'>\n  <query xmlns='jabber:iq:register'>\n    <x xmlns='jabber:x:data' type='form'>\n      <title>Password Change</title>\n      <instructions>Use this form to change your password.</instructions>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>jabber:iq:register:changepassword</value>\n      </field>\n      <field type='text-single' label='Username' var='username'>\n        <required/>\n      </field>\n      <field type='text-private' label='Old Password' var='old_password'>\n        <required/>\n      </field>\n      <field type='text-private' label='New Password' var='password'>\n        <required/>\n      </field>\n      <field type='text-single' label='Mother&apos;s Maiden Name' var='x-mmn'>\n        <required/>\n      </field>\n    </x>\n  </query>\n  <error code='401' type='modify'>\n    <not-authorized xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n\n```\n\n然后客户端返回相关信息\n\n```xml\n<iq type='set' from='bill@shakespeare.lit/globe' to='shakespeare.lit' id='change2'>\n  <query xmlns='jabber:iq:register'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>jabber:iq:register:changepassword</value>\n      </field>\n      <field type='text-single' var='username'>\n        <value>bill@shakespeare.lit</value>\n      </field>\n      <field type='text-private' var='old_password'>\n        <value>theglobe</value>\n      </field>\n      <field type='text-private' var='password'>\n        <value>groundlings</value>\n      </field>\n      <field type='text-single' var='x-mmn'>\n        <value>Throckmorton</value>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n\nref: [XEP-0077: In-Band Registration](https://xmpp.org/extensions/xep-0077.html#usecases)\n","tags":["XMPP"],"categories":["XMPP"]},{"title":"XMPP Overview","url":"/2019/03/26/XMPP-Overview/","content":"\n\n\n跟朋友做一个项目，想快速开发，选了XMPP协议。它是一套通信协议。分为两部分，[XMPP Core Services](https://xmpp.org/rfcs/rfc6121.html#A%20Sample%20Session) 和 XMPP Extension Protocols. 核心由基础feature组成，扩展协议就非常丰富，而且一直在发展。Wiki上有张各种IM协议的汇总表，推荐！\n\n- [Comparison of instant messaging protocols - Wikipedia](https://en.wikipedia.org/wiki/Comparison_of_instant_messaging_protocols)\n\n\n## XMPP Addressing \n\n这是一张Client-Server的图，图里的server、client都遵循XMPP协议。叫 XMPP entity. 它们有各自唯一的Address, 格式如'username@server.com', 叫 JID (Jaber ID)\n [RFC 7622 - Extensible Messaging and Presence Protocol (XMPP): Address Format](https://datatracker.ietf.org/doc/rfc7622/)\n \n ![28a215f7.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/28a215f7.png)\n \n其中resource是拿来做同一账号多客户端标记的， 比如图中`User1` 从 pc ,phone1 和 phone2登录同一账号，resource分别是 `pc`, `iphone1`,`iphone2`\n \n \n ## XMPP Client- Server Streams\n \n 客户端与服务端通过长链接方式通信，现在多用WebSocket。当客户端跟服务端握手成功，它们开始用 XML stream通信。\n \n ![f1565a2e.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/f1565a2e.png)\\\n\n \nXML stream 总是以  ``<stream>`` 开头， ``</stream>`` tag结尾。是xml消息的容器。\n\n```\nAn XML stream is a container for the exchange of XML elements between any two entities over a network. \nDuring the life of the stream, the entity that initiated it can send an unbounded number of XML elements over the stream, either elements used to negotiate the stream (e.g., to complete TLS negotiation or SASL negotiation) or XML stanzas. \n```\n\n下面是client跟server的一次消息交互， 绿色来自client的，黑色消息来自server\n\n \n  ![f97e583b.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/65d38868.png)\n\n ### XML stanza\n An XML stanza is the basic unit of meaning in XMPP. A stanza is a first-level element (at depth=1 of the stream) whose element name is \"message\", \"presence\", or \"iq\" and whose qualifying namespace is 'jabber:client' or 'jabber:server'. \n \n \n ### XMPP Communication Primitives\n\nA `stanza` is the smallest piece of XML data a client can send to a server ( server send to client) in one package.\n\nxmpp中，服务端、客户数据交换时，最小XML数据单位 叫 stanza。如上图，绿色的就是一个stanza，黑色的也是一个stanza。Stanza有几种类型: `message`, `iq`, `presence`。 \n\n#### The Message Stanza\n\nThe <message/> stanza is meant to be used to send data between XMPP entities.\n\n![6fe8a15e.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/6fe8a15e.png)\n\n - from：发送方\n - to： 接收方\n - body: 消息内容\n - type 有几种类型:\n     -`<message type=”chat”/>` ( chat message stanza) \n     - `< message type=”groupchat”/>` ( groupchat message stanza)\n     - `< message type=”error”/>` (error message stanza)\n\n#### The Presence Stanza\n\n用来表示在线状态的\n \n\n![0fbe995b.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/0fbe995b.png)\n\n`show` 标签里可能会有的几种状态: \n`chat` : online and available for chat ; \n`away` : 暂时离开\n`xa` : 长时间离开\n`dnd`: 请勿打扰\n\n如果你想知道别的状态，需要先发消息给Server，subscribe别人。 \n\n\n#### The IQ stanza\n \n The IQ( Info/Query) stanza is used to get some information from the server ( info about the server or its registered clients) or to apply some settings to the server.\n \n 用来获取消息，或者请求设置\n  \nType属性中的类型 :get ,set ,result or error. \n- `< iq type=”get”/>` stanzas are used to get(ask) some information ( from the server). \n- `<iq type=”set”/>` stanzas are used to apply some settings to the server.When you send get/set IQ stanzas to the server ,\n- it can reply either with an `< iq type=”result”/>` stanza when your request has been successfully processed by the server or \n- `<iq type=”error”/>` stanza when something has gone wrong with your request.The figure below shows an IQ stanza that we send to the server and the reply we get from the server.\n\n\n![30c96f66.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/30c96f66.png)\n\n\nThe client sends an IQ get stanza to the server to request its contact list.We know it is asking for the contact list because of the `jabber:iq:roster` XML namespace.\n\nThe XMPP engine in the server is programmed to know that when a client sends `jabber:iq:roster` namespaced IQ ,it wants to retrieve its contact list.There are other `namespaces` in XMPP for other uses and you will surely come accross them in your XMPPing journey.\n\nThe server responds with a list of the JID’s contacts wraped within a `jabber:iq:roster` namespaced `<query/>`tag.\n\n\n## 本地搭建 Server \n\n我搭的是ejabberd. 官方安装教程: [Installing ejabberd \\| ejabberd Docs](https://docs.ejabberd.im/admin/installation/#install-on-macos)\n\n#### 启动服务\n\n```\ncd /Applications/ejabberd-19.02\n//开启服务\n./bin/ejabberdctl start  \n//状态\n./bin/ejabberdctl status  \n\n// help 查看更多功能哦\n./bin/ejabberdctl help \n```\n\n#### 注册账户\n\n打开 [admin 页面](http://localhost:5280/admin/), 虚拟主机 -> localhost(可能你的名字不一样) -> 用户。 现在你可以自己创建账户了。\n\n![578b88b6.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/578b88b6.png)\n\n\n如果有自定义需求,配置教程 [Configuring ejabberd \\| ejabberd Docs](https://docs.ejabberd.im/admin/configuration/#mod-http-ws) \n \n#### 客户端玩起来\n\n客户端有很多[选择](https://xmpp.org/software/clients.html)，不过大多数都是渣。如果是WebSocket，用这个 [GitHub - processone/xmpp-websocket-client: Test XMPP Websocket client](https://github.com/processone/xmpp-websocket-client) 调试可以看到stanza，挺方便的。\n\n如果Mac用户报auth问题，可以打开`vim conf/ejabberd.yml`, `tls`配置成`false`\n![5202ee46.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/5202ee46.png)\n\n#### 关于js lib\n打算用React Native写，lib选了 [GitHub - xmppjs/xmpp.js: XMPP for JavaScript](https://github.com/xmppjs/xmpp.js) 。当然 Web多用框架 Strophe.js。这儿有个简单比较[How do you compare to strophe.js · Issue #217 · xmppjs/xmpp.js · GitHub](https://github.com/xmppjs/xmpp.js/issues/217)\n\n### 其他资料\n\n- 简单介绍 [A friendly introduction to XMPP – blikoon](https://www.blikoontech.com/xmpp/xmpp-a-soft-friendly-introduction)\n\n- 官方协议很详细，例子也很形象。 [Extensible Messaging and Presence Protocol (XMPP): Core](https://xmpp.org/rfcs/rfc6120.html#tls)\n\n- 如何选择即时通讯应用的数据传输格式 [如何选择即时通讯应用的数据传输格式-其它分享/专项技术区 - 即时通讯开发者社区!](http://www.52im.net/thread-276-1-1.html)\n- 强列建议将Protobuf作为你的即时通讯应用数据传输格式 [强列建议将Protobuf作为你的即时通讯应用数据传输格式-其它分享/专项技术区 - 即时通讯开发者社区!](http://www.52im.net/thread-277-1-1.html) \n\n\n\n\n","tags":["XMPP"],"categories":["NetWork"]}]